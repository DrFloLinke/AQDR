[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"Welcome Analysing Quantitative Data R! purpose module introduce key components statistical programming language R demonstrate commonly used methods can applied preprocess analyse quantitative data.module divided four parts. Please work part time, ensure complete exercises end chapter.queries, please contact F.Reiche@warwick.ac.uk","code":""},{"path":"accessibility.html","id":"accessibility","chapter":"Accessibility","heading":"Accessibility","text":"companion uses font “Lexend”. Lexend fonts intended reduce visual stress improve reading performance. Initially designed dyslexia struggling readers mind, Bonnie Shaver-Troup, creator Lexend project, soon found fonts also great everyone else.companion also uses dark mode theme. many users, including neurodivergent individuals, dark mode can reduce eye strain enhance focus minimising visual overstimulation.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"section provides basic overview R programming language instructions set R RStudio computer.","code":""},{"path":"introduction.html","id":"what-is-r-and-why-should-i-learn-it","chapter":"1 Introduction","heading":"What is R and why should I learn it?","text":"R open-source statistical programming language used data processing, analysis visualization. released 1993 University Auckland based older S programming language. Since , grown one popular languages quantitative data analysis across multiple disciplines.many reasons learning R worth time:1. ’s open-source - opposed popular statistical packages SPSS, Stata SAS, R open-source tool. means using R public libraries completely free charge requires special licences. maintained user community, thus improvements directly coincide requirements end-users, rather profit-driven considerations often guiding introduction new functionalities proprietary statistical packages.2. can widely applied - since ’s developed users, tools R almost everything, simple data manipulation visualization automated web data collection, natural language processing, survey data analysis, epidemiology, computational biology, social network analysis, cognitive modelling, geospatial analysis, deep learning many .3. widely applied - 2019, R 5th popular tool data science mentioned job advertisements indeed.com. widely used variety industries, including tech, consulting, think-tanks public institutions.4. abundance resources available -line - due increase popularity recent years, multiple R courses available -line, help master usage particular techniques libraries practical exercises. considerable size community emerged surrounding language throughout recent decades means almost problems face different levels advancement R programming likely encountered others past. result, Google tremendous resource troubleshooting, debugging deepening understanding ins outs R programming. Examples useful MOOC course websites include DataCamp, Coursera Edex.5. programming language analysing data. may sound like cliché, ubiquity data transforming almost every area life nowadays. Therefore data literacy understanding key programming concepts extremely useful , never know may need future. Majority concepts covered course large extent transferable commonly used languages data analysis tools. high level technical data analysis skills one desirable skills according employers - fact largely overlooked many prospective job seekers:","code":""},{"path":"introduction.html","id":"the-course-structure","chapter":"1 Introduction","heading":"The course structure","text":"course divided four parts. first one introduce R, covering basic concepts related different data structures, simple tools analysis core programming concepts. second part extends application specialist R libraries used data manipulation visualization. Part 3 covers key statistical analysis techniques, correlation linear regression discusses can applied R. Finally, part 4 devoted advanced topics.chapter consists content part, discussing new R tools techniques examples, followed summary, includes list functions used chapter along short explanations finally set practical _exrcises solutions. material presented chapter - R Script, Markdown file, exercises data - available downloaded top chapter page. Throughout chapter’s content, R code always presented “chunks” followed output produce, can see image . Note can always use button top right corner copy content chunk clipboard paste R session.remainder chapter, go process setting necessary tools personal computer.","code":""},{"path":"introduction.html","id":"setup","chapter":"1 Introduction","heading":"Setup","text":"get started R, ’ll need download two things: R language R Studio IDE (Integrated Development Environment). can get first one CRAN following appropriate installation link operating system top page. install R, go RStudio website download install R Studio.Now done installation, ready start using R - can clicking RStudio shortcut. opening application, couple things useful set . First, open “Tools” tab top window select “Global Options”. , “General tab” uncheck “restore .RData workspace startup” set “Save workspace .RData exit” “Never”. ensure R session always starts clean, without objects loaded previous time used . , “Code” section, check option “Soft-wrap R Source file”. Finally “Appearance” section select editor theme choice, well appropriate font size zoom. Click Apply OK done.","code":""},{"path":"introduction.html","id":"layout","chapter":"1 Introduction","heading":"Layout","text":"R Studio editor consists R main panes - “Source”, “Console”, “Environment/History/…”, “Files/Plots/Packages/…”. can adjust location hide pane button, located right side navigation bar.","code":""},{"path":"introduction.html","id":"console-pane","chapter":"1 Introduction","heading":"Console pane","text":"console output generated R (except plots) goes. can also enter R Studio function calls produce output. Give try type print(\"Hello world!\") command line.can also try entering simple mathematical calculations 2+2 see R works perfectly calculator. Note rarely enter longer pieces code console. ensure reproducibility work, code always executed saved R Scripts.","code":"\nprint(\"Hello world!\")[1] \"Hello world!\""},{"path":"introduction.html","id":"source-pane","chapter":"1 Introduction","heading":"Source pane","text":"source pane contains R Scripts - essentially text files save longer pieces R code can execute sequentially. can open new R-Script clicking icon top left corner pressing Ctrl + Shift + N Windows (Command + Shift + N Macbooks). can save R script clicking floppy disk icon top R script pressing Ctrl + S (Command + S). Please save file name hello.R. Make sure create separate folder r_course store files related lessons. can type print(\"Hello world!\") function call console execute selecting line pressing Ctrl + Enter (Command + Enter) pressing small icon top right corner. Generally, can execute longer pieces code first selecting entire chunk using cursor pressing appropriate execution keyboard shortcut clicking execution button. can also comment code using # hashtag. Everything following # interpreted R code, therefore can write anything want begin new line pressing Enter. Generally, ’s crucial comment code, come back scripts half year, likely remember everything. rather keeping print(\"Hello world!\") first R script, type:","code":"\nprint(\"Hello world!\") #this function prints it input to the console"},{"path":"introduction.html","id":"a-short-note-on-reproducibility","chapter":"1 Introduction","heading":"A short note on reproducibility","text":"vital essential code work course future cases R usage stored R scripts rather executed directly console. ideal R project consist file containing data used format collected (case primary data) provided (case secondary data) R script(s) used analysis appropriate comments made step, including data preprocessing, visualization statistical analyses run part project. way, anyone wants reproduce analysis (including year) can simply open script, “press play” get results , well trace back steps decisions made arrive results. crucial academia, allows supervisor/reviewer ensure methodological correctness work, important step tackling replication crisis haunting many academic disciplines. also important business setting, allows co-workers understand work, find possible errors re-use necessary, rather looking black box producing output potentially questionable quality.Essential code refers anything needed reproduce analysis. examples non-essential operations may still execute console include getting overview data (example printing variable names, number records, variable types producing simple plot going include final work) well looking function documentation described . However, course, ’s recommended keep code use R scripts. allow come back lesson review tools learned throughout course. Every section provide R script code uses order top page. also include R markdown file (.Rmd) content. Rmarkdown special format used produce documents formats HTML, pdf Docx mixing text R code - learn R Markdown section end course.","code":""},{"path":"introduction.html","id":"environment-pane","chapter":"1 Introduction","heading":"Environment pane","text":"third tab provides list R Environments. important idea R, irrelevant course. advanced readers, Hadley Wickham’s Advanced R provides good overview concept. course, work R’s Global Environment. objects assign R stored displayed. example, printed output 2 + 2 R console. However, can also store output object (almost) arbitrary name, say x, using <- assignment operator. output normally stored console instead passed object left. can type x script execute type x console press enter see value stored x, seen .Note x appeared environment pane Values section. Similarly, can create function, typing:, function foo appear environment appropriate label. learn assignment functions R Programming Basics Key Programming Concepts. , important takeout point “Environment” tab allows see objects defined R, along key properties.","code":"\nx <- 2 + 2\nx[1] 4\nfoo <- function() 2 + 2"},{"path":"introduction.html","id":"a-short-note-on-keeping-your-working-environment-clean","chapter":"1 Introduction","heading":"A short note on keeping your working environment clean","text":"working R project, ’s important always start clean environment. Especially start receiving error trace back easily, best first step often clean run session run script run line carefully examining output. clean working environment, simply restart R Studio session, either selecting “Restart R” option “Session” tab top window pressing Ctrl + Shift + F10 (Command + Shift + F10). Note cause lose everything stored environment. yet another reason put code script - result, even restart session, able reproduce everything previously present Global Environment.","code":""},{"path":"introduction.html","id":"filesplothelp-pane","chapter":"1 Introduction","heading":"Files/plot/help … pane","text":"last pane contains file browser, plot viewer documentation. learn plotting data chapters Exploratory analysis Data visualization. importantly, section also can view help coming R documentation. Every function R offline documentation file associated can access using R Studio. simply type help(functionname) question mark ? followed function name. Give try typing ?sum R console pressing enter - able see help sum function. documentation extremely useful working R. content may seem bit technical first, learn R, lot things become clearer, making easier learn understand new functionalities. Furthermore, usually provides reproducible examples R function’s usage (need scroll bottom documentation find ), allow understand context can function used. example, sum function documentation, can see:Give try hello.R R script - see sum function behaving exactly expected.","code":"\n## Pass several numbers to sum, and it also adds the elements.\nsum(1, 2, 3, 4, 5)"},{"path":"introduction.html","id":"a-short-note-on-finding-help-when-working-with-r","chapter":"1 Introduction","heading":"A short note on finding help when working with R","text":"built-documentation useful, sometimes may run trouble ’s difficult work . simplest solution concisely describe problem (copy error message receiving) Google . Usually, first result show come StackOverflow. StackOverflow Q & website focused programming languages, extensive section solely R (almost 350 000 questions time course creation). example, can try typing \"\" + 5 console. resulting error message Error \"\" + 5 : non-numeric argument binary operator rather complicated, might put many first-time users . However, quick Google search lead Stack Overflow post, explains binary operation calculation takes two values (operands) produces another value (…) see error message, means (function ’re calling ) trying perform binary operation something isn’t number. Note ’s good make sure question answered previously (case 99 100 times) posting new one. decide post question, make sure follow Stack Overflow guidelines, well make example reproducible, described post.","code":""},{"path":"basics.html","id":"basics","chapter":"2 Basics of R Programming","heading":"2 Basics of R Programming","text":"","code":""},{"path":"basics.html","id":"content","chapter":"2 Basics of R Programming","heading":"2.1 Content","text":"","code":""},{"path":"basics.html","id":"arithmetic-operations-and-assignment","chapter":"2 Basics of R Programming","heading":"Arithmetic operations and assignment","text":"R allows perform every basic mathematical operation, can simply used calculator. , can see several examples.operations performed generate output, printed R console. time, however, useful store outputs operations perform, can accessed repeatedly. , can store values variables, can viewed manipulated referencing names. Values assigned variables using <-operator. = may seem equivalent, advanced reasons <- used whenever assigning value. ’re interested technical details behind , can check Stack Overflow post.can name variable anything like, however :start numberstart numberhave whitespaces1have whitespaces1include mathemtical operators ’s name, *, /, ^, %, etc. - ’s best avoid special characters except “” “.” separate words necessary, example my_variable .variable. can see dot used variable names many users, technically using  better practice, dot additional special meaning attached .include mathemtical operators ’s name, *, /, ^, %, etc. - ’s best avoid special characters except “” “.” separate words necessary, example my_variable .variable. can see dot used variable names many users, technically using  better practice, dot additional special meaning attached .also useful avoid naming variables using names already defined R something else - however, learn avoid progress course.Keep mind, variable names arbitrary, ’s good keep concise informative, especially present code someone come back work long period time.Assigning values produce output. access values assigned variable, call name directly script console. can use perform mathematical operations objects well.Finally, can always assign new value name. However implies old value discarded. can useful know won’t need access value . example, ’s common practice modify variable already defined x <- x + 5. simply means “add 5 x store x”.","code":"\n5 + 3 #addition[1] 8\n5 - 3 #subtraction[1] 2\n5 / 3 #division[1] 1.666667\n5 / 0[1] Inf\n5 * 3 #multiplication[1] 15\n5 ^ 3 #exponentiation[1] 125\nsqrt(4) #square root[1] 2\n(5 + 5) / (3 + 1) #parenthesis[1] 2.5\n9 %% 2 #modulo[1] 1\n9 %/% 2 #integer division[1] 4\nlog(2) #natural logarithim[1] 0.6931472\nexp(2) #exponent[1] 7.389056\nx <- 5\nmy_number <- 4.2\nresult <- 5 + 6 * 7 - 8\nx <- 5\ny <- 7\nx[1] 5\ny[1] 7\nx + y[1] 12\nz <- x * y\nz[1] 35\nx <- 5\nx[1] 5\nx <- 7\nx[1] 7\nx <- x + 2"},{"path":"basics.html","id":"vectors","chapter":"2 Basics of R Programming","heading":"Vectors","text":"operations useful, true power R comes -called vectorization mathematical () operations. vector R terminology just fancy word ordered sequence numbers “column” Excel sheet. Vectors also commonly referred variables - context course, terms used interchangably. Vectors created combine function c(). function simply expression followed parentheses takes values input generates values output. Vectors assigned names way numbers. fact, number R equivalent vector length 1. can see examples vectors created.R also offers shorthand creating sequences integers two values, example:also possible create multiple repetitions given vector using rep() function, takes vector first argument number required repetitions second argument.length vector refers number elements contains. can examined using length() function:Vectorization operation refers fact operation performed vectors element-wise. true majority R operations. example, adding vectors [1 2 3] [5 6 7] produce vector [6 8 10]. operation performed vector single number (scalar, using specific terminology), applied pair elements, [1 1 1] multiplied 2 yield [2 2 2]. can see examples vectors action.case performing operations vector scalar (one number), operation applied element vector. example:mentioned earlier vectors can thought ordered sequences numbers, can also contain text. vectors callled “character vectors” constructed similarily numeric vectors. text enquoted “” denote interpreted variable name function.Mathematical operations addition division performed character vectors obvious reasons produce error attempt . However, can combine words numbers one vector - however, treated text, number 5 example gets converted character “5”.paste function useful dealing character vectors - can thought equivalent addition operation text.","code":"\nx <- c(1, 4, 5, 6)\nx[1] 1 4 5 6\nz <- c(5 / 2, 7 * 8, 2 + 1)\nz[1]  2.5 56.0  3.0\nv <- c(x, z)\nv[1]  1.0  4.0  5.0  6.0  2.5 56.0  3.0\n1:10 [1]  1  2  3  4  5  6  7  8  9 10\nx <- 15:5\nx [1] 15 14 13 12 11 10  9  8  7  6  5\nrep(5, 3) #repreat the number 5 3 times[1] 5 5 5\na <- c(5, 6, 7)\nb <- rep(a, 4) #repeat vector a 4 times and assign it to b\nb [1] 5 6 7 5 6 7 5 6 7 5 6 7\na <- 1:5\nlength(a)[1] 5\nx <- c(1, 2, 3, 2)\ny <- c(5, 6, 7, 4)\nx + y[1]  6  8 10  6\nx - y[1] -4 -4 -4 -2\nx ^ y[1]    1   64 2187   16\nz <- 5 * x - 2 * y\nz[1] -5 -2  1  2\nx <- c(1, 2, 3, 2)\nx * 3[1] 3 6 9 6\na <- \"Hello world\"\na[1] \"Hello world\"\nwords <- c(\"This\", \"Is\", \"A\", \"Sequence\", \"Of\", \"Words\")\nwords[1] \"This\"     \"Is\"       \"A\"        \"Sequence\" \"Of\"       \"Words\"   \nmixed <- c(5, \"something\", \"something else\")\nmixed[1] \"5\"              \"something\"      \"something else\"\nname <- \"John\"\nsurname <- \"Doe\"\npaste(name, surname)[1] \"John Doe\"\nnames <- c(\"John\",\"Jane\",\"Thomas\")\nsurnames <- c(\"Doe\",\"Smith\",\"Kowalsky\")\npaste(names, surnames)[1] \"John Doe\"        \"Jane Smith\"      \"Thomas Kowalsky\""},{"path":"basics.html","id":"coercion","chapter":"2 Basics of R Programming","heading":"Coercion","text":"Another important topic dealing vectors coerecion. refers forcing one vector type become another using functions. example, use .character force R object character vector, .numeric force numeric vector:Note always work, many cases elements one vector type interpreted another. example:case, R still returns output, however third element nums vector turned NA value. NA shorthand Available - ’s constant R uses deal missing values. indicated warning printed R console. Missing values covered detail next chapter.","code":"\nnumbers_char <- c(\"5\",\"6\",\"7\")\nnumbers_char[1] \"5\" \"6\" \"7\"\nnumbers <- as.numeric(numbers_char)\nnumbers[1] 5 6 7\nnumbers <- c(10, 123, 12)\nas.character(numbers)[1] \"10\"  \"123\" \"12\" \nnums <- c(\"1\",\"2\",\"three\")\nas.numeric(nums)Warning: NAs introduced by coercion[1]  1  2 NA"},{"path":"basics.html","id":"logical-values-and-operators","chapter":"2 Basics of R Programming","heading":"Logical Values and Operators","text":"Another crucial type operations R logical operations, also known boolean. used evaluate truth value logical statements variable “equal variable B” variable numeric vector. Whenever queried statement True, return TRUE FALSE otherwise. can see simple examples using equality operator == - double equality means checking whether two values equal, rather assigning one another.! operator used negation, !TRUE results FALSE vice versa. Accordingly, != used denote ‘equals ’.Logical operations can also used compare values, using < b “less b”, <= b “less equal b” vice versa.Finally, & (logical “”) | (logical “”) operators designed combine TRUE/FALSE values. , put & two logical values, yield TRUE values TRUE. | hand return TRUE values TRUEThe logical values also often used verify whether dealing certain R type - example check whether value character numeric. achieved using functions, .numeric .character.numbers characters, logical values also form special types vectors can used perform element-wise operations.can also used find whether value numeric character vector equal another.boolean vectors can also thought special case numeric vectors consisting 0s 1s, 0 corresponds FALSE 1 TRUE value. can easily seen example :","code":"\na <- 5\na == 5[1] TRUE\na == 3[1] FALSE\na - 2 == 3[1] TRUE\n\"John\" == \"James\"[1] FALSE\n!TRUE[1] FALSE\n!FALSE[1] TRUE\n5 != 6[1] TRUE\n\"John\" != \"James\"[1] TRUE\nx <- 5\ny <- 3\n\nx > y[1] TRUE\nx - 2 < y[1] FALSE\nx - 2 <= y[1] TRUE\nTRUE & TRUE[1] TRUE\nTRUE & FALSE[1] FALSE\nTRUE | FALSE[1] TRUE\nFALSE | FALSE[1] FALSE\n(5 + 1 == 6) | (2 + 2 == 5)[1] TRUE\n(5 + 1 == 6) & (2 * 2 == 10)[1] FALSE\nnumbers <- c(5, 6, 7)\nis.vector(numbers)[1] TRUE\nis.numeric(numbers)[1] TRUE\nis.character(numbers)[1] FALSE\nwords <- c(\"Word\",\"Word\")\nis.numeric(words)[1] FALSE\nis.character(words)[1] TRUE\na <- c(TRUE, FALSE, FALSE)\nb <- c(TRUE, TRUE, TRUE)\na & b[1]  TRUE FALSE FALSE\nx <- c(5, 6, 7, 8)\nx == 5[1]  TRUE FALSE FALSE FALSE\ny <- c(\"John\", \"James\", \"Thomas\")\nz <- c(\"John\",\"James\",\"Robert\")\nz == y[1]  TRUE  TRUE FALSE\nTRUE + TRUE + TRUE[1] 3"},{"path":"basics.html","id":"indexing","chapter":"2 Basics of R Programming","heading":"Indexing","text":"large volume data can stored one vector, often may want access specific element , fraction elements. index vector, simply integer corresponding position value vector. , vector N values integers ranging 1 N. example, vector c(5, 10, 3, 2), index 5 1, index 10 2, index 3 3, etc. Indexing operation accessing vector’s elemet given index, using square brackets []. example, [5] means “get fifth element vector ”.Indexing can also used replace values given position vector. example , replace first element number 1000.Indexing can also done using another vector numeric values. example may want get first, second fifth elements given vector, sequence elements 1 4.Indexing even powerful conjunction logical operations. , logical vector can used index vector - indexing operations returns values indexed vector corresponding indexing logical vector TRUE. may sound confusing first, actually quite straightforward, seen :example, imagine vector gdp vector holds GDP per capita values list countries country vector holds corresponding country names. Logical indexing may useful, want get names countries GDP per capita certain value:can also use multiple critertia, example index countries GDP higher 40000 USD UN Human Development Index higher 0.9.","code":"\na <- c(5.2, 4.5, 6.2, 8.9, 10.2, 4.8, 0.1)\na[5][1] 10.2\na[1] <- 1000\na [1] 1000.0    4.5    6.2    8.9   10.2    4.8    0.1\na <- c(5.2, 4.5, 6.2, 8.9, 10.2, 4.8, 0.1)\na[c(1, 3, 5)][1]  5.2  6.2 10.2\n#equivalent to:\nb <- c(1, 3, 5)\na[b][1]  5.2  6.2 10.2\n#can also be done for a sequence\na[1:5][1]  5.2  4.5  6.2  8.9 10.2\nx <- c(4.2, 5.6, 7.2, 1.1)\nindex <- c(FALSE, TRUE, TRUE, FALSE) #only second and third elements are TRUE\nx[index] #returns only second and third elements of the x vector[1] 5.6 7.2\ngdp <- c(69687, 67037, 65111, 52367, 41030, 32946, 29961)\ncountries <- c(\"Qatar\", \"Iceland\", \"USA\",\n               \"Germany\", \"United Kingdom\", \"Italy\", \"Spain\")\ncountries[gdp > 40000][1] \"Qatar\"          \"Iceland\"        \"USA\"            \"Germany\"        \"United Kingdom\"\nhdi <- c(0.848, 0.938, 0.920, 0.939, 0.920, 0.883, 0.893)\ncountries[gdp > 40000 & hdi > 0.9][1] \"Iceland\"        \"USA\"            \"Germany\"        \"United Kingdom\""},{"path":"basics.html","id":"sorting","chapter":"2 Basics of R Programming","heading":"Sorting","text":"many occasions, ’s useful sort vector see ’s highest lowest values. can achieved using sort function.default, R sorts vectors increasing order (case character vectors, translates -Z sorting). However, sort function additional argument, decreasing, can used specify whether sorting done decreasing order. argument default argument, .e. takes certain value unless specified otherwise user. common R lot functions allow customizing way work specifying additional arguments, default value avoid effort specifying every time certain function used. default arguments can easily recognized R documentation. case sort, Usage section reads sort(x, decreasing = FALSE, ...). means, function takes x (vector sorted) main argument, decreasing, defaults FALSE. argument decreasing also logical - can take TRUE FALSE values - common argument type certain operation can performed two different ways additional element may always desired.sorting vector may useful certain circumstances, lot time may actually need sort values another vector. example, let’s assume vector names corresponding ages, want see names ordered age.can achieved using order function, returns indices vector needed re-arrange sorted order.case, age 10 (index 2) go first place, 15 (index 4) second position, 20 (index 3) third, etc. Note two following operations equivalent:first one tells R simply sort values age, whereas second index age indices age sorted order. get names sorted age, can use:Finally, rank function returns sample ranks given vector, .e. relative position sorted list. Note different order. rank returns position corresponding value sorted order, whereas order returns indices original vector needed put sorted order.example, first value vector returned rank(age) 5, since first value age vector 50, last numeric order. first value vector returned order(age) 2 - , 2nd element age (.e. value 10) go first position vector correctly ordered.Finally, logical indices can converted numerical values using function. takes logical vector input returns indices value vector TRUE. can see example :function helpful certain situations, however ’s bad practice apply cases logical indexing sufficient, example:sufficient, ’s need use:One situations use function can preferred simple logical indexing vector contains missing values (discussed next chapter. example, first expression return NA., running logical comparisons numbers > 5 always returns missing values, along TRUE FALSE logical values. make sense, since NA comparable number.skips NA values, returning indices values TRUE.result, can perform indexing variable missing values using :Two cousins function .max .min, return index highest lowest value vector. , coming back ages example, can retrieve name person highest lowest age using respectively:","code":"\nnumbers <- c(8, 4, 5, 10, 2, 123)\nsort(numbers)[1]   2   4   5   8  10 123\nsort(numbers, decreasing = TRUE)[1] 123  10   8   5   4   2\nnames <- c(\"Thomas\",\"Peter\",\"Ahmed\",\"Emily\",\"Helena\")\nage <- c(50, 10, 20, 15, 40)\norder(age)[1] 2 4 3 5 1\nsort(age)[1] 10 15 20 40 50\nage[order(age)][1] 10 15 20 40 50\nnames[order(age)][1] \"Peter\"  \"Emily\"  \"Ahmed\"  \"Helena\" \"Thomas\"\nnames[order(age, decreasing = TRUE)] #decreasing order[1] \"Thomas\" \"Helena\" \"Ahmed\"  \"Emily\"  \"Peter\" \nage[1] 50 10 20 15 40\nrank(age)[1] 5 1 3 2 4\norder(age)[1] 2 4 3 5 1\nnumbers <- 1:10\nnumbers > 5 [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\nwhich(numbers > 5)[1]  6  7  8  9 10\nnumbers[numbers > 5][1]  6  7  8  9 10\nnumbers[which(numbers > 5)][1]  6  7  8  9 10\nnumbers <- c(2, 4, 1, 10, 20, NA)\nnumbers[numbers > 5][1] 10 20 NA\nnumbers > 5[1] FALSE FALSE FALSE  TRUE  TRUE    NA\nwhich(numbers > 5)[1] 4 5\nnumbers[which(numbers > 5)][1] 10 20\nnames[which.max(age)][1] \"Thomas\"\nnames[which.min(age)][1] \"Peter\""},{"path":"basics.html","id":"summary","chapter":"2 Basics of R Programming","heading":"2.2 Summary","text":"Vectors simply ordered sequences elements represent concept analyze - example, can vector country names vector corresponding GDP per capita amounts. also known variables.Vectors simply ordered sequences elements represent concept analyze - example, can vector country names vector corresponding GDP per capita amounts. also known variables.Vectorization simply means, add (perform operation) two vectors toegether/numeric element vector, done element-wise.Vectorization simply means, add (perform operation) two vectors toegether/numeric element vector, done element-wise.Functions R objects take values inputs produce values outputs.Functions R objects take values inputs produce values outputs.Logical values result comparing vectors using logical operators (==, <, >). can either TRUE logical statment true (e.g. 2 + 2 == 4) FALSE otherwise (e.g. 7 > 10).Logical values result comparing vectors using logical operators (==, <, >). can either TRUE logical statment true (e.g. 2 + 2 == 4) FALSE otherwise (e.g. 7 > 10).Indexing means retrieving vector elements numeric index (.e. position vector). can also done using logical values - case, elements corresponding TRUE retrieved.Indexing means retrieving vector elements numeric index (.e. position vector). can also done using logical values - case, elements corresponding TRUE retrieved.Sorting refers putting elements vector numeric alphabetial order. can done either directly vector using sort() reference another vector using order(). rank() allows retrieve relative rank item (.e. position vector sorted).Sorting refers putting elements vector numeric alphabetial order. can done either directly vector using sort() reference another vector using order(). rank() allows retrieve relative rank item (.e. position vector sorted).","code":""},{"path":"basics.html","id":"functions-list","chapter":"2 Basics of R Programming","heading":"Functions list","text":"","code":""},{"path":"basics.html","id":"exercises","chapter":"2 Basics of R Programming","heading":"2.3 Exercises","text":"code creates three vectors corresponding individual’s name, birth year birth month.Create vector named birthdays contains names, birth months birth years person. example, first one look like \"Thomas, February 1976.Create vector named birthdays contains names, birth months birth years person. example, first one look like \"Thomas, February 1976.Filter people born October year 1980. Store names vector named oct1980Filter people born October year 1980. Store names vector named oct1980Given vector x <- c(5, 40, 15, 10, 11). output expect following functions?sort(x)order(x)rank(x)Use R verify answers.Vector country contains names 6 countries following 4 vectors contain countries’ correspondig Expected Years Schooling, eys, Mean Years Schooling mys, Life Expectancy Birth lexp Per capita Gross National Income gni.United Nations Human Development Index (HDI) given following formula:HDI = \\(\\sqrt[3]{\\text{Life Expectancy Index} * \\text{Education Index} * \\text{Income Index}}\\), whereLife Expectancy Index = \\(\\frac{\\text{Life Expectancy}-20}{85-20}\\)Education Index = \\(\\frac{\\text{Mean Years Schooling Index} + \\text{Expected Years Schooling Index}}{2}\\)Mean Years Schooling Index = \\(\\frac{\\text{Mean Years Schooling}}{15}\\)Expected Years Schooling Index = \\(\\frac{\\text{Expected Years Schooling}}{18}\\)Income Index = \\(\\frac{ln(GNIpc) - ln(100)}{ln(75,000) - ln(100)}\\)Write R code answer following questions:Calculate HDI countries.Calculate HDI countries.Store country names HDI lower 0.75 vector coutry_lhdi. Print names countries.Store country names HDI lower 0.75 vector coutry_lhdi. Print names countries.Store country names HDI lower 0.8 GNI higher $10000 vector country_hlghStore country names HDI lower 0.8 GNI higher $10000 vector country_hlghPrint names countries HDI least high HDI Turkey (excluding Turkey).Print names countries HDI least high HDI Turkey (excluding Turkey).Print names countries Expected Years Schooling index higher Life Expectancy Index.Print names countries Expected Years Schooling index higher Life Expectancy Index.data contains records UK General Election turnout 1964 2019.Write code answer following questions:years turnout higher 70/%?years turnout higher 70/%?parties won elections turnout 0.65?parties won elections turnout 0.65?Obtain years turnout lowest highest store vector year_minmax.Obtain years turnout lowest highest store vector year_minmax.Store names parties won 3 elections highest turnout vector top3Store names parties won 3 elections highest turnout vector top3The solutions exercises available 2020-11-12.","code":"\nyear <- c(1976, 1974, 1973, 1991, 1972, 1954, \n          1985, 1980, 1994, 1970, 1988, 1951, \n          1957, 1966, 1968, 1963, 1999, 1977, \n          1984, 1998)\n\nmonth <- c(\"February\", \"February\", \"April\",\n           \"August\", \"September\", \"November\", \n           \"October\", \"December\", \"May\", \"March\", \n           \"June\", \"November\", \"October\", \"May\", \n           \"July\", \"August\", \"March\", \"July\", \n           \"October\", \"January\")\n\nname <- c(\"Thomas\", \"Natalie\", \"James\", \n          \"Gina\", \"Cate\", \"Rob\", \"Frank\",\n          \"Tyle\", \"Marshall\", \"Ted\", \"Emily\", \n          \"Brandon\", \"Yasmin\", \"Tina\", \n          \"Phillip\", \"Natasha\", \"Joan\", \n          \"Jack\", \"Alice\", \"Barney\")\ncountry <- c(\"Argentina\", \"Georgia\",\n             \"Mexico\", \"Philippines\",\n             \"Turkey\", \"Ukraine\")\neys <- c(17.6, 15.4, 14.3, 12.7, 16.4, 15.1)\nmys <- c(10.6, 12.8, 8.6, 9.4, 7.7, 11.3)\nlexp <- c(76.5, 73.6, 75, 71.1, 77.4, 72)\ngni <- c(17611, 9570, 17628, 9540, 24905, 7994)\nturnout <- c(0.771, 0.758, 0.72, 0.788, 0.728, 0.76, 0.727, 0.753, 0.777, 0.714, 0.594, 0.614, 0.651, 0.661, 0.687, 0.673)\n\nyear <- c(1964, 1966, 1970, 1974, 1974, 1979, 1983, 1987, 1992, 1997, 2001, 2005, 2010, 2015, 2017, 2019)\n\nparty <- c(\"Labour\", \"Labour\", \"Conservative\", \"Labour\",\n           \"Labour\", \"Labour\", \"Conservative\",\n           \"Conservative\", \"Conservative\",\n           \"Conservative\", \"Labour\", \"Labour\", \"Labour\",\n           \"Conservative\", \"Conservative\", \n           \"Conservative\")"},{"path":"datastructures.html","id":"datastructures","chapter":"3 Data structures","heading":"3 Data structures","text":"","code":""},{"path":"datastructures.html","id":"content-1","chapter":"3 Data structures","heading":"3.1 Content","text":"previous chapter become familiar common data structure R programming - vector. section, introduced advanced data structures often used R, particular data.frame, common way storing manipulating data R.Generally, best way examine R object using str() function, returns contents object along class. example can check works simple vectorsnum indicates integer vector [1:3] tells us index ranges 1 3.","code":"\nnumbers <- c(5, 3, 8)\nstr(numbers) num [1:3] 5 3 8\nwords <- c(\"five\",\"three\",\"eight\")\nstr(words) chr [1:3] \"five\" \"three\" \"eight\""},{"path":"datastructures.html","id":"data-frames","chapter":"3 Data structures","heading":"Data Frames","text":"previous chapter’s exercises ’ve manipulated data related basic development indicators several countries. ’re dealing multiple variables represented multiple vectors, ’s often useful store toegether one entity - data.frame. Data frames can simply thought tables, columns vector unique name. case, can store information countries data frame called dev_data.can use head function see first 5 rows data (toy example might seem unnecessary, useful get overview variables data consists potentially thousands rows).str() function also useful get overview variables included dataframe:access column stored dataframe, can use $ operator.Similarily, can use operator create new column:case vectors, data frames can indexed retrieve values stored specific positions. Since data frame table, position dataframe associated two indices - one rows, columns - first index references row second column. example, code retrieves value second row third column dev_data.Note identical :mys third column dev_data.leaving one indices empty, can also retrieve entire row/column data frame:Data frames can also indexed integer vectors. indexing always return smaller data frame. example, retrieve rows 1 5 columns 2 3, can :Similarily, character vectors referencing column names can used subset dataframe. achieve similar result one , one also type:can also use logical indexing subset dataframes. Recall previous chapter, can check values given vector satisfy certain condition :can use output generated code index dev_data data frame obtain rows gni per capita larger 10000:many useful functions work combination data frames. , several examples:command allows evaluate column names context given data frame. means, reference data frame name whenever use one columns. Suppose wanted calculate UN’s Education Index previous section’s exercises assign ’s values new column dev_data, dev_data$edu_ind. done :However, many circumstances require reference name data frame using multiple times, often making code long unreadable. avoid , ’s often useful :function takes name dataframe first argument operation want perform second argument.Similarily, subset dataframe multiple variables, subset() command can used:","code":"\ncountry <- c(\"Argentina\", \"Georgia\", \"Mexico\", \n             \"Philippines\", \"Turkey\", \"Ukraine\")\neys <- c(17.6, 15.4, 14.3, 12.7, 16.4, 15.1)\nmys <- c(10.6, 12.8, 8.6, 9.4, 7.7, 11.3)\nlexp <- c(76.5, 73.6, 75, 71.1, 77.4, 72)\ngni <- c(17611, 9570, 17628, 9540, 24905, 7994)\ndev_data <- data.frame(country, eys, mys, lexp, gni)\nhead(dev_data)      country  eys  mys lexp   gni\n1   Argentina 17.6 10.6 76.5 17611\n2     Georgia 15.4 12.8 73.6  9570\n3      Mexico 14.3  8.6 75.0 17628\n4 Philippines 12.7  9.4 71.1  9540\n5      Turkey 16.4  7.7 77.4 24905\n6     Ukraine 15.1 11.3 72.0  7994\nstr(dev_data)'data.frame':   6 obs. of  5 variables:\n $ country: chr  \"Argentina\" \"Georgia\" \"Mexico\" \"Philippines\" ...\n $ eys    : num  17.6 15.4 14.3 12.7 16.4 15.1\n $ mys    : num  10.6 12.8 8.6 9.4 7.7 11.3\n $ lexp   : num  76.5 73.6 75 71.1 77.4 72\n $ gni    : num  17611 9570 17628 9540 24905 ...\ndev_data$gni[1] 17611  9570 17628  9540 24905  7994\ndev_data$log_gni <- log(dev_data$gni)\ndev_data$log_gni[1]  9.776279  9.166388  9.777244  9.163249 10.122824  8.986447\ndev_data[2, 3][1] 12.8\ndev_data$mys[2][1] 12.8\ndev_data[1, ] #get first row    country  eys  mys lexp   gni  log_gni\n1 Argentina 17.6 10.6 76.5 17611 9.776279\ndev_data[, 2] #get second column[1] 17.6 15.4 14.3 12.7 16.4 15.1\ndev_data[c(1,5), c(2,3)]   eys  mys\n1 17.6 10.6\n5 16.4  7.7\ndev_data[c(1,5), c(\"eys\",\"mys\")]   eys  mys\n1 17.6 10.6\n5 16.4  7.7\ndev_data$gni > 10000[1]  TRUE FALSE  TRUE FALSE  TRUE FALSE\ndev_data[dev_data$gni > 10000, ]    country  eys  mys lexp   gni   log_gni\n1 Argentina 17.6 10.6 76.5 17611  9.776279\n3    Mexico 14.3  8.6 75.0 17628  9.777244\n5    Turkey 16.4  7.7 77.4 24905 10.122824\nis.data.frame(dev_data) #check if an object is of class `data.frame`[1] TRUE\nnrow(dev_data) #number of rows[1] 6\nncol(dev_data) #number of columns[1] 6\ncolnames(dev_data) #column names[1] \"country\" \"eys\"     \"mys\"     \"lexp\"    \"gni\"     \"log_gni\"\nrownames(dev_data) #row names[1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\"\ndev_data$edu_ind <- (dev_data$mys / 15 + dev_data$eys / 18)/2\ndev_data$edu_ind <- with(dev_data, (mys / 15 + eys / 18)/2)\ndev_data[dev_data$eys > 15 & dev_data$lexp > 75, ]    country  eys  mys lexp   gni   log_gni   edu_ind\n1 Argentina 17.6 10.6 76.5 17611  9.776279 0.8422222\n5    Turkey 16.4  7.7 77.4 24905 10.122824 0.7122222\nsubset(dev_data, eys > 15 & lexp > 75)    country  eys  mys lexp   gni   log_gni   edu_ind\n1 Argentina 17.6 10.6 76.5 17611  9.776279 0.8422222\n5    Turkey 16.4  7.7 77.4 24905 10.122824 0.7122222"},{"path":"datastructures.html","id":"factors","chapter":"3 Data structures","heading":"Factors","text":"looking str(dev_data) ’ve noticed country variable vector type haven’t encountered earlier - factor. Factors specific type vectors used store values take prespecified set values, called factor levels. example, suppose two character vectors storing names students year. can use factor() create factor vector character vector. can done type vector well.can view unique levels factor using levels() function:crucial difference factor character vectors former underlying integer representation. means, ’s natural ordering levels, alphabetic default. can see using coercion function .numeric year factor.Note ordering values corresponds ordering obtained levels() function. matters circumstances (using factor variables regression models, discussed Linear Regression section course). ’s good practice explicitly pass factor levels factor() constructor. example, case, “Sophmore” comes last value factor, even though make sense second. Explicit creation factor levels can seen :can now see ordering levels different, underlying numeric representation factor:Note change value factor vector pre-specified levels:error message returned R means value trying assign factor one predefined levels (.e. “Freshman”,“Junior”, “Senior” “Sophmore”) thus NA missing value generated.However, know level values attached created future, NAs can avoided explicitly creating unused levels constructing factor vector., created variable 5 levels: Freshman, Sophmore, Junior, Senior, Graduate, even though 4 actual values factor. result, can assign value “Graduate” value without producing NAs. relevance empty factor levels become apparent next part book discussing Cross-Tabulation.can also rename levels existing factor, using levels<- command. can done either specific levels factor……levels:way, values character changed quickly.Finally, ’s confusion difference factor() .factor() functions. many contexts, can used equivalently, since create factor vector numeric character vector. However, important differences include:factor() allows explicitly pass vector levels construction, whether .factor() assigns defaultfactor() allows explicitly pass vector levels construction, whether .factor() assigns defaultThe behaviour two functions different passed factors empty levels. example, let’s create year factor earlier keep first three values. case, Sophmore Senior levels unused.behaviour two functions different passed factors empty levels. example, let’s create year factor earlier keep first three values. case, Sophmore Senior levels unused.Passing year vector .factor change anything vector’s structure:However, using factor() constructor existing factor vector convenient way drop unused levels (’s desirable):performance .factor() tends quicker numeric character vectors passed . two commands also treat NA levels slightly differently. can read Stack Overflow post.Finally, R functions data.frame constructor treat read character vectors factors default. can noticed examining dev_data data frame created earlier:can see country factor 6 levels - one country name. doesn’t make much sense, column unlikely repeating values. avoid behaviour, can set stringsAsFactors optional argument data.frame function explicitly FALSE. way, character vectors remain character variables data frame.","code":"\nname <- c(\"Thomas\",\"James\",\"Kate\",\"Nina\",\"Robert\",\"Andrew\",\"John\")\nyear_ch <- c(\"Freshman\",\"Freshman\",\"Junior\",\"Sophmore\",\"Freshman\",\"Senior\",\"Junior\")\nyear_ch[1] \"Freshman\" \"Freshman\" \"Junior\"   \"Sophmore\" \"Freshman\" \"Senior\"   \"Junior\"  \nyear <- factor(year_ch)\nyear[1] Freshman Freshman Junior   Sophmore Freshman Senior   Junior  \nLevels: Freshman Junior Senior Sophmore\nlevels(year)[1] \"Freshman\" \"Junior\"   \"Senior\"   \"Sophmore\"\nyear[1] Freshman Freshman Junior   Sophmore Freshman Senior   Junior  \nLevels: Freshman Junior Senior Sophmore\nas.numeric(year)[1] 1 1 2 4 1 3 2\nyear_ch <- c(\"Freshman\",\"Freshman\",\"Junior\",\n          \"Sophmore\",\"Freshman\",\"Senior\",\"Junior\")\nyear <- factor(year_ch, levels = c(\"Freshman\",\"Sophmore\",\"Junior\",\"Senior\"))\nlevels(year)[1] \"Freshman\" \"Sophmore\" \"Junior\"   \"Senior\"  \nas.numeric(year)[1] 1 1 3 2 1 4 3\nyear[1] <- \"Graduate\"Warning in `[<-.factor`(`*tmp*`, 1, value = \"Graduate\"): invalid factor level, NA generated\nyear_ch <- c(\"Freshman\",\"Freshman\",\"Junior\",\n          \"Sophmore\",\"Freshman\",\"Senior\",\"Junior\")\nyear <- factor(year_ch, levels = c(\"Freshman\",\"Sophmore\",\"Junior\",\"Senior\", \"Graduate\"))\nyear[1] <- \"Graduate\"\nyear[1] Graduate Freshman Junior   Sophmore Freshman Senior   Junior  \nLevels: Freshman Sophmore Junior Senior Graduate\nyear <- factor(year_ch, levels = c(\"Freshman\",\"Sophmore\",\"Junior\",\"Senior\"))\nlevels(year)[1] <- \"Fresher\"\nyear[1] Fresher  Fresher  Junior   Sophmore Fresher  Senior   Junior  \nLevels: Fresher Sophmore Junior Senior\nlevels(year) <- c(\"First\",\"Second\",\"Third\",\"Final\")\nyear[1] First  First  Third  Second First  Final  Third \nLevels: First Second Third Final\nyear_char <- c(\"Freshman\",\"Freshman\",\"Junior\",\n          \"Sophmore\",\"Freshman\",\"Senior\",\"Junior\")\nyear <- factor(year_char, levels = c(\"Freshman\",\"Sophmore\",\"Junior\",\"Senior\"))\nyear <- year[1:3]\nyear[1] Freshman Freshman Junior  \nLevels: Freshman Sophmore Junior Senior\nas.factor(year)[1] Freshman Freshman Junior  \nLevels: Freshman Sophmore Junior Senior\nfactor(year)[1] Freshman Freshman Junior  \nLevels: Freshman Junior\nstr(dev_data)'data.frame':   6 obs. of  7 variables:\n $ country: chr  \"Argentina\" \"Georgia\" \"Mexico\" \"Philippines\" ...\n $ eys    : num  17.6 15.4 14.3 12.7 16.4 15.1\n $ mys    : num  10.6 12.8 8.6 9.4 7.7 11.3\n $ lexp   : num  76.5 73.6 75 71.1 77.4 72\n $ gni    : num  17611 9570 17628 9540 24905 ...\n $ log_gni: num  9.78 9.17 9.78 9.16 10.12 ...\n $ edu_ind: num  0.842 0.854 0.684 0.666 0.712 ...\ndev_data <- data.frame(country, eys, mys, lexp, gni, stringsAsFactors = FALSE)\nstr(dev_data)'data.frame':   6 obs. of  5 variables:\n $ country: chr  \"Argentina\" \"Georgia\" \"Mexico\" \"Philippines\" ...\n $ eys    : num  17.6 15.4 14.3 12.7 16.4 15.1\n $ mys    : num  10.6 12.8 8.6 9.4 7.7 11.3\n $ lexp   : num  76.5 73.6 75 71.1 77.4 72\n $ gni    : num  17611 9570 17628 9540 24905 ..."},{"path":"datastructures.html","id":"reading-and-writing-the-data","chapter":"3 Data structures","heading":"Reading and writing the data","text":"","code":""},{"path":"datastructures.html","id":"reading-from-csv","chapter":"3 Data structures","heading":"Reading from CSV","text":"far, ’ve created small simple datasets manually typing scripts, usual way loading data R external files. common format used store data R analysis CSV file, stands Comma Separated Values. essentially means, data represented text file, values separeted columns indicate relative positions - example, csv file 5 columns 4 commas separate row.example , read data Human Development Indicators 209 countries 2018 obtained UN Human Development Reports. Yuo can download file used example .example, first argument specifies path file read string, .e. enclosed quotation marks. file can read:\n1. using absolute path - example dev <- read.csv(\"C:/Users/yourusername/Documents/dev2018.csv\") Windows dev <- read.csv(\"/Users/yourusername/Documents/dev2018.csv\") MacOS. case, need provide full path file located computer.using relative path, example. case, R search directory current working directory. Working directory simply specific folder computer R looks data. R Studio usually sets one default working directory (can changed Tools -> Global Options -> Set Default Working Directory). means every time open RStudio restart R session (described Chapter 1, working directory set default. can also change working directory manually executing setwd() function script console.can also get current working directory using getwd() function:users tend include setwd(path//project) beginnings scripts, potentially problematic, whenever move data script another folder, errors likely occur. Therefore, good practice always set working directory location R Source script keep data folder source script. can done choosing Session tabNote case, assumed selected “Set Working Directory” > “Source File” location “Session” tab Rstudio, discussed Introduction directory source file folder called “data” dev2018.csv file stored. Alternatively, dev <- read.csv(\"dev2018.csv\") read file directly working directory. also use dev <- read.csv(\"C:/Users/yourusername/Documents/dev2018.csv\") Windows dev <- read.csv(\"/Users/yourusername/Documents/dev2018.csv\") MacOS read data file arbitary folder using absolute path. Similarily data.frame constructor, can also use stringsAsFactors argument ensure character variables read strings.can also save data .csv files using write.csv, takes data frame first argument string specifying path want save file second argument. example, suppose want keep first 40 rows data store separate file.","code":"\ndev <- read.csv(\"data/un_data/dev2018.csv\", stringsAsFactors = FALSE)\nsetwd(\"C:/Users/yourusername/folder\")\ngetwd()\ndev_new <- dev[1:40, ]\nwrite.csv(dev_new, \"data/un_data/dev_new.csv\")"},{"path":"datastructures.html","id":"reading-from-other-formats","chapter":"3 Data structures","heading":"Reading from other formats","text":"csv common format, data often likely come many variants - common examples include Stata’s .dta files SPSS’ .sav, well .xlsx Excel format. R packages offer functionalities percisely deal files.far, used built-functionalities offered R. range pretty extensive ones covered course tip iceberg, much offered user-made packages, offer new functions useful specific tasks. official R packages available CRAN. use package needs installed first loaded. example, use example package named foo, first run install.packages(\"foo\") download package files CRAN install put library(foo) R Script load R. Note installation done , load library every time use - ’s , always put library calls top R script. use function package without loading first, R script execution fail! Please also note, pass package name string (.e. quotation marks) install.packages, without library.Coming back example, can use R package haven load Stata, SPSS SAS files. can see example :Similarily, data can written using:alternatives offered haven package inlcude read_sav read_xpt. packages useful reading unusual data types include readxl reading Excel files foreign broader choice file types.","code":"\ninstall.packages(\"haven\")\nlibrary(haven)\ndev_stata <- read_dta(\"data/un_data/dev2018.dta\")\nwrite_dta(dev, \"data/un_data/dev2018.dta\")"},{"path":"datastructures.html","id":"missing-values","chapter":"3 Data structures","heading":"Missing values","text":"mentioned earlier, NA missing value constant particularly important R. Real-life data likely deal time using R practice often imperfect missingness addressed one first steps analysis process..na() command can used determine whether value R object missing. returns true value index missing.count NAs R object can levarage fact TRUE values also interpreted 1 use sum function:can also verify whether object contains NAs using anyNA function. Let’s check HDI data loaded contains missing values:column returns TRUE. Therefore missingness data.Another useful function missing data analysis complete.cases. name suggests, given data frame returns logical vector TRUE row doesn’t contain missing values. can verify observations cause data missingness:","code":"\nnumbers <- c(1, 4, NA, 6, NA)\nis.na(numbers)[1] FALSE FALSE  TRUE FALSE  TRUE\nsum(is.na(numbers))[1] 2\ndev <- read.csv(\"data/un_data/dev2018.csv\")\nanyNA(dev)[1] TRUE\ndev[!complete.cases(dev), ]                                country  eys   gni lexp mys\n91  Korea (Democratic People's Rep. of) 10.8    NA 72.1  NA\n122                               Nauru 11.3 17313   NA  NA\n150                          San Marino 15.1    NA   NA  NA\n180                              Tuvalu 12.3  5409   NA  NA\n195                             Somalia   NA    NA 57.1  NA"},{"path":"datastructures.html","id":"lists","chapter":"3 Data structures","heading":"Lists","text":"final key R data structure covered section lists. Similarily data frames, lists can thought containers store data structures.2 However, unlike data frames, less strict terms contents - list can store vectors different length, data frames even lists. Lists created list() constructor.can extract elements list using names numeric index. index list, double square brackets [[ used, opposed vectors.list indexed single brackets, returns one-element list, rather object stored :can also extract elements list using $ operator, similarily data.frames. Finally, can assign values lists similarily case vectors data.frames:","code":"\nmy_list <- list(names = c(\"Tom\",\"James\",\"Tim\"), values = 1:20)\nmy_list$names\n[1] \"Tom\"   \"James\" \"Tim\"  \n\n$values\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\nmy_list[[1]][1] \"Tom\"   \"James\" \"Tim\"  \nmy_list[[\"names\"]][1] \"Tom\"   \"James\" \"Tim\"  \nvalues <- my_list[[\"values\"]]\nstr(values) int [1:20] 1 2 3 4 5 6 7 8 9 10 ...\nvalues <- my_list[\"values\"]\nstr(values)List of 1\n $ values: int [1:20] 1 2 3 4 5 6 7 8 9 10 ...\nmy_list[[\"new\"]] <- c(\"new\",\"values\")\nstr(my_list)List of 3\n $ names : chr [1:3] \"Tom\" \"James\" \"Tim\"\n $ values: int [1:20] 1 2 3 4 5 6 7 8 9 10 ...\n $ new   : chr [1:2] \"new\" \"values\""},{"path":"datastructures.html","id":"summary-1","chapter":"3 Data structures","heading":"3.2 Summary","text":"Data Frames one common data structures R. can think Excel spreadsheet tables rows columns list variables (vectors equal length), unique name. value data frame two indexes - one row number one column number. example, df[2,3] retrieves value second row third column.Data Frames one common data structures R. can think Excel spreadsheet tables rows columns list variables (vectors equal length), unique name. value data frame two indexes - one row number one column number. example, df[2,3] retrieves value second row third column.Factors special kind vectors can take pre-specified set values, determined factor created.Factors special kind vectors can take pre-specified set values, determined factor created.csv files common way storing data R. can load data using read.csv save data using write.csv.csv files common way storing data R. can load data using read.csv save data using write.csv.working directory folder computer R looks files default. can check using getwd() function, change using setwd()set location current script located selecting Session > Set Working Directory > Source File Location.working directory folder computer R looks files default. can check using getwd() function, change using setwd()set location current script located selecting Session > Set Working Directory > Source File Location.packages sets new functions developed R external developers, extending functionalities. can install using install.packages load using library function.packages sets new functions developed R external developers, extending functionalities. can install using install.packages load using library function.missing values marked R NA token. many useful functions created detect missing values, .na, complete.cases anyNA.missing values marked R NA token. many useful functions created detect missing values, .na, complete.cases anyNA.lists another type R data structure. can thought containers, can used store arbitrary elements position.lists another type R data structure. can thought containers, can used store arbitrary elements position.","code":""},{"path":"datastructures.html","id":"functions-list-1","chapter":"3 Data structures","heading":"Functions list","text":"","code":""},{"path":"datastructures.html","id":"exercises-1","chapter":"3 Data structures","heading":"3.3 Exercises","text":"following code returns error. ? Check happends set b 1:5 instead 1:3. Explain behaviour.difference character factor vectors R? situation might prefer one vice versa?difference character factor vectors R? situation might prefer one vice versa?complete exercise, load dev2018.csv data R.complete exercise, load dev2018.csv data R.proportion rows complete?proportion rows complete?Store non-missing rows data.frame called dev_clean.Store non-missing rows data.frame called dev_clean.dev_clean, compute HDI following method outlined previous chapter.dev_clean, compute HDI following method outlined previous chapter.Use indexing retrieve:Use indexing retrieve:countries HDI greater 0.7 GNI per capita greater 1000010 countries largest GNI10 countries shortest life expactancy birththe development data Polandcountries Education Index higher Life Expectancy IndexThe UN categorizes countries 4 groups based HDI value - high human development \\(HDI \\geq 0.8\\), high human development \\(0.8 > HDI \\geq 0.7\\), medium human development \\(0.7 > HDI \\geq 0.55\\) low human development \\(0.55 > HDI\\). Based thresholds, create data frame called\nhdi_groups, element names \"vhigh\", \"high\", \"med\", \"low\", containing dataframe observations corresponding respective HDI group. many rows (fraction total data.frame size) levels consist ?following operation returns warning error result quite expect. ? replace first element list 1:5 sequence error doesn’t appear? Name two ways done.solutions exercises available 2020-11-12.","code":"\ndf <- data.frame(a = 1:10, b = 1:3)\nmy_list <- list(vals = 1:10, names = c(\"Jane\",\"Kate\"))\nmy_list[1] <- 1:5Warning in my_list[1] <- 1:5: number of items to replace is not a multiple of replacement length"},{"path":"exploratory.html","id":"exploratory","chapter":"4 Exploratory Data Analysis","heading":"4 Exploratory Data Analysis","text":"","code":""},{"path":"exploratory.html","id":"content-2","chapter":"4 Exploratory Data Analysis","heading":"4.1 Content","text":"","code":""},{"path":"exploratory.html","id":"what-is-exploratory-data-analysis","chapter":"4 Exploratory Data Analysis","heading":"What is exploratory data analysis?","text":"Next data cleaning, exploratory data analysis one first steps taken process analysing quantitative data kind. Essentially, refers getting overview data looking simple summary statistics plots understand distribution variable, well look particularly obvious pronounced relationships variables. one taking deductive approach, clear-cut, falsifiable hypothesis data defined upfront (higher per capita income related higher levels democracy income equality increases levels subjective well-), exploratory data analysis helps verify whether hypothetized relationship data - example applying -called Inter-Ocular Trauma Test (hits eyes, ’s !) plot. informs formal statistical analyses. also allows identify factors may important hypothesized relationship included formal statistical model. case inductive approach, exploratory data analysis allows find patterns form hypothesis furhter tested using formal statistical methods.chapter, cover basic exploratory methods can applied examine numeric categorical data. purpose use data UCI Machine Learning Repository, covers math grades achieved three years education sample students, along demographic variables 3. data download link available top course page. load , can use familiar read.csv function. Note case, sep optional argument specified \";\". can find reading argument function documentation (?read.csv) examining dataset using computer’s notepad app.","code":"\nmath <- read.csv(\"data/student/student-mat-data.csv\", sep = \";\")"},{"path":"exploratory.html","id":"first-look-at-the-data","chapter":"4 Exploratory Data Analysis","heading":"First look at the data","text":"loading data R, ’s useful get overview . first thing ’s worth look many variables many observations dataset. can seen environment browser next name data frame. can also access dimensions data (.e. many rows columns/observations variables ) dim function.can see math dataset consists 395 observations 33 variables. next useful step look dataset’s structure using str variable:lists variables dataset, names types. way, can scope dataset variables interesting analysis start thinking possible relationships might want investigate.Finally, can get basic summary statistics using summary function:lists minimum, maximum, mean quartiles numeric variables, along count missing values . concepts discussed detail next sections chapter. case factor variables, provides count level variable. also mentions number missing variable - case, can see couple NAs . starting analysis, need address - case, simply drop .","code":"\ndim(math)[1] 395  33\nstr(math)'data.frame':   395 obs. of  33 variables:\n $ school    : chr  \"GP\" \"GP\" \"GP\" \"GP\" ...\n $ sex       : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ age       : int  18 17 15 15 16 16 16 17 15 15 ...\n $ address   : chr  \"U\" \"U\" \"U\" \"U\" ...\n $ famsize   : chr  \"GT3\" \"GT3\" \"LE3\" \"GT3\" ...\n $ Pstatus   : chr  \"A\" \"T\" \"T\" \"T\" ...\n $ Medu      : int  4 1 1 4 3 4 2 4 3 3 ...\n $ Fedu      : int  4 1 1 2 3 3 2 4 2 4 ...\n $ Mjob      : chr  \"at_home\" \"at_home\" \"at_home\" \"health\" ...\n $ Fjob      : chr  \"teacher\" \"other\" \"other\" \"services\" ...\n $ reason    : chr  \"course\" \"course\" \"other\" \"home\" ...\n $ guardian  : chr  \"mother\" \"father\" \"mother\" \"mother\" ...\n $ traveltime: int  2 1 1 1 1 1 1 2 1 1 ...\n $ studytime : int  2 2 2 3 2 2 2 2 2 2 ...\n $ failures  : int  0 0 3 0 0 0 0 0 0 0 ...\n $ schoolsup : chr  \"yes\" \"no\" \"yes\" \"no\" ...\n $ famsup    : chr  \"no\" \"yes\" \"no\" \"yes\" ...\n $ paid      : chr  \"no\" \"no\" \"yes\" \"yes\" ...\n $ activities: chr  \"no\" \"no\" \"no\" \"yes\" ...\n $ nursery   : chr  \"yes\" \"no\" \"yes\" \"yes\" ...\n $ higher    : chr  \"yes\" \"yes\" \"yes\" \"yes\" ...\n $ internet  : chr  \"no\" \"yes\" \"yes\" \"yes\" ...\n $ romantic  : chr  \"no\" \"no\" \"no\" \"yes\" ...\n $ famrel    : int  4 5 4 3 4 5 4 4 4 5 ...\n $ freetime  : int  3 3 3 2 3 4 4 1 2 5 ...\n $ goout     : int  4 3 2 2 2 2 4 4 2 1 ...\n $ Dalc      : int  1 1 2 1 1 1 1 1 1 1 ...\n $ Walc      : int  1 1 3 1 2 2 1 1 1 1 ...\n $ health    : int  3 3 3 5 5 5 3 1 1 5 ...\n $ absences  : int  6 4 10 2 4 10 0 6 0 0 ...\n $ G1        : int  5 5 7 15 6 15 12 6 16 14 ...\n $ G2        : int  6 5 8 14 10 15 12 5 18 15 ...\n $ G3        : int  6 6 10 15 10 15 11 6 19 15 ...\nsummary(math)    school              sex                 age         address            famsize         \n Length:395         Length:395         Min.   :15.0   Length:395         Length:395        \n Class :character   Class :character   1st Qu.:16.0   Class :character   Class :character  \n Mode  :character   Mode  :character   Median :17.0   Mode  :character   Mode  :character  \n                                       Mean   :16.7                                        \n                                       3rd Qu.:18.0                                        \n                                       Max.   :22.0                                        \n                                                                                           \n   Pstatus               Medu            Fedu           Mjob               Fjob          \n Length:395         Min.   :0.000   Min.   :0.000   Length:395         Length:395        \n Class :character   1st Qu.:2.000   1st Qu.:2.000   Class :character   Class :character  \n Mode  :character   Median :3.000   Median :2.000   Mode  :character   Mode  :character  \n                    Mean   :2.749   Mean   :2.522                                        \n                    3rd Qu.:4.000   3rd Qu.:3.000                                        \n                    Max.   :4.000   Max.   :4.000                                        \n                                                                                         \n    reason            guardian           traveltime      studytime        failures     \n Length:395         Length:395         Min.   :1.000   Min.   :1.000   Min.   :0.0000  \n Class :character   Class :character   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:0.0000  \n Mode  :character   Mode  :character   Median :1.000   Median :2.000   Median :0.0000  \n                                       Mean   :1.448   Mean   :2.031   Mean   :0.3342  \n                                       3rd Qu.:2.000   3rd Qu.:2.000   3rd Qu.:0.0000  \n                                       Max.   :4.000   Max.   :4.000   Max.   :3.0000  \n                                                       NA's   :3                       \n  schoolsup            famsup              paid            activities          nursery         \n Length:395         Length:395         Length:395         Length:395         Length:395        \n Class :character   Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                                               \n                                                                                               \n                                                                                               \n                                                                                               \n    higher            internet           romantic             famrel         freetime         goout      \n Length:395         Length:395         Length:395         Min.   :1.000   Min.   :1.000   Min.   :1.000  \n Class :character   Class :character   Class :character   1st Qu.:4.000   1st Qu.:3.000   1st Qu.:2.000  \n Mode  :character   Mode  :character   Mode  :character   Median :4.000   Median :3.000   Median :3.000  \n                                                          Mean   :3.944   Mean   :3.235   Mean   :3.104  \n                                                          3rd Qu.:5.000   3rd Qu.:4.000   3rd Qu.:4.000  \n                                                          Max.   :5.000   Max.   :5.000   Max.   :5.000  \n                                                                                          NA's   :1      \n      Dalc            Walc           health         absences            G1              G2       \n Min.   :1.000   Min.   :1.000   Min.   :1.000   Min.   : 0.000   Min.   : 3.00   Min.   : 0.00  \n 1st Qu.:1.000   1st Qu.:1.000   1st Qu.:3.000   1st Qu.: 0.000   1st Qu.: 8.00   1st Qu.: 9.00  \n Median :1.000   Median :2.000   Median :4.000   Median : 4.000   Median :11.00   Median :11.00  \n Mean   :1.481   Mean   :2.287   Mean   :3.554   Mean   : 5.709   Mean   :10.91   Mean   :10.71  \n 3rd Qu.:2.000   3rd Qu.:3.000   3rd Qu.:5.000   3rd Qu.: 8.000   3rd Qu.:13.00   3rd Qu.:13.00  \n Max.   :5.000   Max.   :5.000   Max.   :5.000   Max.   :75.000   Max.   :19.00   Max.   :19.00  \n                 NA's   :1                                        NA's   :1                      \n       G3       \n Min.   : 0.00  \n 1st Qu.: 8.00  \n Median :11.00  \n Mean   :10.42  \n 3rd Qu.:14.00  \n Max.   :20.00  \n                \nmath <- math[complete.cases(math), ]"},{"path":"exploratory.html","id":"numeric-vs-categorical-variables","chapter":"4 Exploratory Data Analysis","heading":"Numeric vs categorical variables","text":"","code":""},{"path":"exploratory.html","id":"numeric-variables","chapter":"4 Exploratory Data Analysis","heading":"Numeric variables","text":"","code":""},{"path":"exploratory.html","id":"histograms","chapter":"4 Exploratory Data Analysis","heading":"Histograms","text":"simplest often powerful way examine single numeric variable use histogram. Histogram divides variable ranges equal size called bins. bin represented bar, height corresponds count/proportion observations falling range. main difference histogram bar chart histogram breaks bars, variable describes assumed continuous, discrete. Let’s examine two numeric variables math dataset - age absences (total absent hours recorded teacher student) using histograms. histogram created using hist function:cases, can see lowest values frequent. example, second histogram can read 250 395 students samples absent 0-5 hours school year.","code":"\nhist(math$age, breaks = length(unique(na.omit(math$age))))\nhist(math$absences)"},{"path":"exploratory.html","id":"mean","chapter":"4 Exploratory Data Analysis","heading":"Mean","text":"Mean (aka average) simplest statistic describing numeric variable - simply sum variable/vector divided length. R, can calculate mean variable using mean function. example, let’s examine average number absences sample:done age returns value:removed missing values (NA's) start, command worked returned NA. ever come across issue, reminder need something missing data. just wish circumvent problem time , call:specify argument na.rm(remove NA values) TRUE.can also use trim argument specify fraction observations removed end sorted variables calculating mean. makes estimate mean robust potentially large unrepresentative values affecting calculated value - -called outliers, discussed extensively section quantiles. Note specifying trim argument 0.1 doesn’t seem change mean age significantly:However, case absences changes value average absences quite lot. Can think reason ? Take look histograms variables.","code":"\nsum(math$absences)/nrow(math)[1] 5.763636\nmean(math$absences)[1] 5.763636\nmean(math$age)[1] 16.67013\nmean(math$age, na.rm = TRUE)[1] 16.67013\nmean(math$age, na.rm = TRUE, trim = 0.1)[1] 16.59871\nmean(math$absences, trim = 0.1)[1] 4.278317"},{"path":"exploratory.html","id":"variance-and-standard-deviation","chapter":"4 Exploratory Data Analysis","heading":"Variance and standard deviation","text":"mean offers good description central tendency variable (.e. value expect see often), describing variable just mean can misleading. example, consider values -10000, 20, 10000 15, 20, 25. cases mean :However, misleading say variables similar. try describe difference computing average distance value mean:However, results 0, since negative positive values example cancel . avoid , can measure variance, calculates mean sum squared distances value variable mean. Since distance squared (always positive), positive negative values cancel .can see captures difference two vectors.can calculate variance simple shortcut R, var function:Note gives us different results variance computed hand. calculate population wariance divide number observations population (length vector), N. , variance calculated “manually” equivalent :Instead, var() function calculates sample variance, divide sum squared distances mean \\(N-1\\). dividing sample N tends underestimate variance population. mathematical reasons behind clearly outlined article. , can “manually” arrive equivalent estiamte one obtained using var function :can apply variance function absence age, see spread:One problem arising using variance describe data units aren’t interpretable, since squared. Therefore, saying variance absence time 64 squared hours doesn’t sound intuitive. avoid , usually use use standard deviation practice, simply square root variance. taking square root return variable original units. standard deviation variable calculated using sd function:ethat including na.rm = TRUE option illsutrative purposes , since remove missing values, earlier.can know compare standard deviation mean variables:can clearly seen hours students’ absence variability students’ ages. makes intuitive sense, since sample consists students roughly age group (easiest way can see running unique(math$age)). time, students differ match total hours absence. explains trimmed mean different overall mean case absences, yet quite similar age.can use widget see varying standard deviation mean affects distribution variable (case normally distributed random variable). Note need active internet connection app load.","code":"\nx <- c(15, 20, 25)\ny <- c(-985, 20, 1025)\nmean(x) == mean(y)[1] TRUE\nmean(x - mean(x))[1] 0\nmean(y - mean(y))[1] 0\nmean((x - mean(x))^2)[1] 16.66667\nmean((y - mean(y))^2)[1] 673350\nvar(x)[1] 25\nvar(y)[1] 1010025\nsum((x - mean(x))^2)/length(x)[1] 16.66667\nmean((x - mean(x))^2)[1] 16.66667\nsum((x - mean(x))^2)/(length(x) - 1) == var(x)[1] TRUE\nvar(math$age, na.rm = TRUE)[1] 1.622673\nvar(math$absences)[1] 65.31117\nsd(math$age, na.rm = TRUE)[1] 1.273842\nsd(math$age, na.rm = TRUE) == sqrt(var(math$age, na.rm = TRUE))[1] TRUE\nwith(math, c(mean = mean(age, na.rm = TRUE), \n  sd = sd(age, na.rm = TRUE)))     mean        sd \n16.670130  1.273842 \nwith(math, c(mean = mean(absences, na.rm = TRUE), \n  sd = sd(absences, na.rm = TRUE)))    mean       sd \n5.763636 8.081533 "},{"path":"exploratory.html","id":"quantiles","chapter":"4 Exploratory Data Analysis","heading":"Quantiles","text":"final statistic going discuss quantile. Quantiles allow us get better grasp distribution data. Essentially, quantiles cut points divide variable intervals equal sizes. example, deciles 10-quantiles, dividing variable 10 ranges. example 8th decile variable value greater 80% values variable. R can obtain arbitrary quantile using quantile function, specifying proportion cutpoints probs argument.example, can see 90% values variable absences lower 14. probs argument can either scalar vector, can obtain multiple quantiles . example example obtain -called quartiles (4-quantiles).get deciles :can visualize using histogram:","code":"\nquantile(math$absences, probs = 0.9)90% \n 14 \nquantile(math$absences, probs = c(0, .25, .5, .75, 1)) #quartiles  0%  25%  50%  75% 100% \n   0    0    4    8   75 \nquantile(math$absences, probs = seq(0, 1, by = 0.1))  0%  10%  20%  30%  40%  50%  60%  70%  80%  90% 100% \n   0    0    0    2    2    4    4    6   10   14   75 "},{"path":"exploratory.html","id":"median","chapter":"4 Exploratory Data Analysis","heading":"Median","text":"median specific quantile - 50th percentile variable, .e. midpoint variable’s distribution. opposed mean, ’s affected outlying values. Large differences mean meadian often evidence skew variable’s distribution.","code":""},{"path":"exploratory.html","id":"outliers","chapter":"4 Exploratory Data Analysis","heading":"Outliers","text":"Finally, mentioned earlier, quantiles particularly useful comes identifying outliers. Outliers observations extreme values, lying far majority values dataset. cases may results data collection error, others simply rare examples variable interest taking high low value. Outliers can often extert high levarage given statistic measuring (mean), removing may sometimes change results analysis significantly. Thus, often worth removing re-running analysis make sure ’s affected severly small number observations extreme values. Note say outliers always removed disregarded - contrary , observations outlying values treated extra care role analyst examine values extreme possible implications analysis.Quantiles can used find outlying observations - example, looking 0.001 0.999 cutpoints, considering values outiers.","code":""},{"path":"exploratory.html","id":"box-plots","chapter":"4 Exploratory Data Analysis","heading":"Box plots","text":"Box plots commonly used visualize distribution variable. , use boxplot function plot boxplot age variable math dataset.box middle plot corresponds inter-quartile range variable (IQR) - range 1st 3rd quartile variable (equivalent value range 25th 75th percentile). thick line middle corrsponds variable’s median (2nd quartile/50th percentile). ‘whiskers’ (.e. horizontal lines connected dashed line end box) correspond minimum maximum values variable. maximum defined largest value variable smaller number 1.5 IQR third quartile minimum lowest value variable larger number 1.5 IQR first quartile. Anything /whiskers numbers considered outlier marked dot. example can see one observation outlier, lying significantly upper whisker boxplot. can identify value plugging formula upper whisker (#3rd quartile + \\(1.5IQR\\)) finding value lies .useful many circumstances, box plots can deceiving, two similarily looking box plots can represent different disttributions. ’s always useful look variable’s histogram well. can seen example :","code":"\nboxplot(math$age)\nmaximum <- quantile(math$age, 0.75, na.rm = TRUE, names = FALSE) + \n  1.5 * IQR(math$age, na.rm = TRUE)\nmath$age[which(math$age > maximum)][1] 22"},{"path":"exploratory.html","id":"scatter-plots","chapter":"4 Exploratory Data Analysis","heading":"Scatter plots","text":"Finally, good way explore relationship two numeric variables visually scatter plots. Scatter plots represent observation marker, x-axis represnting value one variable y-axis another. Scatter plots simply created using plot function.example , can see ’s positive relationship student’s grade first year grade second year. plot sufficient make strong empirical claims, usually valuable first step finding statistical regularities dataset. formal ways measuring association variables discussed sections statisical association linear regression.","code":"\nplot(math$G1, math$G2)"},{"path":"exploratory.html","id":"categorical-variables","chapter":"4 Exploratory Data Analysis","heading":"Categorical variables","text":"","code":""},{"path":"exploratory.html","id":"cross-tabulation","chapter":"4 Exploratory Data Analysis","heading":"Cross-tabulation","text":"Categorical variables often best described frequency tables, provide counts number occurrences level categorical variable.Additionally, can transform table proportions, rather frequencies, using prop.table function transform output table.can also convert table bar plot, using barplot function.table function can also used cross-tabulation - creating table summarizing count observations overlap two categories. example look relationship reason choosing particular school paid classes attendance.appears students chose school course preference less likely attend extra paid classes students choosing school reasons.can made apparent substitute frequencies proportions:Note case, proportions calculated respect total count participants (.e. add 1). comparison purposes, might useful look proportion respect total categories. can specified margin argument. setting 1, calculate proportions respect row margins, .e. divide counts individuals paid variable total category reason variable.analogy, margin = 2 leads division column margins, .e. sums categories paid variable.","code":"\ntable(math$sex)\n  F   M \n203 182 \nprop.table(table(math$sex))\n        F         M \n0.5272727 0.4727273 \nbarplot(table(math$Mjob))\nbarplot(prop.table(table(math$Mjob)),\n        names.arg = c(\"At home\", \"Health\", \"Other\", \"Services\", \"Teacher\"))\ntable(math$reason, math$paid)            \n             no yes\n  course     92  47\n  home       52  56\n  other      16  20\n  reputation 50  52\nprop.table(table(math$reason, math$paid))            \n                     no        yes\n  course     0.23896104 0.12207792\n  home       0.13506494 0.14545455\n  other      0.04155844 0.05194805\n  reputation 0.12987013 0.13506494\nprop.table(table(math$reason, math$paid), margin = 1)            \n                    no       yes\n  course     0.6618705 0.3381295\n  home       0.4814815 0.5185185\n  other      0.4444444 0.5555556\n  reputation 0.4901961 0.5098039\nprop.table(table(math$reason, math$paid), margin = 2)            \n                     no        yes\n  course     0.43809524 0.26857143\n  home       0.24761905 0.32000000\n  other      0.07619048 0.11428571\n  reputation 0.23809524 0.29714286"},{"path":"exploratory.html","id":"customizing-visualizations","chapter":"4 Exploratory Data Analysis","heading":"Customizing visualizations","text":"previous sections, discussed basic tools data visualizations R, histograms, scatter plots, box plots bar charts. R base graphics allows user create powerful great-looking visualizations. However achieving can quite complicated. , dedicated called ggplot2 created enable creating good-looking informative visualziations much simpler user interface. data visualization chapter covers detail. However, case wanted start preparing visualizations purposes exploratory data analysis, might find tips useful:","code":""},{"path":"exploratory.html","id":"changing-axis-labels","chapter":"4 Exploratory Data Analysis","heading":"Changing axis labels","text":"case every plot R can change axis labels using xlab ylab arguments:can also add title specifying main argument:color objects plot can altered using col argument:can also specified character vector, different color point:make informative, can also add legend using legend function:can also change limits axes, specifying xlim ylim arguments","code":"\nplot(math$G1, math$G2, xlab = \"Grade in term 1\", ylab = \"Grade in term 2\")\nplot(math$G1, math$G2, \n     xlab = \"Grade in term 1\", ylab = \"Grade in term 2\",\n     main = \"Student grades\")\nplot(math$G1, math$G2, \n     xlab = \"Grade in term 1\", ylab = \"Grade in term 2\",\n     main = \"Student grades\",\n     col = \"red\")\ncol_gender <- rep(\"red\", nrow(math))\ncol_gender[which(math$sex == \"F\")] <- \"blue\"\nplot(math$G1, math$G2, \n     xlab = \"Grade in term 1\", ylab = \"Grade in term 2\",\n     main = \"Student grades\",\n     col = col_gender)\ncol_gender <- rep(\"red\", nrow(math))\ncol_gender[which(math$sex == \"F\")] <- \"blue\"\nplot(math$G1, math$G2, \n     xlab = \"Grade in term 1\", ylab = \"Grade in term 2\",\n     main = \"Student grades\",\n     col = col_gender)\nlegend('bottomright', \n       legend = c('Female', 'Male'),\n       col = c('blue', 'red'), pch = 1)\ncol_gender <- rep(\"red\", nrow(math))\ncol_gender[which(math$sex == \"F\")] <- \"blue\"\nplot(math$G1, math$G2, \n     xlab = \"Grade in term 1\", ylab = \"Grade in term 2\",\n     main = \"Student grades\", xlim = c(0, 30), ylim = c(0, 30))"},{"path":"exploratory.html","id":"summary-2","chapter":"4 Exploratory Data Analysis","heading":"4.2 Summary","text":"Exploratory data analysis essential first step quantitative data analysis. provides overview data allows select variables interest, verify first intuitions data explore possible relationships. Functions useful first overview include str() summary.Exploratory data analysis essential first step quantitative data analysis. provides overview data allows select variables interest, verify first intuitions data explore possible relationships. Functions useful first overview include str() summary.Histograms useful way summarizing variable’s distribution representing bars equal width (.e. equal value ranges), height corresponds number/proportion values within given range.Histograms useful way summarizing variable’s distribution representing bars equal width (.e. equal value ranges), height corresponds number/proportion values within given range.Mean, variance standard deviation commonly used measures numeric data. first refers likely value variable, later two - variable’s spread. advantage standard deviation variance ’s expressed units data. can obtain R using mean, var sd functions.Mean, variance standard deviation commonly used measures numeric data. first refers likely value variable, later two - variable’s spread. advantage standard deviation variance ’s expressed units data. can obtain R using mean, var sd functions.Quantiles cutpoints divide numeric variable ranges equal proportions. can calculate arbitrary quantiles using quantile function.Quantiles cutpoints divide numeric variable ranges equal proportions. can calculate arbitrary quantiles using quantile function.Box plots summarize distribution variable presenting interquartile range box, median tick line middle, whiskers extending maximum minimum dots marking outliers.Box plots summarize distribution variable presenting interquartile range box, median tick line middle, whiskers extending maximum minimum dots marking outliers.Scatter plots useful explore relationship two numerical variables. can create using plot function.Scatter plots useful explore relationship two numerical variables. can create using plot function.Categorical variables describe data can classified number discrete categories. can summarize one categorical variable relationship two categorical variables using frequency tables, available R table function. prop.table function can normalize frequencies table cells proportions. can also wrap table barplot.Categorical variables describe data can classified number discrete categories. can summarize one categorical variable relationship two categorical variables using frequency tables, available R table function. prop.table function can normalize frequencies table cells proportions. can also wrap table barplot.","code":""},{"path":"exploratory.html","id":"functions-list-2","chapter":"4 Exploratory Data Analysis","heading":"Functions list","text":"","code":""},{"path":"exploratory.html","id":"exercises-2","chapter":"4 Exploratory Data Analysis","heading":"4.3 Exercises","text":"Match histograms boxplots :variable x contains numbers [1, 20, 4, 50, 30, 40]. Compute IQR. values whiskers box plot? () outliers? Confirm calculations plotting box plotThe variable x contains numbers [1, 20, 4, 50, 30, 40]. Compute IQR. values whiskers box plot? () outliers? Confirm calculations plotting box plotLoad student-por.csv R session. data describes grades obtained students Portugeese class consists variables similar math dataset. Conduct EDA preforming following steps:Load student-por.csv R session. data describes grades obtained students Portugeese class consists variables similar math dataset. Conduct EDA preforming following steps:Examine variables dataset, types, distribution first 5 observations.Examine variables dataset, types, distribution first 5 observations.Get proportion missing observations (overall variable) remove observations missing values.Get proportion missing observations (overall variable) remove observations missing values.Use tools choice get analyze distribution age, absence grade variables. Identify outliers cases. variables compare couterparts math dataset analyzed chapter?Use tools choice get analyze distribution age, absence grade variables. Identify outliers cases. variables compare couterparts math dataset analyzed chapter?many girls boys por dataset? Visualize using bar plot.many girls boys por dataset? Visualize using bar plot.solutions exercises available 2020-11-12.","code":"\npor <- read.csv(\"data/student/student-por.csv\", sep = \";\")"},{"path":"programming.html","id":"programming","chapter":"5 Key Programming Concepts","heading":"5 Key Programming Concepts","text":"","code":""},{"path":"programming.html","id":"content-3","chapter":"5 Key Programming Concepts","heading":"5.1 Content","text":"make data analysis efficient, crucial understand crucial programming concepts. first part section discuss loops statements. -called “control flow statements”, common almost programming languages. second part discuss creation basic usage functions. Finally, third part go sapply() function family, common tool used R apply functions objects multiple times.","code":""},{"path":"programming.html","id":"control-flow-statements","chapter":"5 Key Programming Concepts","heading":"Control flow statements","text":"","code":""},{"path":"programming.html","id":"for-loops","chapter":"5 Key Programming Concepts","heading":"For loops","text":"loops essentially way telling programming language “perform operations ask N times”. loop R beginns () statement, followed opening curly brace { line - esentially opening -loop. , usually new line, place code want execute. , last line close loop another curly brace }. can execute loop placing cursor either statement (first line) closing brace (last line) executing code. , can see loop printing string \"Hello world!\" 5 timesThe statements variable sequentially take values object (usually vector) specified right hand side keyword. majority cases, object sequence integers, example , takes values element vector 1:5 prints .loop used add constant element vector:However, R redundant, vectorization (see section vectors chapter 2). statement os equivalent :simpler, also efficient.Another, practical aplication loop examine columns data frame missing values, :, can see 0 misisng values country name, 1 missing value expected years schooling variable , 3 missing values gni life expectancy 5 missing values mean years schooling.bit useful previous example, R still offers shorthand method problems, discussed detail last part chapter. general, due phenomena vectorization, loops rarely used simple data analysis R. However, core element programming , therefore ’s important understand . fact, vectorization made possible loops used R background - simply faster efficient versions.","code":"\nfor(i in 1:5) {\n  print(\"Hello world\")\n}[1] \"Hello world\"\n[1] \"Hello world\"\n[1] \"Hello world\"\n[1] \"Hello world\"\n[1] \"Hello world\"\nfor(i in 1:5) {\n  print(i)\n}[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\nx <- c(4, 5, 1, 2, 9, 8, 0, 5, 3)\nx[1] 4 5 1 2 9 8 0 5 3\n#for all integers between 1 and length of vector x:\nfor(i in 1:length(x)) { \n  x[i] <- x[i] + 5\n}\nx[1]  9 10  6  7 14 13  5 10  8\nx <- c(4, 5, 1, 2, 9, 8, 0, 5, 3)\nx + 5[1]  9 10  6  7 14 13  5 10  8\ndev <- read.csv(\"data/un_data/dev2018.csv\",\n                stringsAsFactors = FALSE)\nmissing <- numeric() #create empty numeric vector\nfor (i in 1:length(dev)){\n  missing[i] <- sum(is.na(dev[,i])) #get sum of missing for ith column\n  names(missing)[i] <- names(dev)[i] #name it with ith column name\n}\nmissingcountry     eys     gni    lexp     mys \n      0       1       3       3       5 "},{"path":"programming.html","id":"if-statements","chapter":"5 Key Programming Concepts","heading":"If statements","text":"statements another crucial programming concept. essentially allow performing computation conditionally logical statement. words, depending logical expression operation performed . loops R constructed following way:logical_expression must expression evaluates logical value, example X > 5, country == \"France\" .na(x). operations performed logical_expression evaluates TRUE. simples possible example beIf naturally complemented else clause, .e. operations performed otherwise. general form statement :case, R first checks logical_expression evaluates TRUE, doesn’t, performs other_operations. example:Finally, else allows provide another statement evaluated. general form statement :, R first checks logical_statement, ’s FALSE proceeds check other_logical_statement. second one TRUE performs other_operation ’s FALSE proceeds perform yet_another_operation. extension previous example:-ELSE statments can used conditionally replace values. example, suppose want create variable 1 country France 0 otherwise. :, vectorization, R offers shorthand , ifelse() function:look documentation ?ifelse, can see takes three arguments - test, yes . test argument logical condition - logical_statement , small subtle difference can evaluate logical vector rather one single logical value. yes argument value returned function test TRUE argument returned test FALSE. can fully see example :","code":"\nif (logical_expression) {\n  operations\n}\nx <- 2\nif (x > 0) {\n  print(\"the value is greater than 0\")\n}[1] \"the value is greater than 0\"\nx <- -2\nif (x > 0) {\n  print(\"the value is greater than 0\")\n}\nif (logical_expression) {\n  operations\n} else {\n  other_operations\n}\nx <- -2\nif (x > 0) {\n  print(\"the value is greater than 0\")\n} else {\n  print(\"the value is less or equal than 0\")\n}[1] \"the value is less or equal than 0\"\nif (logical_statement) { \n  operation\n} else if (other_logical_statement) {\n  other_operation\n} else {\n  yet_another_operation\n}\nx <- 2\nif (x > 0) {\n  print(\"The value is positive\")\n} else if (x < 0) {\n  print(\"The value is negative\") \n} else {\n  print(\"The value is 0\")\n}[1] \"The value is positive\"\ndev$france <- 0\nfor (i in 1:nrow(dev)) {\n  if (dev$country[i] == \"France\") {\n    dev$france[i] <- 1\n  }\n}\n\ndev$france[dev$country == \"France\"][1] 1\ndev$france <- ifelse(dev$country == \"France\", 1, 0)\ndev$france[dev$country == \"France\"][1] 1\nifelse(c(TRUE, FALSE, FALSE, TRUE), \"yes\", \"no\")[1] \"yes\" \"no\"  \"no\"  \"yes\"\nifelse(c(TRUE, FALSE, FALSE, TRUE), 1, 0)[1] 1 0 0 1"},{"path":"programming.html","id":"functions","chapter":"5 Key Programming Concepts","heading":"Functions","text":"R known functional programming language - already seen, almost operations performed done using functions. also possible create , custom functions combining functions data structures. done using function() keyword. general syntax function looks follows:R object, can use almost name instead function_name. Arguments separeted commas (example arg1, arg2) - objects pass function perform arbitrary operations. , arguments can arbitrary names, need use within function consistently. Finally, functions return value - last object called within function (output example).creating function can run , exactly way R’s built-functions. simple example return number missing values object:also implement summary statistics function, similar describe() discussed previous chapter:Let’s walk function Given vector x, function :\n1. Checks whether x numeric vector. , returns list ’s mean, standard deviation interquartile range.\n2. Else, checks x character vector. , returns list containng length average number characters.\n3. Else, checks x factor. returns list containing length average number character.can see works :","code":"\nfunction_name <- function(arg1, arg2) {\n  output <- operations(arg1, arg2)\n  output\n}\ncount_na <- function(x) {\n  sum(is.na(x))\n}\n\ncount_na(dev$mys)[1] 5\nsummary_stats <- function(x) {\n  if (is.numeric(x)) {\n    list(Mean = mean(x, na.rm = TRUE), \n                SD = sd(x, na.rm = TRUE), \n                IQR = IQR(x, na.rm = TRUE))\n  } else if (is.character(x)) {\n    list(Length = length(x), \n                  Mean_Nchar = mean(nchar(x)))\n  } else if (is.factor(x)) {\n  list(Length = length(x), \n       Nlevels  = length(levels(x)))\n  }\n}\nsummary_stats(c(1, 2, 3, 10))$Mean\n[1] 4\n\n$SD\n[1] 4.082483\n\n$IQR\n[1] 3\nsummary_stats(dev$country)$Length\n[1] 195\n\n$Mean_Nchar\n[1] 9.902564\nsummary_stats(as.factor(dev$country))$Length\n[1] 195\n\n$Nlevels\n[1] 195"},{"path":"programming.html","id":"keyword-arguments","chapter":"5 Key Programming Concepts","heading":"Keyword arguments","text":"Many functions used R come -called default arguments - already mentioned sorting. defining functions, can make use functionality well. example, count_na example can modified following way:proportion argument controls whether function returns number NAs value proportion entire vector:couple reasons functions frequently applied analyzing data:\n1. avoid repetition - often, need perform operation repeatedly - sometimes dataframe tens hunderds columns even multiple data frames. avoid re-writing code (always increases chance error occuring).\n2. enhance clarity - perform long complicated series operations dataset, ’s often much easier break functions. need come back code long time, often much easier see recode_missing_values(data) appear code, record_missing_values function defined somewhere else, don’t need go code step step, understand particular functions return.\n3 improve performance - operations ’ve seen R take fractions seconds, larger data can often lead longer computation times. Functions can combined tools make computation elegant quicker - methods discussed next section.","code":"\ncount_na <- function(x, proportion = TRUE) {\n  num_na <- sum(is.na(x))\n  if (proportion == TRUE) {\n    num_na/length(x)\n  } else {\n    num_na\n  }\n}\ncount_na(dev$gni)[1] 0.01538462\ncount_na(dev$gni, proportion = TRUE) #same as above[1] 0.01538462\ncount_na(dev$gni, proportion = FALSE)[1] 3"},{"path":"programming.html","id":"sapply","chapter":"5 Key Programming Concepts","heading":"Sapply","text":"Recall code used check column data frame missingness loops section:re-write using new knowledge functions, :may look bit fancy, fact code used perform operation doesn’t differ much terms clarity. exact result can achieved using sapply() function. sapply() takes two arguments - R object, vector data frame function. , applies function element object (.e. value case vectors, column/variable case data frames).result exactly previous case. sapply() used count_na function columns dev dataset.using short, simple functions, sapply() can even concise, can defined function without giving name. example , instead defining count_na separately, define directly within sapply() call (.e. inside parentheses). yields result.Consider function . expect return? Try going element code separately. can check rowSums command works typing ?rowSums R console.function takes vector input computes three quantiles values - 25%, 50%, 75%. may recall previous chapter quantiles cut points divide variable ranges equal proportions data set. resulting quantiles vector consists three values, corresponding thre three quantiles. use sapply three values compare value x vector. result, obtain 3 x n array, n length x. values x get three logical values. TRUE corresponding value x larger quantile FALSE corresponding value x lower quantile. can sum results row, using rowSums. final result vector values 0, 1 2. value 0 corresponding value x less quartiles, 1 greater equal .25, 2 greater equal 0.5 3 greater equal . finally add 1 , correspond true quartile numbers (1st quartile, rather 0th quartile, etc).can use split function, takes data frame vector input splits data frame several parts, value splitting variable. result, obtain dev_split dataset, stores 4 data frames, countries respective quantile expected years schooling.can look descriptive statistics quartiles using:working R looking help online, may stumble upon variants sapply() functions. Essentially, R functions apply name serve purpose - applying function element object. lapply() less user friendy version sapply(), always returns list, vector. vapply() forces user determine type output, makes behaviour predictible slightly faster. tapply() applies function data frame group determined another variable - similar procedure using split() sapply(), less steps.","code":"\nmissing <- numeric() #create empty numeric vector\nfor (i in 1:length(dev)){\n  missing[i] <- sum(is.na(dev[,i])) #get sum of missing for ith column\n  names(missing)[i] <- names(dev)[i] #name it with ith column name\n}\ncount_na <- function(x) {\n  sum(is.na(x))\n}\n\nmissing <- numeric()\nfor (i in 1:length(dev)) {\n  missing[i] <- count_na(dev[,i])\n  names(missing)[i] <- names(dev)[i]\n}\nmissingcountry     eys     gni    lexp     mys  france \n      0       1       3       3       5       0 \nsapply(dev, count_na)country     eys     gni    lexp     mys  france \n      0       1       3       3       5       0 \nsapply(dev, function(x) sum(is.na(x)))country     eys     gni    lexp     mys  france \n      0       1       3       3       5       0 \nquartile <- function(x) {\n  quantiles <- quantile(x, c(0.25, 0.5, 0.75), na.rm = TRUE)\n  comparisons <- sapply(quantiles, function(y) y <= x)\n  rowSums(comparisons) + 1\n}\ndev_split <- split(dev, quartile(dev$eys))\nhead(dev_split[[1]])                    country  eys  gni lexp mys france\n1               Afghanistan 10.1 1746 64.5 3.9      0\n14               Bangladesh 11.2 4057 72.3 6.1      0\n27             Burkina Faso  8.9 1705 61.2 1.6      0\n33 Central African Republic  7.6  777 52.8 4.3      0\n34                     Chad  7.5 1716 54.0 2.4      0\n38                  Comoros 11.2 2426 64.1 4.9      0\nsapply(dev_split, summary)$`1`\n   country               eys              gni             lexp            mys            france \n Length:47          Min.   : 5.000   Min.   :  777   Min.   :52.80   Min.   :1.600   Min.   :0  \n Class :character   1st Qu.: 8.700   1st Qu.: 1611   1st Qu.:60.80   1st Qu.:3.700   1st Qu.:0  \n Mode  :character   Median : 9.700   Median : 2318   Median :64.30   Median :4.850   Median :0  \n                    Mean   : 9.415   Mean   : 3579   Mean   :63.89   Mean   :4.861   Mean   :0  \n                    3rd Qu.:10.550   3rd Qu.: 3731   3rd Qu.:67.00   3rd Qu.:6.075   3rd Qu.:0  \n                    Max.   :11.200   Max.   :17796   Max.   :75.10   Max.   :9.800   Max.   :0  \n                                     NA's   :1                       NA's   :1                  \n\n$`2`\n   country               eys             gni              lexp            mys             france \n Length:50          Min.   :11.30   Min.   :   660   Min.   :58.90   Min.   : 3.100   Min.   :0  \n Class :character   1st Qu.:11.80   1st Qu.:  4232   1st Qu.:68.03   1st Qu.: 6.500   1st Qu.:0  \n Mode  :character   Median :12.30   Median :  6903   Median :71.50   Median : 7.850   Median :0  \n                    Mean   :12.22   Mean   : 10788   Mean   :70.39   Mean   : 7.869   Mean   :0  \n                    3rd Qu.:12.70   3rd Qu.: 11578   3rd Qu.:73.83   3rd Qu.: 9.475   3rd Qu.:0  \n                    Max.   :13.00   Max.   :110489   Max.   :80.10   Max.   :11.600   Max.   :0  \n                                                     NA's   :2       NA's   :2                   \n\n$`3`\n   country               eys             gni             lexp            mys             france \n Length:47          Min.   :13.10   Min.   : 3317   Min.   :63.90   Min.   : 5.500   Min.   :0  \n Class :character   1st Qu.:13.65   1st Qu.:10694   1st Qu.:74.53   1st Qu.: 8.600   1st Qu.:0  \n Mode  :character   Median :14.30   Median :14356   Median :76.05   Median : 9.900   Median :0  \n                    Mean   :14.19   Mean   :22644   Mean   :75.45   Mean   : 9.883   Mean   :0  \n                    3rd Qu.:14.70   3rd Qu.:26054   3rd Qu.:76.88   3rd Qu.:11.200   3rd Qu.:0  \n                    Max.   :15.10   Max.   :99732   Max.   :82.10   Max.   :12.600   Max.   :0  \n                                    NA's   :1       NA's   :1       NA's   :1                   \n\n$`4`\n   country               eys             gni             lexp            mys            france    \n Length:50          Min.   :15.20   Min.   : 9570   Min.   :72.40   Min.   : 7.70   Min.   :0.00  \n Class :character   1st Qu.:15.68   1st Qu.:24906   1st Qu.:77.25   1st Qu.:10.43   1st Qu.:0.00  \n Mode  :character   Median :16.35   Median :34918   Median :81.20   Median :12.25   Median :0.00  \n                    Mean   :16.79   Mean   :35322   Mean   :79.66   Mean   :11.55   Mean   :0.02  \n                    3rd Qu.:17.40   3rd Qu.:45698   3rd Qu.:82.38   3rd Qu.:12.70   3rd Qu.:0.00  \n                    Max.   :22.10   Max.   :83793   Max.   :84.70   Max.   :14.10   Max.   :1.00  "},{"path":"programming.html","id":"summary-3","chapter":"5 Key Programming Concepts","heading":"5.2 Summary","text":"-loops allow perform operation multiple times range values one variable. constructed using (vector). use R relatively rare due vectorization.-statements control whether na operation performed depending value logical condition. conditionally modify values vectors, use ifelse(test, yes, )-Functions can created user combine multiple operations shorter pieces code, allows avoid repetition. take one many arguments return one value.-sapply() function used applying function element vector column data frame. may find versions , apply name, perform task, slight alteration.","code":""},{"path":"programming.html","id":"functions-list-3","chapter":"5 Key Programming Concepts","heading":"Functions list","text":"","code":""},{"path":"programming.html","id":"exercises-3","chapter":"5 Key Programming Concepts","heading":"5.3 Exercises","text":"Suppose pass data frame summary_stats function. function return? ?Suppose pass data frame summary_stats function. function return? ?Use summary_stats function summarize variable iris dataset. can load using data(iris).Use summary_stats function summarize variable iris dataset. can load using data(iris).Use loop create scatter plot Sepal.Width Sepal.length attributes iris dataset flower species (specified Species variable) different marker color. , use skeleton code .Use loop create scatter plot Sepal.Width Sepal.length attributes iris dataset flower species (specified Species variable) different marker color. , use skeleton code .Create function called detect_outliers take vector quantile threshold argument return indices values can considered outliers given threshold (.e. lie nth quantile 100 - nth quantile).Create function called detect_outliers take vector quantile threshold argument return indices values can considered outliers given threshold (.e. lie nth quantile 100 - nth quantile).Extend function returns rows data frame contain outliers (numerical) variables.Extend function returns rows data frame contain outliers (numerical) variables.Apply function exercise dev dataset. countries can considered outliers?Apply function exercise dev dataset. countries can considered outliers?Recall quartile function examples . Can extend :Recall quartile function examples . Can extend :splits variable arbitary number ranges equal proportions (example deciles).splits variable arbitary number ranges equal proportions (example deciles).returns sensible default value vector missing. “sensible default” ? Make default value specifying function arguments.returns sensible default value vector missing. “sensible default” ? Make default value specifying function arguments.Try applying new function dev dataset splitting parts using split. may compare descriptive statistics part using lapply function.Try applying new function dev dataset splitting parts using split. may compare descriptive statistics part using lapply function.solutions exercises available 2021-01-07.","code":"data(iris)\nplot(-99, -99, xlim = c(min(iris$Sepal.Width), max(iris$Sepal.Width)),\n     ylim = c(min(iris$Sepal.Length), max(iris$Petal.Length)))\nfor (...) {\n  points(x = , y = , col = , pch = )\n}\nquartile <- function(x) {\n  quantiles <- quantile(x, c(0.25, 0.5, 0.75), na.rm = TRUE)\n  comparisons <- sapply(quantiles, function(y) y <= x)\n  rowSums(comparisons) + 1\n}"},{"path":"dplyr.html","id":"dplyr","chapter":"6 Data Manipulation","heading":"6 Data Manipulation","text":"","code":""},{"path":"dplyr.html","id":"content-4","chapter":"6 Data Manipulation","heading":"6.1 Content","text":"already discussed methods data manipulation, indexing, subsetting modifying data frames, majority R users approach task using dedicated collection packages called tidyverse, introduced Hadley Wickham, statistician New Zealand. may seem like chapter covers tools performing task already familiar , tidyverse follows different philosophy traditional R, lot advantages including better code readability efficiency. , install load package, simply run code . Remember, need call install.packages , download required files CRAN. library needs called every time start new R session attach library functions working environment.","code":"\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)"},{"path":"dplyr.html","id":"reading-the-data","chapter":"6 Data Manipulation","heading":"Reading the data","text":"chapter, use dataset ’ve used exploratory analysis chapter, presents individual-level information sample students. However, tidyverse offers improved set functions reading data, part readr subpackage - work fairly similar read.csv introduced , however advantages (example read character columns character vectors, rather factors without include stringsAsFactors argument, discussed chapter 3. readr reading functions start read_ used different file types. usual one read_csv (can use exactly way read.csv), however case use read_delim, allows us read file delimiter. case math dataset row separated semicolon (can check opening file via notebook app). specify second delim argument example :can see, running function returns message, shows specification column read - col_character refers character columns, col_double() means numeric columns. force column read specific type. example, may want character column read factors cases - example sex. mentioned , default setting read_ functions read numbers numeric variables text character variables.read sex column factor, can read data , time specifying col_types argument. col_types argument takes list input, specify type selected columns, example sex = col_factor() tell:may wonder simply use .factor factor function:exactly equivalent, however previous way much explicit concise. Anyone (including ) reads analysis immedietaly know columns specified type.final facet readr package functions load data slightly different data type normal read.csvThe data comes loaded tibble (tbl short). Tibbles special kind data frames implemented tidyverse package - thing need know know, everything learned data frames far applies tibbles. offer improvements, discussed .","code":"\nmath <- read_delim(\"data/student/student-mat-data.csv\", delim = \";\")Rows: 395 Columns: 33\n── Column specification ──────────────────────────────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (17): school, sex, address, famsize, Pstatus, Mjob, Fjob, reason, guardian, schoolsup, famsup, pai...\ndbl (16): age, Medu, Fedu, traveltime, studytime, failures, famrel, freetime, goout, Dalc, Walc, healt...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nclass(math$sex)[1] \"character\"\nmath <- read_delim(\"data/student/student-mat-data.csv\", delim = \";\",\n                 col_types = list(sex = col_factor(levels = c(\"M\",\"F\"))))\nclass(math$sex)[1] \"factor\"\nmath$sex <- factor(math$sex, levels = c(\"M\",\"F\"))\nmath <- read.csv(\"data/student/student-mat-data.csv\", sep = \";\")\nclass(math)[1] \"data.frame\"\nmath <- read_delim(\"data/student/student-mat-data.csv\", delim = \";\",\n                 col_types = list(sex = col_factor(levels = c(\"M\",\"F\"))))\nclass(math)[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \nis_tibble(math)[1] TRUE\nis.data.frame(math)[1] TRUE"},{"path":"dplyr.html","id":"the-pipe-operator","chapter":"6 Data Manipulation","heading":"The pipe operator","text":"Perhaps imporant innovation offered tidyverse package -called pipe operator %>%. use may feel bit quirky first, extremely useful widely used modern R users.learned -far, R evaluates function inside . example, can get sum missing values data frame running:essentially performs two steps - first, runs .na math data frame, returns table filled logical values, FALSE given entry missing TRUE . sum takes table input adds values (treating FALSE 0 TRUE 1). many cases, statements can get long, difficult read error-prone, especially keyword arguments specified.operation may done using pipe operator. case, rather evaluating sequence functions within, evaluated left right. %>% operator can understood way _passing output thing left thing right first argument:example, math data frame passed .na function, output passed sum function, returns exactly result. case regular call, may store output variable:continuing drop missing observations:may feel slightly unintuitive case, comes handy performing long sequences operations data, see following sections.","code":"\nsum(is.na(math))[1] 10\nmath %>% is.na() %>% sum()[1] 10\nnumber_missing <- math %>% is.na() %>% sum()\nnumber_missing[1] 10\nmath <- math[complete.cases(math), ]"},{"path":"dplyr.html","id":"dataset-manipulation","chapter":"6 Data Manipulation","heading":"Dataset manipulation","text":"Three key functions commonly used dataset manipulation tidyverse package: mutate, select filter, coming dplyr sub-package. used follows:\n- mutate used modify create columns data frames\n- select used select columns name\n- filter used select rows given set logical valuesAll three functions take data frame first argument. example, can create new column, grade_average adding together grades three years dividing 3:, equivalent :operations create variable called average adding G1, G2 G3 toegether, dividing three. however, case mutate ’s need specify $ opearator, pass math data frame first arguments, function knows G1, G2 G3 names refer particular data frame. mutate function returns data frame, additional column average. commonly, used pipe operator:case, %>% pass math data frame mutate, creates new column returns updated data.frame, stored math.filter allows filter rows data frame, operation similar indexing. example, can get students average grade higher 10 :entire operation done one step, :Note time haven’t modified data frame - variable average created temporarily, can use filter.query shows bit many columns. Suppose wanted narrow search see guardian students average higher 18. use select function, simply selects column data frame name:leaves us data frame one column, showing guardians students best marks.","code":"\nmath <- mutate(math, average = (G1 + G2 + G3)/3)\nmath$average <- (math$G1 + math$G2 + math$G3)/3\nmath <- math %>% mutate(average = (G1 + G2 + G3)/3)\nmath %>% filter(average > 18)# A tibble: 6 × 34\n  school sex     age address famsize Pstatus  Medu  Fedu Mjob   Fjob  reason guardian traveltime studytime\n  <chr>  <fct> <dbl> <chr>   <chr>   <chr>   <dbl> <dbl> <chr>  <chr> <chr>  <chr>         <dbl>     <dbl>\n1 GP     M        15 U       GT3     T           4     4 servi… teac… course father            1         2\n2 GP     M        16 U       GT3     T           4     3 health serv… reput… mother            1         4\n3 GP     M        15 U       LE3     A           4     4 teach… teac… course mother            1         1\n4 GP     M        15 U       LE3     T           4     2 teach… other course mother            1         1\n5 GP     F        18 U       GT3     T           2     2 at_ho… at_h… other  mother            1         3\n6 MS     F        18 R       LE3     T           4     4 other  other reput… mother            2         3\n# ℹ 20 more variables: failures <dbl>, schoolsup <chr>, famsup <chr>, paid <chr>, activities <chr>,\n#   nursery <chr>, higher <chr>, internet <chr>, romantic <chr>, famrel <dbl>, freetime <dbl>,\n#   goout <dbl>, Dalc <dbl>, Walc <dbl>, health <dbl>, absences <dbl>, G1 <dbl>, G2 <dbl>, G3 <dbl>,\n#   average <dbl>\nmath %>%\n  mutate(average = (G1 + G2 + G3)/3) %>%\n  filter(average > 18)# A tibble: 6 × 34\n  school sex     age address famsize Pstatus  Medu  Fedu Mjob   Fjob  reason guardian traveltime studytime\n  <chr>  <fct> <dbl> <chr>   <chr>   <chr>   <dbl> <dbl> <chr>  <chr> <chr>  <chr>         <dbl>     <dbl>\n1 GP     M        15 U       GT3     T           4     4 servi… teac… course father            1         2\n2 GP     M        16 U       GT3     T           4     3 health serv… reput… mother            1         4\n3 GP     M        15 U       LE3     A           4     4 teach… teac… course mother            1         1\n4 GP     M        15 U       LE3     T           4     2 teach… other course mother            1         1\n5 GP     F        18 U       GT3     T           2     2 at_ho… at_h… other  mother            1         3\n6 MS     F        18 R       LE3     T           4     4 other  other reput… mother            2         3\n# ℹ 20 more variables: failures <dbl>, schoolsup <chr>, famsup <chr>, paid <chr>, activities <chr>,\n#   nursery <chr>, higher <chr>, internet <chr>, romantic <chr>, famrel <dbl>, freetime <dbl>,\n#   goout <dbl>, Dalc <dbl>, Walc <dbl>, health <dbl>, absences <dbl>, G1 <dbl>, G2 <dbl>, G3 <dbl>,\n#   average <dbl>\nmath %>%\n  mutate(average = (G1 + G2 + G3)/3) %>%\n  filter(average > 18) %>%\n  select(guardian)# A tibble: 6 × 1\n  guardian\n  <chr>   \n1 father  \n2 mother  \n3 mother  \n4 mother  \n5 mother  \n6 mother  "},{"path":"dplyr.html","id":"reshaping-data","chapter":"6 Data Manipulation","heading":"Reshaping data","text":"’s common social scientific longitudinal nature. means, data given unit observation (example country, household individual) observed multiple variable (example GDP, income, well-) period time. data can come two formats - long wide.Wide data format - wide data format, column represents variable - example, table presented presents grades three students three academic years wide format. column represents separate year.Long data format - long data format, separate column represents name variable separate one - value corresponding variable. format sometimes useful particular types analysis panel data models visualization. can see student scores long format :can see example data loading dataset gdp.csv, contains GDP per capita several years couple European countries:can see data contains country names, well GDP values years 2000 2015 wide format. reshape data long format, can use pivot_longer function, comes tidyr package, another element tidyverse suite. pivot longer, specify dataset name first argument (usually piped function), followed column names contain wide-format variables (assuming order, can specified names left-right-variable, separated colon). Note example, also use inverse quotation marks, since variable named using numbers. names_to argument specifies tha name variable used store names re-formatted variables (example - years) value_to argument specifies name variable used store values (GDP per capita).can see, function produces data long format, 4 columns, 140 rows, opposed wide data consists 7 rows, 22 columns.cases, data might come long format, yet might want reshape long. can done using pivot_wider function. works exactly opposite pivot_longer. first specify data piping function use names_from argument specify name variable containing variable names value_from specify variable containing values. end obtaining data frame started .","code":"\ngdp <- read_csv(\"data/world_bank/gdp.csv\")\nhead(gdp)# A tibble: 6 × 23\n  country ccode `2000` `2001` `2002` `2003` `2004` `2005` `2006` `2007` `2008` `2009` `2010` `2011` `2012`\n  <chr>   <chr>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Germany DEU   27209. 28381. 29179. 29875. 31305. 31794. 34119. 36250. 37802. 36851. 38979. 42542. 43360.\n2 Denmark DNK   28669. 29450. 30640. 30787. 32909. 34150. 37289. 38966. 41278. 40370. 43032. 44403. 44804.\n3 Spain   ESP   21592. 22959. 24372. 25019. 26120. 27607. 30683. 32436. 33263. 32123. 31704. 31868. 31720.\n4 France  FRA   26100. 27502. 28524. 28142. 29034. 30499. 32429. 34086. 35095. 34711. 35927. 37441. 37679.\n5 United… GBR   26413. 27757. 29069. 30262. 31965. 32668. 34761. 35597. 36660. 35030. 36368. 37162. 38312.\n6 Greece  GRC   19524. 20964. 22616. 23871. 25437. 25578. 28515. 29290. 30856. 30388. 28169. 26141. 25284.\n# ℹ 8 more variables: `2013` <dbl>, `2014` <dbl>, `2015` <dbl>, `2016` <dbl>, `2017` <dbl>, `2018` <dbl>,\n#   `2019` <dbl>, X65 <lgl>\ngdp_long <- gdp %>% pivot_longer(`2000`:`2019`, \n                                 names_to = \"year\", values_to = \"gdp_pc\")\nhead(gdp_long)# A tibble: 6 × 5\n  country ccode X65   year  gdp_pc\n  <chr>   <chr> <lgl> <chr>  <dbl>\n1 Germany DEU   NA    2000  27209.\n2 Germany DEU   NA    2001  28381.\n3 Germany DEU   NA    2002  29179.\n4 Germany DEU   NA    2003  29875.\n5 Germany DEU   NA    2004  31305.\n6 Germany DEU   NA    2005  31794.\ngdp_wide <- gdp_long %>% pivot_wider(names_from = \"year\", values_from = \"gdp_pc\")\nhead(gdp_wide)# A tibble: 6 × 23\n  country  ccode X65   `2000` `2001` `2002` `2003` `2004` `2005` `2006` `2007` `2008` `2009` `2010` `2011`\n  <chr>    <chr> <lgl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Germany  DEU   NA    27209. 28381. 29179. 29875. 31305. 31794. 34119. 36250. 37802. 36851. 38979. 42542.\n2 Denmark  DNK   NA    28669. 29450. 30640. 30787. 32909. 34150. 37289. 38966. 41278. 40370. 43032. 44403.\n3 Spain    ESP   NA    21592. 22959. 24372. 25019. 26120. 27607. 30683. 32436. 33263. 32123. 31704. 31868.\n4 France   FRA   NA    26100. 27502. 28524. 28142. 29034. 30499. 32429. 34086. 35095. 34711. 35927. 37441.\n5 United … GBR   NA    26413. 27757. 29069. 30262. 31965. 32668. 34761. 35597. 36660. 35030. 36368. 37162.\n6 Greece   GRC   NA    19524. 20964. 22616. 23871. 25437. 25578. 28515. 29290. 30856. 30388. 28169. 26141.\n# ℹ 8 more variables: `2012` <dbl>, `2013` <dbl>, `2014` <dbl>, `2015` <dbl>, `2016` <dbl>, `2017` <dbl>,\n#   `2018` <dbl>, `2019` <dbl>\nall.equal(gdp_wide, gdp) [1] \"Names: 21 string mismatches\"                                                           \n [2] \"Attributes: < Names: 1 string mismatch >\"                                              \n [3] \"Attributes: < Length mismatch: comparison on first 2 components >\"                     \n [4] \"Attributes: < Component \\\"class\\\": Lengths (3, 4) differ (string compare on first 3) >\"\n [5] \"Attributes: < Component \\\"class\\\": 3 string mismatches >\"                              \n [6] \"Attributes: < Component 2: Modes: numeric, externalptr >\"                              \n [7] \"Attributes: < Component 2: Lengths: 7, 1 >\"                                            \n [8] \"Attributes: < Component 2: target is numeric, current is externalptr >\"                \n [9] \"Component 3: Modes: logical, numeric\"                                                  \n[10] \"Component 3: target is logical, current is numeric\"                                    \n[11] \"Component 4: Mean relative difference: 0.04964384\"                                     \n[12] \"Component 5: Mean relative difference: 0.04797772\"                                     \n[13] \"Component 6: Mean relative difference: 0.02722602\"                                     \n[14] \"Component 7: Mean relative difference: 0.05492863\"                                     \n[15] \"Component 8: Mean relative difference: 0.03197982\"                                     \n[16] \"Component 9: Mean relative difference: 0.08535064\"                                     \n[17] \"Component 10: Mean relative difference: 0.04919092\"                                    \n[18] \"Component 11: Mean relative difference: 0.04411082\"                                    \n[19] \"Component 12: Mean relative difference: 0.02757141\"                                    \n[20] \"Component 13: Mean relative difference: 0.05151733\"                                    \n[21] \"Component 14: Mean relative difference: 0.04769779\"                                    \n[22] \"Component 15: Mean relative difference: 0.01895478\"                                    \n[23] \"Component 16: Mean relative difference: 0.03867191\"                                    \n[24] \"Component 17: Mean relative difference: 0.03078083\"                                    \n[25] \"Component 18: Mean relative difference: 0.02475497\"                                    \n[26] \"Component 19: Mean relative difference: 0.05288349\"                                    \n[27] \"Component 20: Mean relative difference: 0.05189977\"                                    \n[28] \"Component 21: Mean relative difference: 0.03430557\"                                    \n[29] \"Component 22: Mean relative difference: 0.04530826\"                                    \n[30] \"Component 23: Modes: numeric, logical\"                                                 \n[31] \"Component 23: target is numeric, current is logical\"                                   "},{"path":"dplyr.html","id":"joining","chapter":"6 Data Manipulation","heading":"Joining","text":"final data manipulation technique discuss chapter joining. many cases dataset coming two separate file, containing different variables unit observations. case data coming World Bank Open Data, information indicator comes separate csv file. example, suppose data GDP population density countries:Suppose want analyze relationship population density gdp per capita. , convenient merge two datasets one, containing variables gdp pop_dens. can achieve using joins.First, pivot data long format:Note countries two datasets different:join two data frames, need ID variable (set variables) identify observations allow us join . example, country year variables perfect candidate, since corresponds one observation given country given period. say join two datasets country year. sThere three fundamental ways can approach :Inner join used join observations variables joining appear datasets. rows identifying variables don’t match observations dataset dropped resulting dataset. join used care primarily completeness data. order dataframes matter performing inner join.can see new dataframe dat contains gdp_pc pop_dens variables. Furthermore, countries present datasets kept:Left join used join observations variables joining appear first dataset (one left joining function). done primarily care keeping observations first (left) dataset. observations corresponding identifying values found turned missing values:can see example, resulting dataset contains missing values countries present pop_long dataset. countries gdp_long dataset kept:Full join - joining observations data frames producing missing values whenever ’s observation missing one .result full_join, countries including either datasets kept:joining techniques, Filtering joins (semi_join anti_join), well nest_join. can read documentation typing ?join console.","code":"\ngdp <- read_csv(\"data/world_bank/gdp.csv\")\npop <- read_csv(\"data/world_bank/pop_dens.csv\")\nhead(gdp)# A tibble: 6 × 23\n  country ccode `2000` `2001` `2002` `2003` `2004` `2005` `2006` `2007` `2008` `2009` `2010` `2011` `2012`\n  <chr>   <chr>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 Germany DEU   27209. 28381. 29179. 29875. 31305. 31794. 34119. 36250. 37802. 36851. 38979. 42542. 43360.\n2 Denmark DNK   28669. 29450. 30640. 30787. 32909. 34150. 37289. 38966. 41278. 40370. 43032. 44403. 44804.\n3 Spain   ESP   21592. 22959. 24372. 25019. 26120. 27607. 30683. 32436. 33263. 32123. 31704. 31868. 31720.\n4 France  FRA   26100. 27502. 28524. 28142. 29034. 30499. 32429. 34086. 35095. 34711. 35927. 37441. 37679.\n5 United… GBR   26413. 27757. 29069. 30262. 31965. 32668. 34761. 35597. 36660. 35030. 36368. 37162. 38312.\n6 Greece  GRC   19524. 20964. 22616. 23871. 25437. 25578. 28515. 29290. 30856. 30388. 28169. 26141. 25284.\n# ℹ 8 more variables: `2013` <dbl>, `2014` <dbl>, `2015` <dbl>, `2016` <dbl>, `2017` <dbl>, `2018` <dbl>,\n#   `2019` <dbl>, X65 <lgl>\nhead(pop)# A tibble: 6 × 23\n  country ccode `2000` `2001` `2002` `2003` `2004` `2005` `2006` `2007` `2008` `2009` `2010` `2011` `2012`\n  <chr>   <chr>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>\n1 France  FRA    111.   112.   113.   114.   115.   115.   116.   117.   118.   118.   119.   119.   120. \n2 United… GBR    243.   244.   245.   247.   248.   250.   252.   253.   255.   257.   259.   261.   263. \n3 Ireland IRL     55.2   56.1   57.1   58.0   59.1   60.4   62.0   63.9   65.2   65.8   66.2   66.5   66.8\n4 Italy   ITA    194.   194.   194.   195.   196.   197.   198.   199.   200.   201.   202.   202.   202. \n5 Poland  POL    125.   125.   125.   125.   125.   125.   125.   124.   124.   125.   124.   124.   124. \n6 Portug… PRT    112.   113.   114.   114.   115.   115.   115.   115.   115.   115.   115.   115.   115. \n# ℹ 8 more variables: `2013` <dbl>, `2014` <dbl>, `2015` <dbl>, `2016` <dbl>, `2017` <dbl>, `2018` <dbl>,\n#   `2019` <lgl>, X65 <lgl>\ngdp_long <- gdp %>% pivot_longer(`2000`:`2019`, \n                                 names_to = \"year\", values_to = \"gdp_pc\")\npop_long <- pop %>% pivot_longer(`2000`:`2019`, \n                                 names_to = \"year\", values_to = \"pop_dens\")\nunique(gdp_long$country)[1] \"Germany\"        \"Denmark\"        \"Spain\"          \"France\"         \"United Kingdom\" \"Greece\"        \n[7] \"Poland\"        \nunique(pop_long$country)[1] \"France\"         \"United Kingdom\" \"Ireland\"        \"Italy\"          \"Poland\"         \"Portugal\"      \nidentical(unique(gdp_long$country), unique(pop_long$country))[1] FALSE\ndat <- inner_join(gdp_long, pop_long, by = c(\"country\", \"ccode\", \"year\"))\nhead(dat)# A tibble: 6 × 7\n  country ccode X65.x year  gdp_pc X65.y pop_dens\n  <chr>   <chr> <lgl> <chr>  <dbl> <lgl>    <dbl>\n1 France  FRA   NA    2000  26100. NA        111.\n2 France  FRA   NA    2001  27502. NA        112.\n3 France  FRA   NA    2002  28524. NA        113.\n4 France  FRA   NA    2003  28142. NA        114.\n5 France  FRA   NA    2004  29034. NA        115.\n6 France  FRA   NA    2005  30499. NA        115.\nunique(dat$country)[1] \"France\"         \"United Kingdom\" \"Poland\"        \ndat <- left_join(gdp_long, pop_long, by = c(\"country\", \"ccode\", \"year\"))\nhead(dat)# A tibble: 6 × 7\n  country ccode X65.x year  gdp_pc X65.y pop_dens\n  <chr>   <chr> <lgl> <chr>  <dbl> <lgl>    <dbl>\n1 Germany DEU   NA    2000  27209. NA          NA\n2 Germany DEU   NA    2001  28381. NA          NA\n3 Germany DEU   NA    2002  29179. NA          NA\n4 Germany DEU   NA    2003  29875. NA          NA\n5 Germany DEU   NA    2004  31305. NA          NA\n6 Germany DEU   NA    2005  31794. NA          NA\nall.equal(unique(gdp_long$country), unique(dat$country))[1] TRUE\ndat <- full_join(gdp_long, pop_long, by = c(\"country\", \"ccode\", \"year\"))\nhead(dat)# A tibble: 6 × 7\n  country ccode X65.x year  gdp_pc X65.y pop_dens\n  <chr>   <chr> <lgl> <chr>  <dbl> <lgl>    <dbl>\n1 Germany DEU   NA    2000  27209. NA          NA\n2 Germany DEU   NA    2001  28381. NA          NA\n3 Germany DEU   NA    2002  29179. NA          NA\n4 Germany DEU   NA    2003  29875. NA          NA\n5 Germany DEU   NA    2004  31305. NA          NA\n6 Germany DEU   NA    2005  31794. NA          NA\nunique(c(dat$country)) [1] \"Germany\"        \"Denmark\"        \"Spain\"          \"France\"         \"United Kingdom\" \"Greece\"        \n [7] \"Poland\"         \"Ireland\"        \"Italy\"          \"Portugal\"      \nunique(c(gdp_long$country, pop_long$country)) [1] \"Germany\"        \"Denmark\"        \"Spain\"          \"France\"         \"United Kingdom\" \"Greece\"        \n [7] \"Poland\"         \"Ireland\"        \"Italy\"          \"Portugal\"      "},{"path":"dplyr.html","id":"aggregating-data","chapter":"6 Data Manipulation","heading":"Aggregating data","text":"discussed summary statistics can used summarize data, ’s often useful compare values across group, rather look one number describe entire dataset. tidyverse allows us calculate summary statistics variables summarise function. example, get average GDP countries data:different using gdp_long$gdp_pc %>% mean(), returns tibble rather scalar value. However, summarize function powerful conjunction group_by function. name suggests, group_by function divides data frame groups using one variables. surface, doesn’t appear alter much:Similarily, compare country’s average, maximum minimum GDP growth past years:case, first group data frame country. use mutate compute gdp_growth subtracting GDP one year (calculated using lag function) dividing difference lagged GDP. Note mutate function also applies computation according grouping defined group_by - lag() computed within country. use summarise apply functions. Finally, use arrange sort output according negative value average GDP growth, .e. decreasing order.Since behaviour group_by affects many operations performed dataframe, important call ungroup() end operations assign data frame new name - performing operations groupped tibbles can lead suprising results. Coming back example, suppose wanted obtain deviation country’s GDP growth global mean growth. First, obtain growths:can see using .equal function, resulting variables different. , tibble still groupped, mutate(growth_dem = gdp_growth - mean(gdp_growth, na.rm = TRUE)) expression subtracts group mean observation, wheres ’s ungrouped, calculates global mean subtracts . may seem trivial example, forgetting ungroup tibble common error crucial remeber ungroup tibble finishing performing operations . Also note calling group_by() already groupped tibble discards previous groupping applies new one instead.","code":"\ngdp_long %>% summarise(gdp_avg = mean(gdp_pc))# A tibble: 1 × 1\n  gdp_avg\n    <dbl>\n1  33486.\ngdp_long_groupped <- gdp_long %>% group_by(country)\ngdp_long_groupped# A tibble: 140 × 5\n# Groups:   country [7]\n   country ccode X65   year  gdp_pc\n   <chr>   <chr> <lgl> <chr>  <dbl>\n 1 Germany DEU   NA    2000  27209.\n 2 Germany DEU   NA    2001  28381.\n 3 Germany DEU   NA    2002  29179.\n 4 Germany DEU   NA    2003  29875.\n 5 Germany DEU   NA    2004  31305.\n 6 Germany DEU   NA    2005  31794.\n 7 Germany DEU   NA    2006  34119.\n 8 Germany DEU   NA    2007  36250.\n 9 Germany DEU   NA    2008  37802.\n10 Germany DEU   NA    2009  36851.\n# ℹ 130 more rows\npop_long %>%\n  group_by(country) %>%\n  summarise(avg_pop = mean(pop_dens, na.rm = TRUE), \n            sd_pop = sd(pop_dens, na.rm = TRUE))# A tibble: 6 × 3\n  country        avg_pop sd_pop\n  <chr>            <dbl>  <dbl>\n1 France           118.   3.60 \n2 Ireland           63.9  4.89 \n3 Italy            200.   4.67 \n4 Poland           124.   0.301\n5 Portugal         114.   1.13 \n6 United Kingdom   258.  10.3  \ngdp_long %>% \n  group_by(country) %>%\n  mutate(gdp_growth = (gdp_pc - lag(gdp_pc)) / lag(gdp_pc)) %>%\n  summarise(avg_growth = mean(gdp_growth, na.rm = TRUE), \n            max_growth = max(gdp_growth, na.rm = TRUE), \n            min_growth = min(gdp_growth, na.rm = TRUE)) %>%\n  arrange(-avg_growth)# A tibble: 7 × 4\n  country        avg_growth max_growth min_growth\n  <chr>               <dbl>      <dbl>      <dbl>\n1 Poland             0.0636     0.109      0.0361\n2 Denmark            0.0398     0.0919    -0.0220\n3 Germany            0.0391     0.0914    -0.0252\n4 Spain              0.0364     0.111     -0.0343\n5 France             0.0344     0.0633    -0.0134\n6 United Kingdom     0.0330     0.0641    -0.0445\n7 Greece             0.0264     0.115     -0.0730\ngdp_growths <- gdp_long %>% \n                group_by(country) %>%\n                mutate(gdp_growth = (gdp_pc - lag(gdp_pc)) / lag(gdp_pc))\n\n#store demeaned values:\ndem <- gdp_growths %>% \n  mutate(growth_dem = gdp_growth - mean(gdp_growth, na.rm = TRUE))\n\n#stored demeaned values calculated after ungrouping\ndem_ungr <- gdp_growths %>% \n  ungroup() %>%\n  mutate(growth_dem = gdp_growth - mean(gdp_growth, na.rm = TRUE))\n\nall.equal(dem$growth_dem, dem_ungr$growth_dem)[1] \"Mean relative difference: 0.3395083\""},{"path":"dplyr.html","id":"summary-4","chapter":"6 Data Manipulation","heading":"6.2 Summary","text":"tidyverse package set tools data manipulation commonly used R.readr offers convenient inferface reading data R explicitly specifying column classes functions read_csv, read_delim read_tsv.tibble special kind data frame implemented tidyverse package. offers new functionalities, working tibbles similar working traditional R data frames.pipe operator %>% passess values functions - instead evaluating expressions inside-, evaluated left right.select used select columns data frame based namesfilter used filter rows data frame based logical statementmutate used modify values existing columns create new columns data frameData can often come long wide format. can use pivot_longer pivot_wider switch data formats.can merge two data frames common column (set columns) using dplyr’s join functions. Depending way want treat non-matching records, may use left_join, inner_join full_joinYou can aggregate data using summary function. works best group_by, allows get statistics group, following group defined variable set variables. call ungroup() tibble, avoid errors.","code":""},{"path":"dplyr.html","id":"functions-list-4","chapter":"6 Data Manipulation","heading":"Functions list","text":"","code":""},{"path":"dplyr.html","id":"exercises-4","chapter":"6 Data Manipulation","heading":"6.3 Exercises","text":"Select true statements joins correct false statements:. Full join always produce dataframe rows inner join.\nB. Inner join never produce new missing values.\nC. Full join always produce least many rows left join.\nD. Left join used want ensure observations left data frame always matched non-missing element right data frame.remaining exercises use student data, consists three .csv files: math.csv, contains grades achieved student years long format, port.csv, data portugeese classes info.csv, contains demographic variables.Load math port data R. Specify id variable character column.Load math port data R. Specify id variable character column.Load info data R join grades datasets. Make sure keep records students reported grades portugeese math. Use suffix argument join function specify names duplicated variable names (G1, G2 G3) _por portugeese grades _mat math grades.Load info data R join grades datasets. Make sure keep records students reported grades portugeese math. Use suffix argument join function specify names duplicated variable names (G1, G2 G3) _por portugeese grades _mat math grades.Create vector called port_missing contains student IDs present math dataset missing port dataset.Create vector called port_missing contains student IDs present math dataset missing port dataset.Compare average performance Portugeese Math third year schools:Compare average performance Portugeese Math third year schools:student grades improve average subject? improvement better one school ? (HINT: might want data long format use lag function used end chapter. Store data new tibble called students_imp, useful next exercises).student grades improve average subject? improvement better one school ? (HINT: might want data long format use lag function used end chapter. Store data new tibble called students_imp, useful next exercises).grade improvements vary across schools?grade improvements vary across schools?form support - famsup schoolsup lead higher average improvement students’ grades subject?form support - famsup schoolsup lead higher average improvement students’ grades subject?two schools seem effective rising average grade school support?two schools seem effective rising average grade school support?solutions exercises available 2021-01-07.","code":""},{"path":"visualization.html","id":"visualization","chapter":"7 Data Visualization","heading":"7 Data Visualization","text":"","code":""},{"path":"visualization.html","id":"content-5","chapter":"7 Data Visualization","heading":"7.1 Content","text":"final chapter part focuses data visualization. techniques presenting data already described chapter Exploratory data analysis, chapter cover topic depth introduce commonly used tool data visualization R - ggplot2 package. main advantage ggplot2 comparison ---box plotting capabilities coming R simplicity creating relatively complex nice looking plot, often take much longer produce R base graphics.ggplot2 package part tidyverse, introduced previous chapter, often useful conjunction data manipulation tools offered tidyverse packages. can load library directly:However may also attach along tidyverse packages:also load salaries dataset, describes salaries US professors. , need install package using carData package using install.packages function:load data, simpy execute code. dataframe attached global environment.data consists 6 variables, describing academics rank, discipline (theoretical B applied), experience measured years service years since PhD attainment, subjects sex salary. see details data, use ?carData::Salaries","code":"\nlibrary(ggplot2)\nlibrary(tidyverse)\ninstall.packages('carData')\ndata('Salaries', package = 'carData')\nglimpse(Salaries)Rows: 397\nColumns: 6\n$ rank          <fct> Prof, Prof, AsstProf, Prof, Prof, AssocProf, Prof, Prof, Prof, Prof, AssocProf, As…\n$ discipline    <fct> B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, B, A, A, A, A, A, A, A, A, A, A, B…\n$ yrs.since.phd <int> 19, 20, 4, 45, 40, 6, 30, 45, 21, 18, 12, 7, 1, 2, 20, 12, 19, 38, 37, 39, 31, 36,…\n$ yrs.service   <int> 18, 16, 3, 39, 41, 6, 23, 45, 20, 18, 8, 2, 1, 0, 18, 3, 20, 34, 23, 36, 26, 31, 3…\n$ sex           <fct> Male, Male, Male, Male, Male, Male, Male, Male, Male, Female, Male, Male, Male, Ma…\n$ salary        <int> 139750, 173200, 79750, 115000, 141500, 97000, 175000, 147765, 119250, 129000, 1198…"},{"path":"visualization.html","id":"the-plotting-syntax","chapter":"7 Data Visualization","heading":"The plotting syntax","text":"Similarily tidyverse tools explored previous chapter, ggplot uses , original approach creating plots, quite different previously encouneterd exploratory data analysis lesson. initialize ggplot object, always call ggplot function, specifying name data frame first argument.can see initiates empty plot. furhter specify variables want associate object using aes() function. aes abbreviation stands aesthetic mappings. defines bindings variables dataframe specified first argument ggplot object aesthetic elements object - example, x y axes plot, line/point colors shapes bar fills. example, aes(x = absences) can interpreted “link variable absences x-axis plot”.Now figure includes x axis, automatically chosen tick locations. final step create actual plot. done “adding” -called geom plot skeleton created far. Geoms simply functions used create different plot types representing data associated ggplot object ggplot aes - example, geom_histogram used create histogram geom_boxplot create boxplot. Geoms “added” ggplot object using + operator.can see now histogram variable appears plot. plot also comes message prompting us manually specify bin width histogram, can done arguments geom function - either specifying number bins bins width individual bins binwidth.can also change colors bins well borders:mentioned earlier, aesthetic characteristics plot border color fill can treated representation data, visual characteristics plot. example, continuing absences example may see break ouf absences male female students, specifying fill argument aesthetic mapping:also automatically adds legend side plot. blue color represents proportion bin represented male students red - female students.important thing note aesthetic mapping created aes() function can defined globally .e. entire ggplot figure, case (ggplot(Salaries, aes(x = salary))), well locally, .e. one specific geom (geom_histogram(aes(x = salary)). former case, entire figure use set aesthetic mapping, latter, apply specific geom.Note case, global local mappings produce exactly output. However, adding multiple geom structures one plot, see later, using global vs local aesthetic mapping can lead different results.","code":"\nggplot(Salaries)\nggplot(Salaries, aes(x = salary))\nggplot(Salaries, aes(x = salary)) + \n  geom_histogram()`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nggplot(Salaries, aes(x = salary)) + \n  geom_histogram(bins = 40)\nggplot(Salaries, aes(x = salary)) + \n  geom_histogram(binwidth = 5000)\nggplot(Salaries, aes(x = salary)) + \n  geom_histogram(binwidth = 5000, fill = 'blue', color = 'black')\nggplot(Salaries, aes(x = salary, fill = sex)) + \n  geom_histogram(binwidth = 5000, color = 'black')\nggplot(Salaries) + \n  geom_histogram(aes(x = salary, fill = sex), binwidth = 5000,color = 'black')"},{"path":"visualization.html","id":"all-about-geoms---plot-types-in-ggplot2","chapter":"7 Data Visualization","heading":"All about geoms - plot types in ggplot2","text":"section, explore basic plot types (geoms) offered ggplot2 package. number geoms available vast, isn’t means exhaustive discussion topic - can find full list ggplot2 cheatsheet. Even can found external, ggplot-based packages. However, learning basics just couple help gain sufficient understanding ggplot’s plotting philosophy able explore rest use whenever need .","code":""},{"path":"visualization.html","id":"density-estimate","chapter":"7 Data Visualization","heading":"Density estimate","text":"density estimate alternative way draw histogram data. represents distribution continous variable drawing line. can see shape density plot absences directly corresponds histogram variable previous example.Kernel density estimates particularly useful compare distribution variable different values grouping variable. example, can examine difference distributions salary depending position held individual:differences clear-cut - appears expected, higher position held generally leads higher median earnings. However, position also higher variability income, spread Professors earnings twice large Assistant Professors.","code":"\nggplot(Salaries, aes(x = salary)) + \n  geom_density() \nggplot(Salaries, aes(x = salary, fill = rank)) + \n  geom_density(alpha = 0.3)"},{"path":"visualization.html","id":"barplots","chapter":"7 Data Visualization","heading":"Barplots","text":"Histograms kernel density estimates useful representing continuous variables, temperature, GDP hours absence. case discrete variables, take finite unordered set values, ’s often better use bar plots. ggplot2, can easily obtained using geom_bar. example, can use represent academic ranks within dataset.may also want make bar plots horizontal. two ways : old approach simply add coord_flip() ggplot object. may still encounter way plotting horizontal bar plots users code.However, since ggplot version 3.3.0, providing y axis instead x axis leads result. Furthermore, doesn’t cause unnecessary confusion caused flipping axis (example, y-axis label needs specified x-axis label coord_flip() applied). Thus recommended use second approach, provided --date version tidyverse installed., can also fill bars another variable, simply specifying fill argument aesthetic mapping definition:bars can also placed side--side improve comparison. , simply specify named argument position geom_bar function set 'dodge', seen example . means, one bar ‘dodge’ another, placed next . default value position argument 'stacked', pretty self-explanatory can seen previous example.can also use barplots present summary statistics visually - example, average salary professor given rank. , first construct summary data frame, using tools covered previous chapter, plot result.Note case need specify x y aesthetics, x represents name group (case professors’ rank) y - associated value, indicated height bar. Moreover, need setthe stat argument geom_bar identity. default setting, stat = count implies ggplot takes one, discrete variable arguments counts number observations group defined levels variable - operation similar output table(math$health). can also use geom_col, short-hand geom_bar(stat = 'identity') produces output:","code":"\nggplot(Salaries, aes(x = rank)) + \n  geom_bar(width = 0.5, fill = 'forestgreen')\nggplot(Salaries, aes(x = rank)) + \n  geom_bar(width = 0.5, fill = 'forestgreen') +\n  coord_flip()\nggplot(Salaries, aes(y = rank)) + \n  geom_bar(width = 0.5, fill = 'forestgreen')\nggplot(Salaries, aes(x = rank, fill = sex)) + \n  geom_bar(width = 0.5)\nggplot(Salaries, aes(x = rank, fill = discipline)) + \n  geom_bar(position = 'dodge')\nsalary_by_rank <- Salaries %>% \n  group_by(rank) %>%\n  summarise(avg_salary = mean(salary)) %>%\n  ungroup()\n\nggplot(salary_by_rank, aes(x = rank, y = avg_salary)) + \n  geom_bar(stat = 'identity', width = 0.5, fill = 'firebrick')\nggplot(salary_by_rank, aes(x = rank, y = avg_salary)) + \n  geom_col(width = 0.5, fill = 'firebrick')"},{"path":"visualization.html","id":"boxplots","chapter":"7 Data Visualization","heading":"Boxplots","text":"Another way compare variable across groups use boxplots. Boxplots described chapter exploratory data analysis way evaluating distribution continuous variable. also implemented ggplot2 package can used comparisons continuous variables distributions across multiple groups defined discrete variable. can done specifying grouping variable x aesthetic continuous variable want examine y aesthetic.can see medians Male Female professor’s wages sample similar, interquantile range much higher men. time, distribution male wages spread , indicated larger box, longer tails. also includes outliers.can also draw arbitrary summary statistic - mean - plot, using stat_summary function - specify statistic want use fun keyword argument geom using geom argument. case, add cross indicate mean salary sexes plot:","code":"\nggplot(Salaries, aes(x = sex, y = salary)) + \n  geom_boxplot(width = 0.5)\nggplot(Salaries, aes(x = sex, y = salary)) + \n  geom_boxplot(width = 0.5) + \n  stat_summary(fun = \"mean\", geom = \"point\", \n               shape = 3, color = \"red\")"},{"path":"visualization.html","id":"violin-plots","chapter":"7 Data Visualization","heading":"Violin plots","text":"Violin plots closely related box plots, however depict shape variables’ distribution. , overcome issue related use boxplots decribed exploratory analysis chapter - namely two distributions can identical box plots, yet different underlying shapes. violin plots avoid connecting boxplots kernel density estimates, giving better approximation shape variable’s distribution.can see strength coming back misleading example previous chapter. Suppose theThe boxplots look alike:However, violin plot give away entire story - namely fact first category two peaks (.e. comes bimodal distribution, using proper statistical terms), unlikely observe median value. good example distributions political realm self-identification left-right ideological scale, majority respondents reporting either slightly conservative slightly liberal.","code":"\nggplot(Salaries, aes(x = sex, y = salary)) + \n  geom_violin(width = 0.5)\nggplot(dt, aes(x = category, y = value)) + \n  geom_boxplot()\nggplot(dt, aes(x = category, y = value)) + \n  geom_violin()"},{"path":"visualization.html","id":"scatter-plots-1","chapter":"7 Data Visualization","heading":"Scatter plots","text":"far described multiple ways visually representing continous variable, well relationship continous variable discrete grouping variables. many circumstances, interested examining relationship two continuous variables. One commonly employed data visualization techniques problems like scatter plots, simply describe observation point marked two-dimensional graph, x axis representing one variable y axis - . can seen example , look relationship professor’s experience approximated years since attaining PhD salary.clear can see sort relationship experience earnings. words, ’s degree positive correlation two variables (examine term depth next chapter), .e. professors experience tend earn average. However, experience relationship becomes noisy, ’s variation earnings experienced academics. previous cases, can specify additional aesthetics color shape:","code":"\nggplot(Salaries, aes(x = yrs.since.phd, y = salary)) + \n  geom_point()\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, \n                     color = rank, shape = rank)) + \n  geom_point()"},{"path":"visualization.html","id":"line-of-best-fit","chapter":"7 Data Visualization","heading":"Line of best fit","text":"can also add line best fit plot, using geom_smooth() geom, method argument specified 'lm'. line best fit simply line closest points plot average. 'lm' methods stands linear model - method used fitting line, described detail next part, chapter linear regression., able fully understand difference local global aesthetic mappings mentioned earlier chapter. Notice difference providing aesthetic mapping global level (.e. ggplot() function call)…:… just geom_point().former case, color = sex argument used geom_point geom_line(), leads 3 lines different colors fitted groups separately. color aesthetic mapping provided geom_point local level, one line fitted data, specified global mapping. approaches may useful, depending research question. comparison two plots reveals interesting behaviour data: observations considered toegether, seems positive relationship years since PhD salary. However look group level, relationship appears disappear - behaviour known Simpson’s Paradox. case, ’s primarily result relationship rank years since PhD - professors higher ranks experience. variation salaries within groups considered, experience measured years seems hardly explain variation earnings.","code":"\nggplot(Salaries, aes(x = yrs.since.phd, y = salary)) + \n  geom_point() +\n  geom_smooth(method = 'lm')`geom_smooth()` using formula = 'y ~ x'\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color = rank)) + \n  geom_point() +\n  geom_smooth(method = 'lm')`geom_smooth()` using formula = 'y ~ x'\nggplot(Salaries, aes(x = yrs.since.phd, y = salary)) + \n  geom_point(aes(color = rank)) +\n  geom_smooth(method = 'lm')`geom_smooth()` using formula = 'y ~ x'"},{"path":"visualization.html","id":"line-connecting-points","chapter":"7 Data Visualization","heading":"Line connecting points","text":"cases, might want connect points figure line depict sort trend mean variable depending categorical group natural ordering - example, suppose want visually examining differences average earnings professors dataset depending years service.First can obtain average group using group_by summarise.can plot averages using geom_point:seems sort trend data (even though points divert , likely result small sample size given group leading rather unreliable sample estimates), plot emphasize enough. make meanigful, can add line connecting points geom_line. Note set group aesthetic 1, provides ggplot hint connect point.can extend following example comparing trend depending paid classes taken:","code":"\nbyage <- Salaries %>%\n  mutate(yrs_range = cut_width(yrs.since.phd, 5, boundary = 5)) %>%\n  group_by(yrs_range) %>%\n  summarise(avg = mean(salary, na.rm = TRUE)) %>%\n  ungroup()\nggplot(byage, aes(x = yrs_range, y = avg)) + \n  geom_point()\nggplot(byage, aes(x = yrs_range, y = avg, group = 1)) + \n  geom_point() + \n  geom_line()\nbyage <- Salaries %>%\n  mutate(yrs_range = cut_width(yrs.since.phd, 5, boundary = 5)) %>%\n  group_by(yrs_range, discipline) %>%\n  summarise(avg = mean(salary, na.rm = TRUE)) %>%\n  ungroup()`summarise()` has grouped output by 'yrs_range'. You can override using the `.groups` argument.\nggplot(byage, aes(x = yrs_range, y = avg, color = discipline, \n                  lty = discipline, group = discipline)) + \n  geom_point() +\n  geom_line()"},{"path":"visualization.html","id":"multiple-plots","chapter":"7 Data Visualization","heading":"Multiple plots","text":"ggplot2 also makes possible put multiple plots one figure - indeed useful many circumstances, many data visualization professionals consider good practice, follows rule small multiples, making data digestible reader avoiding informational overload one plot. Arranging plots figure can done two ways - based value categorical variable (‘faceting’) arbitrarily putting plots rectangular grid.","code":""},{"path":"visualization.html","id":"faceting","chapter":"7 Data Visualization","heading":"Faceting","text":"Faceting refers simply splitting data value categorical variable, similarily way group_by treats data performing regular manipulation. syntax relatively simple: simply add another layer plot called facet_wrap specify faceting variable following tilde symbol ~ - commonly used notation R, indicating sort dependence one variable another - encounter next two chapters.result can see scatter plots lines best fit three separate plots, one appropriate heading indicating group observations. However, output difficult read, due fact x-axis plot fixed length plots - improves comparability figures, limits clarity. can changed specifying additional argument facet_wrap layer:, can see relationship seen overall dataset disappears within groups.can also facet using one variable arrange figures grid via two dimensional grouping. example, suppose want evaluate distribution experience wihtin combination rank discipline individuals. can achieved using facet_grid layer., can see professors theoretical disciplines seem worked longer average, however range values comparable cases. also appears Assistant Professors Associate Professors applied departments, siginificant differences gender. Similar analysis applied earnings, however, reveals earnings seem higher level applied departments.","code":"\nggplot(Salaries, aes(yrs.since.phd, salary)) + \n  facet_wrap(~ rank) + \n  geom_point() + \n  geom_smooth(method = 'lm')`geom_smooth()` using formula = 'y ~ x'\nggplot(Salaries, aes(yrs.since.phd, salary)) + \n  facet_wrap(~ rank, scales = 'free_x') + \n  geom_point(aes(color = sex)) + \n  geom_smooth(method = 'lm')`geom_smooth()` using formula = 'y ~ x'\nggplot(Salaries, aes(x = yrs.since.phd)) + \n  facet_grid(discipline ~ rank) +\n  geom_histogram()`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nggplot(Salaries, aes(x = salary)) + \n  facet_grid(discipline ~ rank) +\n  geom_histogram()`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."},{"path":"visualization.html","id":"plotting-in-a-grid","chapter":"7 Data Visualization","heading":"Plotting in a grid","text":"Sometimes, want make figure arrangement customized, necessarily arranged accordance variable. example, may want depict consince summary important findings one 2x2 plot. , can use plot_grid function cowplot package (, always, needs installed first).arrange plots arbitrary rectangular grid, first need create plots separate ggplot object. avoid repetition, however, ’s best first create basic object add new layers save separate names.","code":"\nlibrary(cowplot)\nplt <- ggplot(Salaries, aes(fill = discipline, color = discipline))\nplt_hist_s <- plt + geom_density(aes(x = salary), alpha = 0.3)\nplt_hist_y <- plt + geom_density(aes(x = yrs.since.phd), alpha = 0.3)\nplt_bar <- plt + geom_bar(aes(y = rank))\nplt_sct <- plt + geom_point(aes(x = yrs.since.phd, y = salary)) +\n  geom_smooth(aes(x = yrs.since.phd, y = salary), method = 'lm')\nplot_grid(plt_sct, plt_hist_s, plt_hist_y, plt_bar)`geom_smooth()` using formula = 'y ~ x'"},{"path":"visualization.html","id":"customizing-plots","chapter":"7 Data Visualization","heading":"Customizing plots","text":"Note lot cases , plots far publication quality - allowed get overview data, kept original variable names axes issues axis tick labels overlapping, amongst things. issues can fixed ggplot’s customization capabilities.startets, let’s consider one scatter plots created earlier:useful make variable names formal plot. can done using labs layer, used specify labels:Title plot can also specified using ggtitle function:Furthremore, can customize legend labels well. Ths done using scale_color_discrete layer, applies manual changes color aesthetic specified initializing ggplot object.can also customize legend using theme layer. layer used customization majority plot elements, legend, text axes.seen , keyword arguments theme usually take two forms - string, legend.position = 'bottom', element_* theme elements. can read ?element_blank, however basic logic follows - use element_text() specify text characteristics - font, size, color face text elements plot, legend labels axis ticks, element_rect specify characteristics rectangle elements, backgrounds element_blank make given elements disappear plot entirely.cases axis labels two long, can problematic especially x axis, results overlaps makes impossible read . common solution rotate labels certain angle. can done using axis.text.x argument element_text(rotation = n), n magnitude counter-clockwise rotation. vertical horizontal justification can adjusted using vjust hjust arguments respectively.Finally, can make changes overall plot applying themes entire plot. built ggplot package; come cowplot ggpubr. can find couple examples , feel free explore online.Note theme adjustments must specified specific theme specified, otherwise overrides . can also specify theme upfront entire script using theme_set().","code":"\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color = rank)) + \n  geom_point() +\n  geom_smooth(method = 'lm')`geom_smooth()` using formula = 'y ~ x'\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color = rank)) + \n  geom_point() +\n  geom_smooth(method = 'lm') +\n  #add axes labels\n  labs(x = 'Years since PhD', y = 'Salary in USD')`geom_smooth()` using formula = 'y ~ x'\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color = rank)) + \n  geom_point() +\n  geom_smooth(method = 'lm') +\n  #add axes labels\n  labs(x = 'Years since PhD', y = 'Salary in USD') + \n  #add title\n  ggtitle('Salaries of US college professors')`geom_smooth()` using formula = 'y ~ x'\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color = rank)) + \n  geom_point() +\n  geom_smooth(method = 'lm') +\n  #add axes labels:\n  labs(x = 'Years since PhD', y = 'Salary in USD') +\n  #add title\n  ggtitle('Salaries of US college professors') +\n  #rename legend elements:\n  scale_color_discrete(name = 'Rank', \n                       labels = c('Asst. Prof.', \n                                  'Assoc. Prof.',\n                                  'Prof'))`geom_smooth()` using formula = 'y ~ x'\nggplot(Salaries, aes(x = yrs.since.phd, y = salary, color = rank)) + \n  geom_point() +\n  geom_smooth(method = 'lm') +\n  #add axes labels:\n  labs(x = 'Years since PhD', y = 'Salary in USD') +\n  #add title\n  ggtitle('Salaries of US college professors') +\n  #rename legend elements:\n  scale_color_discrete(name = 'Rank', \n                       labels = c('Asst. Prof.','Assoc. Prof.','Prof')) +\n  #customize the plot:\n  theme(legend.position = 'bottom', #move legend to the bottom\n        legend.background = element_rect(fill = 'lightblue'), #legend background\n        legend.text = element_text(size = 8, face = 'italic'), #legend font\n        legend.title = element_blank()) #remove title`geom_smooth()` using formula = 'y ~ x'\nbyage <- Salaries %>%\n  mutate(yrs_range = cut_width(yrs.since.phd, 5, boundary = 5)) %>%\n  group_by(yrs_range, discipline) %>%\n  summarise(avg = mean(salary, na.rm = TRUE)) %>%\n  ungroup()`summarise()` has grouped output by 'yrs_range'. You can override using the `.groups` argument.\nggplot(byage, aes(x = yrs_range, y = avg, color = discipline, \n                  lty = discipline, group = discipline)) + \n  geom_point() +\n  geom_line() +\n  labs(x = 'Years since PhD', y = 'Average earnings') +\n  theme(axis.text.x = element_text(angle = 45, vjust = 0.9, hjust = 1.0))\nplt <- ggplot(byage, aes(x = yrs_range, y = avg, color = discipline, \n                  lty = discipline, group = discipline)) + \n  geom_point() +\n  geom_line() + \n  labs(x = 'Years since PhD', y = 'Average earnings')\nplt +\n  theme_bw() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 1.0))\nplt +\n  theme_bw() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 1.0))\nplt +\n  theme_classic() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 1.0))\nplt +\n  theme_cowplot() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 1.0))\nplt +\n  theme_minimal() + \n  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 1.0))\ntheme_set(theme_grey(base_size = 10))\nplt +\n  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 1.0))"},{"path":"visualization.html","id":"saving-plots","chapter":"7 Data Visualization","heading":"Saving plots","text":"Saving plots can done using ggsave function:","code":"\nggsave(plot = plt, filename = 'files/test.png', width = 150, height = 100, units = 'mm')"},{"path":"visualization.html","id":"summary-5","chapter":"7 Data Visualization","heading":"7.2 Summary","text":"ggplot part tidyverse collection popular plotting package Rggplot part tidyverse collection popular plotting package Ryou initialize ggplot object using ggplot() function, data frame planning visualize first argument aesthetic mapping created aes() function second argument.initialize ggplot object using ggplot() function, data frame planning visualize first argument aesthetic mapping created aes() function second argument.aesthetic mappings created aes() function, defines connections graphical elements plot variables data frame. elements can mapped include x y axes, color, fill, shape line type. mapping can created globally, provided ggplot() function locally, passing aes() specific geoms.aesthetic mappings created aes() function, defines connections graphical elements plot variables data frame. elements can mapped include x y axes, color, fill, shape line type. mapping can created globally, provided ggplot() function locally, passing aes() specific geoms.geoms constituent elements ggplot objects. different graphical structures, histograms, boxplots scatter plots can added initialized ggplot object using addition operator +. geom uses aesthetic mapping specified globally, unless specified otherwise locally.geoms constituent elements ggplot objects. different graphical structures, histograms, boxplots scatter plots can added initialized ggplot object using addition operator +. geom uses aesthetic mapping specified globally, unless specified otherwise locally.facet_wrap facet_grid functions can used split plots small multiples. done using ~ tilde operator - example, facet_grid(sex ~ rank) split figure rectangular grid plots combinations sex rank variables.facet_wrap facet_grid functions can used split plots small multiples. done using ~ tilde operator - example, facet_grid(sex ~ rank) split figure rectangular grid plots combinations sex rank variables.can customize elements plot, axes labels using labs() command, legend names, using scale_* functions, well elements theme() layer, time works element_* functions argumentswe can customize elements plot, axes labels using labs() command, legend names, using scale_* functions, well elements theme() layer, time works element_* functions argumentswe can apply pre-defined changes plots using themes, theme_bw theme_minimal. can also set entire session using theme_set().can apply pre-defined changes plots using themes, theme_bw theme_minimal. can also set entire session using theme_set().plots can saved via ggsave function.plots can saved via ggsave function.","code":""},{"path":"visualization.html","id":"functions-list-5","chapter":"7 Data Visualization","heading":"Functions list","text":"","code":""},{"path":"visualization.html","id":"exercises-5","chapter":"7 Data Visualization","heading":"7.3 Exercises","text":"Consider plot created earlier plot_grid function cowplot package. Use knowledge plot customization make readable, example :keeping one legend fill variablerotating axis tick labels necessarychanging axes labelsmaking points scatter plot smalleradding themeSave final figure png file.can find initial code :remainder next exericses, need load gapminder dataset part gapminder package.Get overview dataset. many variables observations ? many unique values variable ?Get overview dataset. many variables observations ? many unique values variable ?Visualize relationship per capita gdp life expectancy 2007 using scatter plot. Include one line best fit color markers continent. Make sure plot appropriate axis labels. line offer good fit line? kind curve better? ?Visualize relationship per capita gdp life expectancy 2007 using scatter plot. Include one line best fit color markers continent. Make sure plot appropriate axis labels. line offer good fit line? kind curve better? ?Examine countries appear divert overall trend plot created previous exercise.Examine countries appear divert overall trend plot created previous exercise.Visualize difference GDP per capita distribution continents (2007). Use least two different methods compare advantages disadvantages. Remember appropriate labels title!Visualize difference GDP per capita distribution continents (2007). Use least two different methods compare advantages disadvantages. Remember appropriate labels title!Compare GDP per capita continent year using connected scatter plot. careful - taking group average continent incorrect, population sizes differ. can try presenting values log scale using scale_y_log10() make lines visible.Compare GDP per capita continent year using connected scatter plot. careful - taking group average continent incorrect, population sizes differ. can try presenting values log scale using scale_y_log10() make lines visible.Prepare plot, time visualizing average GDP growth rate continents. HINT: use groupby() %>% mutate() routine lag() function previous chapter.Prepare plot, time visualizing average GDP growth rate continents. HINT: use groupby() %>% mutate() routine lag() function previous chapter.solutions exercises available 2021-01-07.","code":"\nplt <- ggplot(Salaries, aes(fill = discipline, color = discipline))\nplt_hist_s <- plt + geom_density(aes(x = salary), alpha = 0.3)\nplt_hist_y <- plt + geom_density(aes(x = yrs.since.phd), alpha = 0.3)\nplt_bar <- plt + geom_bar(aes(y = rank))\nplt_sct <- plt + geom_point(aes(x = yrs.since.phd, y = salary)) +\n  geom_smooth(aes(x = yrs.since.phd, y = salary), method = 'lm')\nplot_grid(plt_sct, plt_hist_s, plt_hist_y, plt_bar)`geom_smooth()` using formula = 'y ~ x'\ndata(gapminder, package = 'gapminder')"},{"path":"association.html","id":"association","chapter":"8 Statistical Inference and Association","heading":"8 Statistical Inference and Association","text":"","code":""},{"path":"association.html","id":"content-6","chapter":"8 Statistical Inference and Association","heading":"8.1 Content","text":"far, described variety methods wrangle explore data R. performing cleaning exploratory analysis, common perform formal tests data verify whether relationships hypothesized hold scrutiny tests supported statistical theory. chapter present couple testing relationships. formal knowledge statistical inference useful, chapter rely background knowledge heavily.","code":"\nlibrary(tidyverse)"},{"path":"association.html","id":"comparing-means","chapter":"8 Statistical Inference and Association","heading":"Comparing means","text":"mean good measure data comparing means across groups can help us determine way given variable varies depending conditions - example, whether average GDP growth certain period differs two countries whether average earnings different depending people’s gender race. However, may seem difficult determine whether difference really meaningful, especially usually don’t entire population examining hand, (pressumably random) sample population. example, suppose randomly choose 5 men 5 women compute average earnings. obtain 35000 pounds men 40000 pounds women. claim men average earn less women, based data? difference sufficient claim difference exists overall population? questions answered statistical inference.","code":""},{"path":"association.html","id":"is-mean-different-from-0---one-sample-t-test","chapter":"8 Statistical Inference and Association","heading":"Is mean different from 0? - one sample t-test","text":"’ll start simple case. data file wages.csv contains information average salary sample 100 individuals 2005 and2 2010. interested whether growth salary. First, read data obtain percentege growth:can examine average:see mean around 0.015. sufficient claim average salary employees target population grown 2005 2010? check , can perform -called t-test, takes account variability sample size, determines probability falsely reject hypothesis mean equal 0 - probability p-value. Note p-value probability mean equal 0. familiar frequentist statistical inference, recall p-value probability obtaining statistic extreme sample statistic assumption null hypothesis true repeated sampling.conduct t-test, can simply use t.test function:p-value usually important part output produced function. case, 0.0077. means, mean significantly different 0 95% confidence level. Confidence level way can quantify certainty difference parameter hypothesized value (case 0). 95% confidence level one commonly used thresholds social sciences. Generally, recipe checking p-value satisfies cerain confidence level subtract confidence level 1 compare p-value. p-value smaller value obtained subtraction, significance test statistic satisfies . , example, 95% confidence \\(1 - 0.95 = 0.05\\) 0.0077 $ < 0.05$, thus can say mean significantly different 0 95% confidence level.Another important information reported output t-test confidence interval. confidence interval provides us way quantifying uncertainty underlying value statistic (case mean), given variability sample (measured standard deviation, described chapter 4. Suppose take 100 random samples original population. 95% confidence interval describes range exepct mean 95 100 samples fall. case mean, given \\(\\bar{\\mu}\\pm 1.96SE(\\bar{\\mu})\\), \\(\\bar\\mu\\) sample mean obtained \\(SE(\\bar{\\mu})\\) standard error mean given \\(\\sigma/\\sqrt{n}\\), sample standard deviation divided square root number observations sample. Note 95% confidence interval including 0 equivalent statistic significantly different 0 95% level.","code":"\nwages <- read_csv('data/wages.csv')Rows: 100 Columns: 3\n── Column specification ──────────────────────────────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): gender\ndbl (2): salary2005, salary2010\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nwages <- wages %>% mutate(change = (salary2010 - salary2005)/salary2005)\nmean(wages$change)[1] 0.01489452\nt.test(wages$change)\n    One Sample t-test\n\ndata:  wages$change\nt = 2.7211, df = 99, p-value = 0.007688\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.004033511 0.025755527\nsample estimates:\n mean of x \n0.01489452 "},{"path":"association.html","id":"error-bars","chapter":"8 Statistical Inference and Association","heading":"Error bars","text":"confidence interval around mean can displayed ggplot using geom_errorbar function. -called errorbar good way display range likely values around mean.case data, plot errorbars, first compute standard error mean using formula discussed .create bar plot add geom_errorbar top . Note case specify x aesthetic chraracter 'Wage change'. unusual plot just one bar plot, geom_col geom_errorbar require x aesthetic passed.","code":"\nwages_summary <- wages %>%\n  summarise(change_mean = mean(change), \n            change_err = sd(change)/sqrt(n()))\nggplot(wages_summary, aes(x = 'Wage change', y = change_mean)) +\n  geom_col(width = 0.2) + \n  geom_errorbar(aes(ymin = change_mean - 1.96 * change_err, \n                ymax = change_mean + 1.96 * change_err), width = 0.1) + \n  labs(x = '', y = 'Mean change in wage')"},{"path":"association.html","id":"are-two-means-different---two-sample-t-test","chapter":"8 Statistical Inference and Association","heading":"Are two means different? - two sample t-test","text":"simple extension, can apply logic t-test difference two means within one sample - called two sample t-test implemented R function. grouping variable specified using formula notation, encounter next chapter dealing linear regression. test difference mean variable x groups defined y, specify t.test(x ~ y). , coming back example, can examine whether average salary 2005 different male female employees.result seem significant, meaning statistical evidence real difference male female earnings underlying populations (precisely, took 100 samples underlying population, 95 show non-zero difference). Based sample, however, magnitude difference quite difficult determine, expect range 19000 2000 dollars. can visualize using geom_errorbar:","code":"\nt.test(salary2005 ~ gender, data = wages)\n    Welch Two Sample t-test\n\ndata:  salary2005 by gender\nt = -2.4595, df = 97.494, p-value = 0.01568\nalternative hypothesis: true difference in means between group F and group M is not equal to 0\n95 percent confidence interval:\n -19486.287  -2082.285\nsample estimates:\nmean in group F mean in group M \n       31020.72        41805.01 \nwages %>%\n  group_by(gender) %>%\n  summarise(wage_mean = mean(salary2005), \n            wage_err = sd(salary2005)/sqrt(n())) %>%\n  ggplot(aes(x = gender, y = wage_mean)) + \n  geom_col(width = 0.3) + \n  geom_errorbar(aes(ymin = wage_mean - wage_err, \n                    ymax = wage_mean + wage_err), width = 0.2) +\n  ylab('Average salary in 2005')"},{"path":"association.html","id":"relationship-between-two-continuous-variables","chapter":"8 Statistical Inference and Association","heading":"Relationship between two continuous variables","text":"","code":""},{"path":"association.html","id":"covariance","chapter":"8 Statistical Inference and Association","heading":"Covariance","text":"far discussed techniques looking statistical relationships one continuous variable (wage) one categoric variable (salary). many circumstances, however, interested measuring association two continuous variables. part consider data sample students free variables: average weekly time spent studying, days student home ill achieved GPA.can examine pairwise relationships variables using pairs() function, useful tool analyzing datasets multiple continuous variables.Let’s start interpreting plot. rectangles variable tell name axis. example, plot lower left corner shows relationship GPA (x axis) study time (y axis). can see students sample spent time studying seem higher grades - points higher one axis tend also higher . hand, students ill , average, achieved lower grades. seems relationship ill time spent studying.statistical terms, relationship can measured covariance two variables. Recall discussion variance exploratory analysis chapter. calculated vector x using sum((x - mean(x))^2)/(length(x) - 1), var(x) function short. Covariance essentially , calculated two variables instead one, using sum((x - mean(x)) * mean((y - mean(y))))/(length(x) - 1) cov function short. can see demonstrated :variance actually nothing else covariance variable !Essentially covariance measures average element-wise product observations deviation mean two variables. may sound complicated, breaking makes simple. two variables, gpa days_ill, people grades higher average grade also tend study longer average study time. , students subtract mean grade mean study time respective grades study times, average positive., hand people higher grades average tend lower time spent ill home average, average products demeaned (.e. mean subtracted ) variables negative, since majority products negative.Finally, ’s relationship two variables - example days_ill study_time, expect average products demeaned variables close 0, since around number positive negative.last example seems incorrect? possible covariance study_time days_ill larger covariance study_time gpa, even though plot suggests much stronger relationship latter? explore next section correlation.","code":"\nscores <- read_csv('data/scores.csv')Rows: 100 Columns: 3\n── Column specification ──────────────────────────────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): study_time, days_ill, gpa\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\npairs(scores,upper.panel = NULL)\ncov_fun <- function(x, y) sum((x - mean(x)) * (y - mean(y)))/(length(x) - 1)\ncov_fun(scores$gpa, scores$study_time)[1] 1.337834\ncov(scores$gpa, scores$study_time)[1] 1.337834\ncov(scores$gpa, scores$gpa) == var(scores$gpa)[1] TRUE\ncov(scores$gpa, scores$study_time)[1] 1.337834\ncov(scores$gpa, scores$days_ill)[1] -11.16068\ncov(scores$study_time, scores$days_ill)[1] 2.419399"},{"path":"association.html","id":"correlation","chapter":"8 Statistical Inference and Association","heading":"Correlation","text":"downside covariance measure relationship completely dependent units two variables measures, , percisely, range values take. take covariance average time spent studying GPA compare covariance average time spent studying time ill, latter greater, simply time expressed hours days, values ranging 0.8 15.1 1 110 respectively, GPA ranges 1 5:, values get multiplying study_time days_ill tend higher general. makes use covariance problematic estimating objective strength relationship two variables.order avoid , use correlation instead. Correlation simply covariance, divided product standard deviation variables. Without going mathematical details, suffice say standardizes covariance, ranges -1 1, -1 meaning perfect negative relationship (.e. one variable increases, always decreases) 1 meaning perfect positive relationship (one variable increases, decreases). 0 means ’s relationship variables.can see using R code. cor_fun created demonstration purposes, usual function used R obtain correlation simply cor.Now can see, relationship study_time days_ill indeed close 0:can also use cor entire data frame obtain -called correlation matrix, shows pairwise relationships two variablesNote diagonal always 1, .e. correlation variable always 1.obvious reasons, function also won’t work applied data frame containing text data:visualize pariswise relationships two variables using plot bit sophisticated one produced pairs() can use ggpairs function GGally package, produced ggplot style plot, presenting correlations, density plots scatter plots numeric variables dataset:","code":"\nvapply(scores, range, numeric(2))     study_time days_ill  gpa\n[1,]       1.42        4 1.33\n[2,]      15.28      100 4.70\ncor_fun <- function(x, y) cov_fun(x, y)/(sd(x) * sd(y))\ncor_fun(scores$gpa, scores$study_time)[1] 0.5538811\ncor(scores$gpa, scores$study_time)[1] 0.5538811\ncor(scores$study_time, scores$days_ill)[1] 0.03523657\ncor(scores)           study_time    days_ill        gpa\nstudy_time 1.00000000  0.03523657  0.5538811\ndays_ill   0.03523657  1.00000000 -0.7001128\ngpa        0.55388114 -0.70011285  1.0000000\ncor(wages)\nlibrary(GGally)\nggpairs(scores)"},{"path":"association.html","id":"further-details","chapter":"8 Statistical Inference and Association","heading":"Further details","text":"details p-value computed:","code":"\nerr <- sd(wages$change)/sqrt(nrow(wages))\ntscore <- mean(wages$change)/err\ndf <- length(wages$change) - 1\npt(tscore, df, lower.tail = FALSE) * 2[1] 0.007687596\nt.test(wages$change)\n    One Sample t-test\n\ndata:  wages$change\nt = 2.7211, df = 99, p-value = 0.007688\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 0.004033511 0.025755527\nsample estimates:\n mean of x \n0.01489452 "},{"path":"association.html","id":"summary-6","chapter":"8 Statistical Inference and Association","heading":"8.2 Summary","text":"","code":""},{"path":"association.html","id":"functions-list-6","chapter":"8 Statistical Inference and Association","heading":"Functions list","text":"","code":""},{"path":"association.html","id":"exercises-6","chapter":"8 Statistical Inference and Association","heading":"8.3 Exercises","text":"Write function compute correlation just numeric variables data frame. Test wages data.Write function compute correlation just numeric variables data frame. Test wages data.correlation variable always equal 1? Write R code demonstrate .correlation variable always equal 1? Write R code demonstrate .remainder exercises, come back Salaries data used previous chapter:Using correlation, examine relationship stronger - one years since PhD salary one years service salary.Use t-tests check whether can confirm reject following hypothesis, based sample Salaries dataset.’s difference salary Male Female professors.’s difference salary Male Female professors.’s difference salary professors applied theoretical department.’s difference salary professors applied theoretical department.average salary different 100 000 USD.average salary different 100 000 USD.Recall plot produced towards end previous chapter depicting average salary age group academic discipline. Produce plot, time include error bars depicting confidence intervals around means. code produce table used last exercises . Note need modify (computing standard errors) plotting data. Remeber adding appropriate labels plot.Examine correlation years since phd average salary groups defined data.solutions exercises available 2021-02-18.","code":"\n#ANSWER\ncor(Salaries$salary, Salaries$yrs.since.phd)[1] 0.4192311\ncor(Salaries$salary, Salaries$yrs.service)[1] 0.3347447\n#the relationship between years since PhD and salary appears to be stronger\nbyage <- Salaries %>%\n  mutate(yrs_range = cut_width(yrs.since.phd, 5, boundary = 5)) %>%\n  group_by(yrs_range, discipline) %>%\n  summarise(avg = mean(salary, na.rm = TRUE)) %>%\n  ungroup()`summarise()` has grouped output by 'yrs_range'. You can override using the `.groups` argument."},{"path":"ols.html","id":"ols","chapter":"9 Linear Regression","heading":"9 Linear Regression","text":"","code":""},{"path":"ols.html","id":"content-7","chapter":"9 Linear Regression","heading":"9.1 Content","text":"","code":""},{"path":"ols.html","id":"introduction-1","chapter":"9 Linear Regression","heading":"Introduction","text":"Regression power house social sciences. widely applied takes many different forms. Chapter going explore linear variant, also called Ordinary Least Squares (OLS). type regression used dependent variable continuous. following Chapter look regression binary dependent variable calculation probability fall either two categories. let’s first turn linear regression.","code":""},{"path":"ols.html","id":"bivariate-linear-regression","chapter":"9 Linear Regression","heading":"Bivariate Linear Regression","text":"","code":""},{"path":"ols.html","id":"the-theory","chapter":"9 Linear Regression","heading":"The Theory","text":"Regression able identify direction relationship independent dependent variable, also able quantify effect. Let us choose Y dependent variable, X independent variable. data displaying scatter plot:little goodwill can already see positive relationship: X increases, Y increases, well. Now, imagine taking ruler trying fit line best describes relationship depicted points. regression line.position line coordinate system usually described two items: intercept Y-axis, slope line. slope defined rise run, indicates much Y increases (decreases slope negative) add additional unit X. notation follows call intercept \\(\\beta_{0}\\), slope \\(\\beta_{1}\\). task estimate values, also called coefficients. can see depicted graphically :PopulationWe first assume dealing population sample. regression line just drawn called Population Regression Function (PRF) written follows:\\[\\begin{equation}\nE(Y|X_{}) = \\beta_{0} + \\beta_{1} X_{}\n\\tag{9.1}\n\\end{equation}\\]wer dealing population, line geometric locus expected values dependent variable Y, given values independent variables X. approach statistics underpins module: frequentist statsctics (opposed Bayesian statistics). understanding values “long run”, sampled repeatedly population, expected value value , well, expect see often long run.regression line intercepting observations. two located line, others little distance PRF. distances \\(E(Y|X_{})\\) \\(Y_{}\\) called error terms denoted \\(\\epsilon_{}\\).describe observations \\(Y_{}\\) therefore need add error terms equation (9.1):\\[\\begin{equation}\nY_{} = \\beta_{0} + \\beta_{1} X_{} + \\epsilon_{}\n\\tag{9.2}\n\\end{equation}\\]SampleIn reality hardly ever population social sciences, generally contend sample. Nonetheless, can construct regression line basis sample, Sample Regression Function (SRF). important note nature regression line derive fromt sample different every sample, sample values . Rarely, PRF SRF - always using SRF estimate PRF.order flag notation use specify SRF, using little hats everything estimate, like :\\[\\begin{equation}\n\\hat{Y}_{} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1} X_{}\n\\tag{9.3}\n\\end{equation}\\]Analogously, describe observations \\(Y_{}\\) adding estimated error terms \\(\\hat{\\epsilon}_{}\\) equation.\\[\\begin{equation}\nY_{} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1} X_{} + \\hat{\\epsilon}_{}\n\\end{equation}\\]following graph visdualised relationship observation, PRF, SRF respective error terms.Ordinary Least Squares (OLS)eye-balled scatter plot start Chapter order fit line , sub-consciously done minimising distance observations line. put differently, tried minimise error term \\(\\hat{\\epsilon}_{}\\). basically intuition behind fitting SRF mathematically, . try minimise sum error terms, observations close regression line possible. problem encounter distances always sum zero.similar calculating standard deviation differences observations mean sum zero (essentially thing ), simply square distances. minimising sum distances observations regression line, sum squared distances observations regression line. Graphically, end little squares made \\(\\hat{\\epsilon}_{}\\) gives method name: Ordinary Least Squares (OLS).now ready apply stuff real-world example!","code":""},{"path":"ols.html","id":"the-application","chapter":"9 Linear Regression","heading":"The Application","text":"applied part Chapter, going model feelings towards Donald Trump lead-presidential election 2020. Data investigation taken https://electionstudies.org/data-center/2020-exploratory-testing-survey/ Please follow link download “2020 Exploratory Testing Survey” pop working directory.can load ANES data set:good, variable bounded 0 100. fact 999 placeholder missing data throughout data set. need replace NAs.look summary , everything looks fine now:way, just wanted replace one variable, example fttrump1, called:Norris Inglehart (2016) argued :populist support Europe generally stronger among older generation, men, less educated, religious, ethnic majorities, patterns confirming previous research.Let’s see also applies presidential elections US. first look question: “older people rate Trump higher younger people?”. independent variables age.Let’s evaluate relationship scatter plot line best fit:positive relationship. can calculate exact numerical nature relationship follows:start specifying object store results. call lm means linear model. dependent variable fttrump1 listed first, tilde independent variable, age. Finally, tell R data set use. can print result, calling model1.interpret results?age zero, person rate Trump 31.68 average. course makes little sense anything theoretical / mathematical consideration.every additional year age, person rate Trump 0.22 points higher average.findings significant acceptable significance level? Let’s find , getting detailed output:OK, lot , worth pausing go step step. First, R reminds us actual formula used estimate model:ignoring section residuals, don’t need make life difficult needs . Now come coefficients:size direction course previous output, output now contains additional information standard error, resulting t-value, p-value. R helpful , offers us varying amount asterisks according different, commonly accepted levels significance. 0.05 standard practice social sciences, accept anything one, asterisks. intercept slope coefficient significant 95% confidence level, shown statistical relationship age ratings Trump.omitting residual standard error reason , let us look model fit indicators.Multiple R-Squared (aka \\(R^{2}\\)) tells us much variation dependent variable fttrump1 explained independent variable age. \\(R^{2}\\) runs 0 1, 1 equal 100% variation. case, explained mere 0.09% Trump rating. lousy, can lot better . Never expect anything near 100% unless work toy data set text book. get 60-70% can happy. return Adjusted \\(R^{2}\\) Section Multiple Linear Regression.F-statistic end:","code":"\nanes <- read.csv(\"data/anes.csv\")\nsummary(anes$fttrump1)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00   40.00   44.59   80.00  999.00 \nanes[anes == 999] <- NA\nsummary(anes$fttrump1)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00    0.00   40.00   42.42   80.00  100.00       7 \nanes$fttrump1 <- with(anes, replace(fttrump1, fttrump1 == 999, NA))\nsummary(anes$age)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  18.00   34.75   49.00   48.87   63.00  110.00 \nlibrary(tidyverse)\n\nggplot(anes, aes(x = age, y = fttrump1)) +\n  geom_point() +\n  geom_smooth(method = lm)\nmodel1 <- lm(fttrump1 ~ age, data = anes)\nmodel1\nCall:\nlm(formula = fttrump1 ~ age, data = anes)\n\nCoefficients:\n(Intercept)          age  \n    31.6837       0.2197  \nsummary(model1)\nCall:\nlm(formula = fttrump1 ~ age, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-55.847 -39.152  -0.523  39.258  64.143 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 31.68372    2.14801  14.750  < 2e-16 ***\nage          0.21967    0.04157   5.284 1.35e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.67 on 3071 degrees of freedom\n  (7 observations deleted due to missingness)\nMultiple R-squared:  0.009011,  Adjusted R-squared:  0.008688 \nF-statistic: 27.92 on 1 and 3071 DF,  p-value: 1.35e-07"},{"path":"ols.html","id":"categorical-independent-variables-aka-dummies","chapter":"9 Linear Regression","heading":"Categorical Independent Variables (aka ‘Dummies’)","text":"Often variables categorical. One example variable sex two categories: male female.Turn factor variable assign telling labelsCheck worked:Let’s estimate model:interpret ?Let’s slope coefficient first: women rate Trump 7.16 points less man average. interpretation dummy variable coefficient done regards reference category. case “male”. effect observe equivalent moving “male” “female” effect adds 7.16 points.gives indication interpret intercept case: value displayed men rate Trump average, namely 46.16 points. significant 95% confidence level.effect corroborates hypothesis advanced Inglehart Norris, results displayed elegant way. sex authors made statement men. need change reference category “female”.re-estimate model, get effect displayed directly:Whilst many categorical variables binary, course . work categorical variable 3 levels?next determinant mentioned Inglehart Norris’ paper education. can obtain information respondent’s level education variable educ.terribly telling , yet, let’s look codebook:first step , recode variable factor variable:Eight levels many meaningful analysis, two reductionist. sake simplicity, let’s go three: low, medium high education. recode ordered factor follows:Check results:ready go:Whilst intercept statistically significant, slope coefficients . Therefore, can conclude education statistical influence Trump’s approval ratings.Note, sex example , R chose first level independent variable reference category. wish change , can manner . can also check level R used reference category contrasts() command. :","code":"\nsummary(anes$sex)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   1.000   2.000   1.522   2.000   2.000 \ntable(anes$sex)\n   1    2 \n1473 1607 \nanes$sex <- factor(anes$sex, labels = c(\"Male\", \"Female\"))\ntable(anes$sex)\n  Male Female \n  1473   1607 \nmodel2 <- lm(fttrump1 ~ sex, data = anes)\nsummary(model2)\nCall:\nlm(formula = fttrump1 ~ sex, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.156 -38.992  -1.156  38.844  61.008 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   46.156      1.009  45.749  < 2e-16 ***\nsexFemale     -7.165      1.397  -5.129 3.09e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.68 on 3071 degrees of freedom\n  (7 observations deleted due to missingness)\nMultiple R-squared:  0.008493,  Adjusted R-squared:  0.00817 \nF-statistic: 26.31 on 1 and 3071 DF,  p-value: 3.095e-07\nanes <- anes %>%\n  mutate(sex = relevel(sex, ref = \"Female\"))\nmodel2 <- lm(fttrump1 ~ sex, data = anes)\nsummary(model2)\nCall:\nlm(formula = fttrump1 ~ sex, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.156 -38.992  -1.156  38.844  61.008 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  38.9919     0.9661  40.358  < 2e-16 ***\nsexMale       7.1646     1.3969   5.129 3.09e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.68 on 3071 degrees of freedom\n  (7 observations deleted due to missingness)\nMultiple R-squared:  0.008493,  Adjusted R-squared:  0.00817 \nF-statistic: 26.31 on 1 and 3071 DF,  p-value: 3.095e-07\nsummary(anes$educ)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   3.000   4.000   4.012   5.000   8.000 \ntable(anes$educ)\n  1   2   3   4   5   6   7   8 \n100 656 622 326 761 424 102  89 \nanes$educ <- factor(anes$educ)\nanes <- anes %>%\n  mutate(educ_fac = recode(educ, '1'=\"low\", \n                       '2'= \"low\",\n                       '3'= \"low\",\n                       '4' = \"medium\",\n                       '5' = \"medium\",\n                       '6' = \"high\",\n                       '7' = \"high\",\n                       '8' = \"high\"))\ntable(anes$educ_fac)\n   low medium   high \n  1378   1087    615 \nmodel3 <- lm(fttrump1 ~ educ_fac, data = anes)\nsummary(model3)\nCall:\nlm(formula = fttrump1 ~ educ_fac, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-42.943 -42.019  -2.388  37.981  57.981 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     42.0189     1.0481  40.090   <2e-16 ***\neduc_facmedium   0.9240     1.5775   0.586    0.558    \neduc_fachigh     0.3693     1.8870   0.196    0.845    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.85 on 3070 degrees of freedom\n  (7 observations deleted due to missingness)\nMultiple R-squared:  0.0001119, Adjusted R-squared:  -0.0005395 \nF-statistic: 0.1718 on 2 and 3070 DF,  p-value: 0.8422\ncontrasts(anes$educ_fac)       medium high\nlow         0    0\nmedium      1    0\nhigh        0    1"},{"path":"ols.html","id":"summary-for-bivariate-regression","chapter":"9 Linear Regression","heading":"Summary for Bivariate Regression","text":"’s ! made first big step understanding regression output producing output . explanations real world never mono-causal. always multiple influences working time, need set statistical model take complexity account. brings us next step: multiple regression.","code":""},{"path":"ols.html","id":"multiple-linear-regression","chapter":"9 Linear Regression","heading":"Multiple Linear Regression","text":"","code":""},{"path":"ols.html","id":"the-theory-1","chapter":"9 Linear Regression","heading":"The Theory","text":"simply extending Equation (9.3) adding independent variables. two independent variables write:\\[\\begin{equation}\n\\hat{Y} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1} X_{1i} + \\hat{\\beta}_{2} X_{2i}\n\\end{equation}\\]Note betas subscript now, also independent variables. example \\(X_{1i}\\) denote \\(^{th}\\) observation independent variable 1.can extend generally :\\[\\begin{equation}\n\\hat{Y} = \\hat{\\beta}_{0} + \\hat{\\beta}_{1} X_{1i} + \\hat{\\beta}_{2} X_{2i} + ... + \\hat{\\beta}_{n} X_{ni}\n\\tag{9.4}\n\\end{equation}\\]n number independent variables model.","code":""},{"path":"ols.html","id":"the-application-1","chapter":"9 Linear Regression","heading":"The Application","text":"Just extended Equation (9.3) (9.4), can extend model R - simply need connect independent variables +. wished look joint influence independent variables included far, type:","code":"\nmodel4 <- lm(fttrump1 ~ age + sex + educ_fac, data = anes)\nsummary(model4)\nCall:\nlm(formula = fttrump1 ~ age + sex + educ_fac, data = anes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-55.109 -38.373  -1.385  37.536  68.242 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    27.33647    2.40776  11.353  < 2e-16 ***\nage             0.23274    0.04156   5.599 2.34e-08 ***\nsexMale         7.66785    1.40848   5.444 5.62e-08 ***\neduc_facmedium  0.32209    1.56889   0.205    0.837    \neduc_fachigh   -0.36738    1.89537  -0.194    0.846    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 38.5 on 3068 degrees of freedom\n  (7 observations deleted due to missingness)\nMultiple R-squared:  0.01868,   Adjusted R-squared:  0.0174 \nF-statistic:  14.6 on 4 and 3068 DF,  p-value: 8.15e-12"},{"path":"ols.html","id":"the-interpretation","chapter":"9 Linear Regression","heading":"The Interpretation","text":"included multiple independent variables now, interpretation coefficients changes slightly. principle called “Ceteris Paribus” means “things equal”. exactly mean?Take coefficient age, example. bivariate regression interpret follows: “average, every additional year age, support Trump increase 0.23274 units”. first thing note size coefficient changed. ran bivariate model 0.21967. reason inclusion variables. , isolating, purifying influence variable age , holding sex educ_fac constant. also say “sex educ_fac equal, average, every additional year age, support Trump increase 0.23274 units”. new interpretation coefficients multiple regression.","code":""},{"path":"ols.html","id":"model-fit-again","chapter":"9 Linear Regression","heading":"Model Fit (again)","text":"added “shoe size interviewee” model, make absolutely sense theoretical point view. Yet, R-Squared either stay , even increase. R-Squared can never decrease addition variables. course good. need measure takes account number independent variables, penalises us inclusion irrelevant variables. measure called “Adjusted R-Squared” can found bottom model summary.run bivariate model, always use “Multiple R-Squared”, running multiple regression, always use “Adjusted R-Squared”. allow compare model fit models determine whether variable adds explanatory power (“Adjusted R-Squared” increases), pointless (“Adjusted R-Squared” stays ), detrimental model (“Adjusted R-Squared” decreases).","code":""},{"path":"ols.html","id":"model-specification","chapter":"9 Linear Regression","heading":"Model Specification","text":"noticed quoted Norris Inglehart’s determinants populist support done intentionally. selection independent variables always needs guided theory. Theory provides logic structure enquiry makes scientific (called “Political Science” “Politics”, let nobody tell otherwise. Politics takes place Westminster defined negotiation different groups according respective power - don’t say didn’t learn anything module). Otherwise, stabbing dark, randomly checking factors deem influential.composition regression model therefore also needs guided theory. theory multiple components, extended time, can test propositions stage separately. Classical Modernisation example, posits wealthier countries democratic. Later , influencing factors extended health, education, urbanisation, etc. make sense run model just GDP first, add three variables.Occasionally, inclusion new variables takes significance away previously included ones, able show new variables explain variation dependent variable better. , always makes sense test different combinations independent variables look deeper explains outcome better / best.One last word selecting independent variables: can’t just throw random number variables model. need observe principle parsimony asks use many variables necessary, possible.","code":""},{"path":"ols.html","id":"summary-7","chapter":"9 Linear Regression","heading":"9.2 Summary","text":"OLS Acronym “Ordinary Least Squares”.OLS Acronym “Ordinary Least Squares”.CLM Acronym “Classical Linear Model”.CLM Acronym “Classical Linear Model”.BLUE Acronym “Best Linear Unbiased Estimator”.BLUE Acronym “Best Linear Unbiased Estimator”.Parsimony Use many variables necessary, possible.Parsimony Use many variables necessary, possible.","code":""},{"path":"ols.html","id":"functions-list-7","chapter":"9 Linear Regression","heading":"Functions list","text":"","code":""},{"path":"ols.html","id":"exercises-7","chapter":"9 Linear Regression","heading":"9.3 Exercises","text":"relationship proposed Inglehart Norris (2016) also includes religiosity ethnic majorities possible predictors.Using variable att2, assess bivariate regression influence religiosity. Categorise attending services almost every week, every week ‘religious’, others ‘religious’.Using variable latin1, assess bivariate regression member Hispanic, Latino, Spanish origin negative effect approving Trump.Another, frequently used variable predict endorsements politicians income. bivariate regression, use variable income test relationship. , create new variable called income_fac three levels: low income (0-44,999), medium income (45,000-84,999), high income (>85,000).solutions exercises available 2021-02-18.","code":""},{"path":"ols.html","id":"references","chapter":"9 Linear Regression","heading":"9.4 References","text":"Inglehart, Ronald F. Norris, Pippa (2016) Trump, Brexit, Rise Populism: Economic -Nots Cultural Backlash. HKS Working Paper . RWP16-026, Available SSRN: https://ssrn.com/abstract=2818659 http://dx.doi.org/10.2139/ssrn.2818659","code":""},{"path":"logit.html","id":"logit","chapter":"10 Logistic Regression","heading":"10 Logistic Regression","text":"","code":""},{"path":"logit.html","id":"content-8","chapter":"10 Logistic Regression","heading":"10.1 Content","text":"previous Chapter encountered linear regression analysis allowed us quantify amount direction one independent variables continuous dependent variable. already mentioned , also type regression can deal binary dependent variable. usually yes/scenario, democracy / autocracy, war / peace, trade agreement / trade agreement, … get picture. Many problems questions political science binary outcomes, learn important useful method answer research questions. previous Chapter, take theory first, applying theory empirical example. time concerning survival passengers Titanic.","code":""},{"path":"logit.html","id":"logit---the-intuition","chapter":"10 Logistic Regression","heading":"Logit - The Intuition","text":"COVID-19 put bit damper , question can relate whether go tonight, . “propensity go ” directly observable, call latent variable. can imagine running minus infinity plus infinity, point continuum making decision go . Let’s call point tau (\\(\\tau\\)). Graphically, look like :inclination go , likely influenced amount money wallet / bank. broke, less inclined (sensible), swimming , inclined. , “propensity go ” (remember running minus plus infinity) influenced budget, let’s construct graph, pop propensity go y-axis, budget x-axis. assume relationship linear, can fit regression line coordinate system, just previous Chapter:Whilst visualises influence budget latent variable, aiming make prediction probability going , .Now imagine, budget \\(x_{1}\\). way threshold \\(\\tau\\) likely scenario stay home. friends going , sun shining, just scored 74 essay. chance still go . less likely budgetary constraint suggest, . going : every budgetary point, probability distribution (logit bell-shaped curve unlike normal distribution, called logistic distribution4). draw probability distributions , graph looks like :probability going coloured grey. can see even \\(x_{1}\\) teeny bit probability go . budget increases, probability slides threshold \\(\\tau\\), reach magical point \\(x_{5}\\) probability 50%. , amount probability sliding \\(\\tau\\) steadily decreasing, shape logistic distribution.can depict amount probability (size grey area) \\(x_{}\\) separate graph called Cumulative Probability (Density Function), short CDF:s-shaped curve now gives us probability (going ) \\(x_{}\\) (budget). important note relationship linear, linear regression. s-shaped curve increase probability going \\(x_{2}\\) \\(x_{3}\\) going \\(x_{3}\\) \\(x_{4}\\). can see visualised :therefore able interpret coefficients way OLS. using predicted probabilities instead. one step time. Let’s first get hands dirty data.","code":""},{"path":"logit.html","id":"logit---the-estimation","chapter":"10 Logistic Regression","heading":"Logit - The Estimation","text":"going use data passengers Titanic 1912 investigate survived.Schematically, can write logit command follows:can use , however, need set working directory, load data, prepare dependent variable, turning factor:first investigation, let’s see whether passenger’s age influenced probability survive sinking. hypotheses follows:\\(H_{0}\\): Age impact probability survive\\(H_{}\\): Age impact probability surviveIf visualise Null-Hypothesis, find probability (average probability) surviving every \\(x_{}\\):Let’s see much evidence hypothesis estimating logit model:OLS can obtain results using summary() function:take throught output bit bit now.","code":"\nlogit <- glm(depvar ~ indepvar, \n             data = mydata, \n             family = \"binomial\")\nlibrary(readxl)\nlibrary(tidyverse)\n\ntitanic <- read_excel(\"data/titanic.xlsx\", sheet=\"titanic_full\")\n\ntitanic$survived <- factor(titanic$survived, \n                           labels=c(\"no\", \"yes\"))\nlogit <- glm(survived ~ age, \n             data = titanic, \n             na.action = na.exclude,\n             family = \"binomial\")\nsummary(logit)\nCall:\nglm(formula = survived ~ age, family = \"binomial\", data = titanic, \n    na.action = na.exclude)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)  \n(Intercept) -0.136531   0.144715  -0.943   0.3455  \nage         -0.007899   0.004407  -1.792   0.0731 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1414.6  on 1045  degrees of freedom\nResidual deviance: 1411.4  on 1044  degrees of freedom\n  (263 observations deleted due to missingness)\nAIC: 1415.4\n\nNumber of Fisher Scoring iterations: 4"},{"path":"logit.html","id":"logit---the-output","chapter":"10 Logistic Regression","heading":"Logit - The Output","text":"always, R first shows formula estimated model.find coefficients – unlike OLS output. First need see whether coefficients statistically significant. , numbers just occurred chance, take message . looking p-value:social sciences generally require 95% confidence level, p-value \\(p\\le 0.05\\). p-value age coefficient 0.0731 therefore larger required threshold. can draw conclusion age significant impact probability survive sinking Titanic!R also gives information missing values end. always worthwhile looking , aware many observations actually used estimation.","code":""},{"path":"logit.html","id":"logit---interpreting-the-coefficients","chapter":"10 Logistic Regression","heading":"Logit - Interpreting the Coefficients","text":"far, said logistic regression interpret coefficients directly, linear. resort something called predicted probabilities. ?can show , need estimate new model, can interpret coefficients statistically significant - know labouring point, surprised often goes wrong essays. Let’s look whether age influenced probability travel first-class. , recode class variable binary dummy estimate model:can see coefficients highly significant, can interpret .explained , way OLS. point, can say looking output restricted :Direction: independent variable positive negative influence dependent variable?Size: can compare size effect different coefficients “larger ”, “smaller ”. effect, size coefficients determines steep s-shaped CDF , higher coefficient, steeper curve.want delve deeper interpretation, can evaluate probability y-axis different values x-axis – stay example, probability travelling first class different ages?Let us first get basic overview variable . can callingAverage age: 30Minimum age: 0.17 (two months)Maximum age: 80263 missing observationsAs first step, might interesting see probability travelling first class average age. calculating average age, need exclude missing values setting na.rm=TRUE.defining object, can use predict probability point:important set type response obtain probabilities, otherwise R return log-odds another way interpreting results logit. Log-odds defined logarithm probability success probability failure. going look module.mean age, probability travel First Class 24%. set age maximumand calculate predicted probability , changes drastically:Now can make statements :average age, probability travel First Class Titanic 24%.maximum age 80 years, probability increases 66% 90%.might wish get overview probabilities travel first class entire range age variable. can , byfinding rangecreating sequence ranging minimum maximum value, steps 1 yearpredicting probabilities using previously created sequence listIf rush, can simply plot base R plot.want look jazzy, use GGPLOT2 (need turn sequence predicted probabilities data frame first):can see graph just older 47 likely travel First Class:can also derive sophisticated way. take log-odd (defined logarithm probability success probability failure) set equal regression line5:\\[\\begin{equation*}\nlog(0.5/(1-0.5)) = -3.187456 + 0.067767 \\times age\n\\end{equation*}\\]\\[\\begin{equation*}\nlog(1) = 0 = -3.187456 + 0.067767 \\times age\n\\end{equation*}\\]Rearranging, obtain\\[\\begin{equation*}\nage = 3.187456/0.067767 = 47.03586\n\\end{equation*}\\]general, solve age value p:\\[\\begin{equation*}\nage = (log(p/(1-p)) - 3.187456)/0.067767\n\\end{equation*}\\], make easily reproducible:\\[\\begin{equation}\nage = (log(p/(1-p)) - coef(class\\_age)[1])/coef(class\\_age)[2]\n\\end{equation}\\]just want x-value associated 50% probability, simply divide intercept slope coefficient!","code":"\ntitanic <- titanic %>% \n  mutate(class = \n           as.numeric(\n             recode(pclass, '1'='1', \n                    '2'='0',\n                    '3'='0')))\n\nclass_age <- glm(class ~ age, \n                data = titanic, \n                na.action = na.exclude,\n                family = \"binomial\")\n\nsummary(class_age)\nCall:\nglm(formula = class ~ age, family = \"binomial\", data = titanic, \n    na.action = na.exclude)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -3.187456   0.213561  -14.93   <2e-16 ***\nage          0.067767   0.005825   11.63   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1223.3  on 1045  degrees of freedom\nResidual deviance: 1056.1  on 1044  degrees of freedom\n  (263 observations deleted due to missingness)\nAIC: 1060.1\n\nNumber of Fisher Scoring iterations: 4\nsummary(titanic$age)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1667 21.0000 28.0000 29.8811 39.0000 80.0000     263 \nmeanage = data.frame(age = mean(titanic$age, na.rm=TRUE))\npredict(class_age, meanage, type=\"response\")        1 \n0.2382104 \nmaxage = data.frame(age = max(titanic$age, na.rm=TRUE))\npredict(class_age, maxage, type=\"response\")        1 \n0.9032496 \nsummary(titanic$age)   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1667 21.0000 28.0000 29.8811 39.0000 80.0000     263 \nxage <- seq(0, 80, 1)\n\nyage <- predict(class_age, list(age = xage),type=\"response\")\nplot(xage, yage, xlab = \"age\", ylab = \"Probability to travel in First Class\", type=\"l\")\npredictions <- data.frame(xage,yage)\n\nggplot(data=predictions, aes(x=xage, y=yage)) +\n  geom_line() +\n  labs(x= \"Age\", y=\"Predicted Probability to Travel in First Class\") +\n  theme(axis.text=element_text(size=12),\n        axis.title=element_text(size=12,face=\"bold\"))\nfirstage = data.frame(age = 47)\n\npredict(class_age, firstage, type=\"response\")        1 \n0.4993925 "},{"path":"logit.html","id":"logit---model-fit","chapter":"10 Logistic Regression","heading":"Logit - Model Fit","text":"question now, good model predict travelling first class? higher proportion correctly predicted cases, better. proportion correctly predicted cases much dependent set cut-point \\(\\tau\\). far, assumed 50%, sensible default. choose different cut-points classify predictions. , example, incorrectly predicting 1s (: travelled first class) large range x-values, just raise cut-point turn (incorrectly) predicted 1s zeros (: travelling class first) instead.therefore fairer use method captures trade-correctly predicting 1s 0s. method called ROC-curve (receiver operating ciriterion) takes form curve. curve two axes:y-axis: Probability correctly predicting 1. (Sensitivity)x-axis: (1-Specificity); Specificity: Probability correctly predicting 0.Usually, also diagonal fitted coordinate system indicate model fit model without independent variables (AKA covariates).passenger class model, curve looks like :interpret ? away diagonal, better model predicts 1s 0s. area called ‘auc’ 100% model correctly predicted everything. area decreases model becomes worse. 50% might well tossed coin make predictions, correctly predicting 50% cases. predict 74.5% isn’t great, bad start. now estimate different models use area compare fit different models.let show got curve first place. start installing package pROCWe can load packageand calculate curve:done ? started predicting probabilities travel first class. second step, unlisted probabilities saved new variable titanic data set. Finally, fed information values dependent variable respective predicted probabilities observation roc() function saved results object called roc. auc() function returns us area, can also get curve graphically:procedure work, essential use option na.exclude dealing missing data estimating model. way predicted probability every observation. deleted missing values na.omit, number observations longer vector containing predicted values receive error message.","code":"\ninstall.packages(\"pROC\")\nlibrary(pROC)\nprob_trav <- predict(class_age, type=\"response\")\n\ntitanic$prob_trav <- unlist(prob_trav)\n\nroc <- roc(titanic$class, titanic$prob_trav)\n\nauc(roc)Area under the curve: 0.745\nplot(roc, print.auc=TRUE)"},{"path":"logit.html","id":"summary-8","chapter":"10 Logistic Regression","heading":"10.2 Summary","text":"latent variable - variable values directly observablelogit - Logistic regression ModelROC curve - receiver operating characteristic curve, captures trade-correctly predicting 1s 0s.","code":""},{"path":"logit.html","id":"functions-list-8","chapter":"10 Logistic Regression","heading":"Functions list","text":"","code":""},{"path":"logit.html","id":"exercises-8","chapter":"10 Logistic Regression","heading":"10.3 Exercises","text":"First ExerciseThe solutions exercises available 2021-02-18.","code":""},{"path":"rmarkdown.html","id":"rmarkdown","chapter":"11 R Markdown","heading":"11 R Markdown","text":"","code":""},{"path":"rmarkdown.html","id":"content-9","chapter":"11 R Markdown","heading":"11.1 Content","text":"One persuasive arguments use R (say SPSS) ability easily make work reproducible. means give RScript another person, able replicate, step step data preparation analysis, obtaining results. fundamental part scientific enquiry, also helpful , wish replicate work later stage. Take : months forgotten data management procedure steps used analysis. achieve ? can, course, use annotations RScript explain others done step. fact exactly matter routine. can go step .might asked studying previous Chapters get great output form Tables Figures essay, dissertation. answer Markdown. lets create reproducible essays / articles great ease, even feature create bibliography take care referencing. Intrigued? read !way, webpage also created R Markdown.","code":""},{"path":"rmarkdown.html","id":"introduction-2","chapter":"11 R Markdown","heading":"Introduction","text":", R Markdown? promised introduction,R Markdown provides unified authoring framework data science, combining code, results, prose commentary. R Markdown documents fully reproducible support dozens output formats, like PDFs, Word files, slideshows, . (https://r4ds..co.nz/r-markdown.html)","code":""},{"path":"rmarkdown.html","id":"usage","chapter":"11 R Markdown","heading":"Usage","text":"communicating decision makers, want focus conclusions, code behind analysis.communicating decision makers, want focus conclusions, code behind analysis.collaborating data scientists (including future !), interested conclusions, reached ( .e. code).collaborating data scientists (including future !), interested conclusions, reached ( .e. code).environment data science, modern day lab notebook can capture , also thinking.environment data science, modern day lab notebook can capture , also thinking.(https://r4ds..co.nz/r-markdown.html)","code":""},{"path":"rmarkdown.html","id":"the-components-of-an-r-markdown-document","chapter":"11 R Markdown","heading":"The Components of an R Markdown Document","text":"YAMLTextCode Chunks","code":""},{"path":"rmarkdown.html","id":"the-yaml","chapter":"11 R Markdown","heading":"The YAML","text":"Acronym “Yet Another Markup Language”Contains settings entire documentPrimarily parameters bibliography","code":""},{"path":"rmarkdown.html","id":"text","chapter":"11 R Markdown","heading":"Text","text":"WritingBasically, can just write text always .’s “” formatting differs.CompilingMarkdown WYSIWYG (See Get)Compiling called “Knitting”","code":""},{"path":"rmarkdown.html","id":"headings","chapter":"11 R Markdown","heading":"Headings","text":"","code":"# Heading \n\n## Sub-Heading\n\n### Sub-Sub Heading"},{"path":"rmarkdown.html","id":"emphasis","chapter":"11 R Markdown","heading":"Emphasis","text":"","code":"*italic*\n\n**bold**\n\n\\texttt(courier)\n\n\\underline(underline)"},{"path":"rmarkdown.html","id":"links","chapter":"11 R Markdown","heading":"Links","text":"Just insert link","code":""},{"path":"rmarkdown.html","id":"lists-1","chapter":"11 R Markdown","heading":"Lists","text":"","code":"- \n    - \n    - "},{"path":"rmarkdown.html","id":"numbered-lists","chapter":"11 R Markdown","heading":"Numbered Lists","text":"","code":"1. \n    a. \n    b. \n2. "},{"path":"rmarkdown.html","id":"line-breaks","chapter":"11 R Markdown","heading":"Line Breaks","text":"produce line break::","code":"line 1\nline 2line 1\n\nline 2"},{"path":"rmarkdown.html","id":"block-quotes","chapter":"11 R Markdown","heading":"Block Quotes","text":"Simply precede quote “\\(>\\)”block turn green ","code":""},{"path":"rmarkdown.html","id":"equations","chapter":"11 R Markdown","heading":"Equations","text":"Two ways set equationsEither wrapped $ signsorExampleThe commandresults :\\[\\begin{equation}\n  Y = \\beta_{0} + \\beta_{1} x_{} + \\epsilon\n\\end{equation}\\]suppress numbering type:\\[\\begin{equation*}\n  Y = \\beta_{0} + \\beta_{1} x_{} + \\epsilon\n\\end{equation*}\\]","code":"$ equation $\\begin{equation}\nequation\n\\end{equation}\\begin{equation}\nY = \\beta_{0} + \\beta_{1} x_{i} + \\epsilon\n\\end{equation}\\begin{equation*}\nY = \\beta_{0} + \\beta_{1} x_{i} + \\epsilon\n\\end{equation*}"},{"path":"rmarkdown.html","id":"list-of-symbols","chapter":"11 R Markdown","heading":"List of Symbols","text":"can find good compilation symbols :https://latex.wikia.org/wiki/List_of_LaTeX_symbols","code":""},{"path":"rmarkdown.html","id":"code-chunks","chapter":"11 R Markdown","heading":"Code Chunks","text":"","code":""},{"path":"rmarkdown.html","id":"in-line-r-code","chapter":"11 R Markdown","heading":"In-Line R Code","text":"can include R Code Markdown wrapping inShortcut:Mac: Option + Command + IWindows: Ctrl + Alt + IExampleresults inChunk OptionsTypes Output Suppressed :ExamplesDisplay, calculate:Suppress Messages PackagesSuppress Messages Packages display","code":"```{r}\n\n``````{r}\n5+3\n```\n5+3[1] 8```{r eval=F}\n5+3\n``````{r message=F}\nlibrary(tidyverse)\n``````{r message=F, eval=F}\nlibrary(tidyverse)\n```"},{"path":"rmarkdown.html","id":"figures-and-graphs","chapter":"11 R Markdown","heading":"Figures and Graphs","text":"can also use include figures graphs:Add Caption!refer text withExampleturns \nFigure 11.1: RStudio Task Bar\ncan see Figure 11.1","code":"```{r echo=FALSE, out.width='75%'}\nknitr::include_graphics('./filename.png')\n``````{r echo=FALSE, out.width='75%', fig.cap=\"\\\\label{fig:test}Test Caption\"}\nknitr::include_graphics('./filename.png')\n```\\ref{fig:test}```{r echo=FALSE, out.width='75%', fig.cap=\"\\\\label{fig:spell}RStudio Task Bar\"}\nknitr::include_graphics('./spell.png')\n```\n\nAs we can see in \\ref{fig:spell}"},{"path":"rmarkdown.html","id":"useful-stuff","chapter":"11 R Markdown","heading":"Useful Stuff","text":"","code":""},{"path":"rmarkdown.html","id":"spell-checker","chapter":"11 R Markdown","heading":"Spell-Checker","text":"","code":""},{"path":"rmarkdown.html","id":"useful-commands","chapter":"11 R Markdown","heading":"Useful Commands","text":"New pageCentering Line","code":"\\newpage\\begin{center}\nText to be centred.\n\\end{center}"},{"path":"rmarkdown.html","id":"bibliography","chapter":"11 R Markdown","heading":"Bibliography","text":"possible (highly recommended) include automatic bibliography MarkdownThis requires coding language LaTeXPerksIt includes citeIt sorts references alphabeticallyConsistent citationAutomatically conform PAIS style","code":""},{"path":"rmarkdown.html","id":"getting-started","chapter":"11 R Markdown","heading":"Getting Started","text":"Download install:\nMac: MacTeX (http://www.tug.org/mactex/)\nWindows: MiKTeX (https://miktex.org/)\nMac: MacTeX (http://www.tug.org/mactex/)Windows: MiKTeX (https://miktex.org/)contain complete TeX system LaTeX editors write documents.: https://www.latex-project.org/get/InstructionsPlace working directory file “bibliography.bib”Add heading end document called ","code":""},{"path":"rmarkdown.html","id":"citations-in-markdown","chapter":"11 R Markdown","heading":"Citations in Markdown","text":"CitationsSuppress AuthorThis can useful author already mentioned text.","code":"Text [@grolemund:2016, p. 361]  \n\nText [@grolemund:2016, pp. 33-35, 38-39 and *passim*].Grolemund and Wickham write that ... [-@grolemund:2016]  "},{"path":"rmarkdown.html","id":"the-.bib-file","chapter":"11 R Markdown","heading":"The .bib file","text":"Every citation needs reference .bib file, :can edit file LaTeXIf want learn , another Moodle Skills Module called Academic Writing LaTeX available.Inputturns output","code":"@book{grolemund:2016,\n  author={Garrett Grolemund and Hadley Wickham},\n  title={R for Data Science},\n  publisher={O'Reilly Media},\n  year={2016}}# Introduction\n\nText [@grolemund:2016, p. 361]\n\n# References"},{"path":"rmarkdown.html","id":"stargazer","chapter":"11 R Markdown","heading":"stargazer","text":"little patience students (academics!) fiddling around MS Word using sorts fancy options make Tables Figures unreadable possible. can tell quite particular comes tabular display statistical output.study degree Political Science, acquiring skills write professionally topic discipline, analyse research question within remit. James . Stimson puts aptly article Writing Political Science says:professional author. Learn use tools authorship choose\nprofession better suited. (p. 10)Stimson says reference Tables particular, principles academic author needs observe. Let quote article :Table design important, often done badly. requires think\nreader knows wants know work \ncarefully lay table tell story. (…)Tables always composed reader can pick one\nunderstand content, without read text. means \nmust fully self-contained, depending nothing explained \ntext. opposite also true; reader able skip table\nunderstand analysis completely text. (p.10)observe principles set Stimson’s article (please read , ’s worth weight gold), R snazzy package helps way. called stargazer pretty much best invention since sliced bread: R package creates code, HTML code ASCII text well-formatted regression tables, multiple models side--side, well summary statistics tables, data frames, vectors matrices.(https://cran.r-project.org/web/packages/stargazer/vignettes/stargazer.pdf)AdvantagesIts ease useThe large number models supportsIts beautiful aestheticsEstimating Model, replicating work Fearon Laitin (2003)Data PrepModel 1Model 2Model 3Now use stargazer put results table. suppressing annoying heager , adjusting font size, .OutputYou note stargazer adds asterisks Stimson strongly (correctly) opposed . rating lower p-values increasing numbers asterisks suggests certain goal (like wanting stay five-star hotel), goal nonesense. want know , recommend excellent module called “Introduction Quantitative Political Analysis ” learn p-value Type Type II errors. stargazer’s practice include asterisks therefore misguided, since journals insist nonsense, worthwhile get used .Font SizesIn descending OrderI ignore {r results='asis', echo=F, message=F, tab.cap = NULL} environment now, show actual stargazer script used.Adding Variable Names, quoting Stimson:usual problem names brief convey indicator . (remember rule self-contained: reader needs page back find ambiguous name stands , violated rule caused reader impatience.) Abbreviate nothing. never ever ever use computer\nvariable names stand concepts. personal code words \nconvey meaning readers. (p.10)Suppress StatisticsFor full list abbreviations statistics, see page 22 https://cran.r-project.org/web/packages/stargazer/stargazer.pdfAdd ROC CurveRound ROC CurveYou can also control number decimal places digits = option generally. example, want round everything two decimal places, set digits = 2.Lastly, let’s label Table, reader knows shown.beautiful informative Table standard work.","code":"\nlibrary(haven)\nlibrary(tidyverse)\nlibrary(pROC)\nlibrary(stargazer)\nfearon <- read_dta(\"data/fearon.dta\")\n\nfearon$onset[fearon$onset==4] <- NA\n\nfearon$onset <- as.factor(fearon$onset)\nmodel1 <- glm(onset ~ gdpenl,\n             family = binomial(link = logit),\n             na.action = na.exclude,\n             data = fearon)\n\nprob_model1 <- predict(model1, type=\"response\")\nfearon$prob_model1 <- unlist(prob_model1)\n\nroc_model1 <- roc(fearon$onset, fearon$prob_model1)Setting levels: control = 0, case = 1Setting direction: controls < cases\nmodel2 <- glm(onset ~ gdpenl + lpopl1,\n             family = binomial(link = logit),\n             na.action = na.exclude,\n             data = fearon)\n\nprob_model2 <- predict(model2, type=\"response\")\nfearon$prob_model2 <- unlist(prob_model2)\n\nroc_model2 <- roc(fearon$onset, fearon$prob_model2)Setting levels: control = 0, case = 1Setting direction: controls < cases\nmodel3 <- glm(onset ~ gdpenl + lpopl1 + lmtnest,\n             family = binomial(link = logit),\n             na.action = na.exclude,\n             data = fearon)\n\nprob_model3 <- predict(model3, type=\"response\")\nfearon$prob_model3 <- unlist(prob_model3)\n\nroc_model3 <- roc(fearon$onset, fearon$prob_model3)Setting levels: control = 0, case = 1Setting direction: controls < cases\\Huge\n\\huge\n\\LARGE\n\\Large\n\\large\n\\normalsize\n\\small\n\\footnotesize\n\\scriptsize\n\\tiny\nstargazer(model1, model2, model3,\n          header=F, \n          font.size = \"tiny\", \n          covariate.labels = c(\"GDP per capita (in logged 1985\\\\$ thousands)\",\n                               \"Population (logged, in thousands)\",\n                               \"Mountainous Terrain (logged \\\\% of total)\"),\n          dep.var.labels   = \"Onset of Civil War\")\nstargazer(model1, model2, model3,\n          header=F, \n          font.size = \"tiny\", \n          covariate.labels = c(\"GDP per capita (in logged 1985\\\\$ thousands)\",\n                               \"Population (logged, in thousands)\",\n                               \"Mountainous Terrain (logged \\\\% of total)\"),\n          dep.var.labels   = \"Onset of Civil War\",\n          omit.stat = c(\"aic\", \"ll\"))\nstargazer(model1, model2, model3,\n          header=F, \n          font.size = \"tiny\", \n          covariate.labels = c(\"GDP per capita (in logged 1985\\\\$ thousands)\",\n                               \"Population (logged, in thousands)\",\n                               \"Mountainous Terrain (logged \\\\% of total)\"),\n          dep.var.labels   = \"Onset of Civil War\",\n          omit.stat = c(\"aic\", \"ll\"),\n          add.lines = list(c(\"ROC Curve\", auc(roc_model1), \n                              auc(roc_model2), auc(roc_model3))))\nstargazer(model1, model2, model3,\n          header=F, \n          font.size = \"tiny\", \n          covariate.labels = c(\"GDP per capita (in logged 1985\\\\$ thousands)\",\n                               \"Population (logged, in thousands)\",\n                               \"Mountainous Terrain (logged \\\\% of total)\"),\n          dep.var.labels   = \"Onset of Civil War\",\n          omit.stat = c(\"aic\", \"ll\"),\n          add.lines = list(c(\"ROC Curve\", round(auc(roc_model1),2), \n                              round(auc(roc_model2),2), \n                              round(auc(roc_model3),2))))\nstargazer(model1, model2, model3,\n          header=F, \n          font.size = \"tiny\", \n          covariate.labels = c(\"GDP per capita (in logged 1985\\\\$ thousands)\",\n                               \"Population (logged, in thousands)\",\n                               \"Mountainous Terrain (logged \\\\% of total)\"),\n          dep.var.labels   = \"Onset of Civil War\",\n          omit.stat = c(\"aic\", \"ll\"),\n          add.lines = list(c(\"ROC Curve\", round(auc(roc_model1),2), \n                              round(auc(roc_model2),2), \n                              round(auc(roc_model3),2))),\n          title = \"Determinants of Civil War (Fearon and Laitin, 2003)\")"},{"path":"rmarkdown.html","id":"summary-9","chapter":"11 R Markdown","heading":"11.2 Summary","text":"","code":""},{"path":"rmarkdown.html","id":"functions-list-9","chapter":"11 R Markdown","heading":"Functions list","text":"","code":""},{"path":"rmarkdown.html","id":"exercises-9","chapter":"11 R Markdown","heading":"11.3 Exercises","text":"solutions exercises available 2021-03-12.","code":""},{"path":"course-summary.html","id":"course-summary","chapter":"12 Course summary","heading":"12 Course summary","text":"","code":""},{"path":"course-summary.html","id":"index-of-functions-used-throughout-the-course","chapter":"12 Course summary","heading":"Index of functions used throughout the course","text":"","code":""}]
